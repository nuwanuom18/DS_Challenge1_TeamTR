{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set() # if you want to use seaborn themes with matplotlib functions\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('CSE_DSIntro1_TRAIN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_state = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Column_1</th>\n",
       "      <th>Column_2</th>\n",
       "      <th>Column_3</th>\n",
       "      <th>Column_4</th>\n",
       "      <th>Column_5</th>\n",
       "      <th>Column_6</th>\n",
       "      <th>Column_7</th>\n",
       "      <th>Column_8</th>\n",
       "      <th>Column_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Column_69</th>\n",
       "      <th>Column_70</th>\n",
       "      <th>Column_71</th>\n",
       "      <th>Column_72</th>\n",
       "      <th>Column_73</th>\n",
       "      <th>Column_74</th>\n",
       "      <th>Column_75</th>\n",
       "      <th>Column_76</th>\n",
       "      <th>Column_77</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>77041.5</td>\n",
       "      <td>44471.03389</td>\n",
       "      <td>88955.41342</td>\n",
       "      <td>1602.4632</td>\n",
       "      <td>1787.3628</td>\n",
       "      <td>1571.6466</td>\n",
       "      <td>1294.2972</td>\n",
       "      <td>1664.0964</td>\n",
       "      <td>1756.5462</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>77120.0</td>\n",
       "      <td>44516.34682</td>\n",
       "      <td>89046.05288</td>\n",
       "      <td>1573.2480</td>\n",
       "      <td>2128.5120</td>\n",
       "      <td>987.1360</td>\n",
       "      <td>956.2880</td>\n",
       "      <td>1511.5520</td>\n",
       "      <td>1388.1600</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>77120.0</td>\n",
       "      <td>44516.34682</td>\n",
       "      <td>89046.05288</td>\n",
       "      <td>1789.1840</td>\n",
       "      <td>1511.5520</td>\n",
       "      <td>1665.7920</td>\n",
       "      <td>1326.4640</td>\n",
       "      <td>1357.3120</td>\n",
       "      <td>1634.9440</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>77117.5</td>\n",
       "      <td>44514.90373</td>\n",
       "      <td>89043.16628</td>\n",
       "      <td>1511.5030</td>\n",
       "      <td>1789.1260</td>\n",
       "      <td>1233.8800</td>\n",
       "      <td>1881.6670</td>\n",
       "      <td>1418.9620</td>\n",
       "      <td>2159.2900</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>77120.0</td>\n",
       "      <td>44516.34682</td>\n",
       "      <td>89046.05288</td>\n",
       "      <td>1974.2720</td>\n",
       "      <td>1696.6400</td>\n",
       "      <td>832.8960</td>\n",
       "      <td>1820.0320</td>\n",
       "      <td>1758.3360</td>\n",
       "      <td>1727.4880</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>2496</td>\n",
       "      <td>77117.5</td>\n",
       "      <td>44514.90373</td>\n",
       "      <td>89043.16628</td>\n",
       "      <td>1203.0330</td>\n",
       "      <td>2282.6780</td>\n",
       "      <td>1542.3500</td>\n",
       "      <td>1758.2790</td>\n",
       "      <td>1850.8200</td>\n",
       "      <td>1295.5740</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>42</td>\n",
       "      <td>33</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>2497</td>\n",
       "      <td>77120.0</td>\n",
       "      <td>44516.34682</td>\n",
       "      <td>89046.05288</td>\n",
       "      <td>894.5920</td>\n",
       "      <td>1203.0720</td>\n",
       "      <td>1079.6800</td>\n",
       "      <td>1480.7040</td>\n",
       "      <td>1449.8560</td>\n",
       "      <td>1604.0960</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>42</td>\n",
       "      <td>34</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>2498</td>\n",
       "      <td>77117.5</td>\n",
       "      <td>44514.90373</td>\n",
       "      <td>89043.16628</td>\n",
       "      <td>1789.1260</td>\n",
       "      <td>1604.0440</td>\n",
       "      <td>1326.4210</td>\n",
       "      <td>1418.9620</td>\n",
       "      <td>1542.3500</td>\n",
       "      <td>1511.5030</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>42</td>\n",
       "      <td>34</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>2499</td>\n",
       "      <td>77117.5</td>\n",
       "      <td>44514.90373</td>\n",
       "      <td>89043.16628</td>\n",
       "      <td>1789.1260</td>\n",
       "      <td>524.3990</td>\n",
       "      <td>1511.5030</td>\n",
       "      <td>1357.2680</td>\n",
       "      <td>863.7160</td>\n",
       "      <td>616.9400</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>42</td>\n",
       "      <td>35</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>2500</td>\n",
       "      <td>77120.0</td>\n",
       "      <td>44516.34682</td>\n",
       "      <td>89046.05288</td>\n",
       "      <td>1542.4000</td>\n",
       "      <td>1789.1840</td>\n",
       "      <td>1850.8800</td>\n",
       "      <td>1511.5520</td>\n",
       "      <td>1758.3360</td>\n",
       "      <td>1326.4640</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>42</td>\n",
       "      <td>35</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows Ã— 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  Column_1     Column_2     Column_3   Column_4   Column_5  \\\n",
       "0        1   77041.5  44471.03389  88955.41342  1602.4632  1787.3628   \n",
       "1        2   77120.0  44516.34682  89046.05288  1573.2480  2128.5120   \n",
       "2        3   77120.0  44516.34682  89046.05288  1789.1840  1511.5520   \n",
       "3        4   77117.5  44514.90373  89043.16628  1511.5030  1789.1260   \n",
       "4        5   77120.0  44516.34682  89046.05288  1974.2720  1696.6400   \n",
       "...    ...       ...          ...          ...        ...        ...   \n",
       "2495  2496   77117.5  44514.90373  89043.16628  1203.0330  2282.6780   \n",
       "2496  2497   77120.0  44516.34682  89046.05288   894.5920  1203.0720   \n",
       "2497  2498   77117.5  44514.90373  89043.16628  1789.1260  1604.0440   \n",
       "2498  2499   77117.5  44514.90373  89043.16628  1789.1260   524.3990   \n",
       "2499  2500   77120.0  44516.34682  89046.05288  1542.4000  1789.1840   \n",
       "\n",
       "       Column_6   Column_7   Column_8   Column_9  ...  Column_69  Column_70  \\\n",
       "0     1571.6466  1294.2972  1664.0964  1756.5462  ...         22          2   \n",
       "1      987.1360   956.2880  1511.5520  1388.1600  ...         22          2   \n",
       "2     1665.7920  1326.4640  1357.3120  1634.9440  ...         22          2   \n",
       "3     1233.8800  1881.6670  1418.9620  2159.2900  ...         22          2   \n",
       "4      832.8960  1820.0320  1758.3360  1727.4880  ...         22          2   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "2495  1542.3500  1758.2790  1850.8200  1295.5740  ...         22          2   \n",
       "2496  1079.6800  1480.7040  1449.8560  1604.0960  ...         22          2   \n",
       "2497  1326.4210  1418.9620  1542.3500  1511.5030  ...         22          2   \n",
       "2498  1511.5030  1357.2680   863.7160   616.9400  ...         22          2   \n",
       "2499  1850.8800  1511.5520  1758.3360  1326.4640  ...         22          2   \n",
       "\n",
       "      Column_71  Column_72  Column_73  Column_74  Column_75  Column_76  \\\n",
       "0          2021         11         23         15         22          2   \n",
       "1          2021         11         23         15         22          2   \n",
       "2          2021         11         23         15         22          2   \n",
       "3          2021         11         23         16         22          2   \n",
       "4          2021         11         23         16         22          2   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "2495       2021         11         42         33         22          2   \n",
       "2496       2021         11         42         34         22          2   \n",
       "2497       2021         11         42         34         22          2   \n",
       "2498       2021         11         42         35         22          2   \n",
       "2499       2021         11         42         35         22          2   \n",
       "\n",
       "      Column_77  Category  \n",
       "0          2021         0  \n",
       "1          2021         0  \n",
       "2          2021         0  \n",
       "3          2021         0  \n",
       "4          2021         0  \n",
       "...         ...       ...  \n",
       "2495       2021         1  \n",
       "2496       2021         1  \n",
       "2497       2021         1  \n",
       "2498       2021         0  \n",
       "2499       2021         0  \n",
       "\n",
       "[2500 rows x 79 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id           0.0\n",
       "Column_1     0.0\n",
       "Column_2     0.0\n",
       "Column_3     0.0\n",
       "Column_4     0.0\n",
       "            ... \n",
       "Column_74    0.0\n",
       "Column_75    0.0\n",
       "Column_76    0.0\n",
       "Column_77    0.0\n",
       "Category     0.0\n",
       "Length: 79, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()/len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(dataset.duplicated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the duplicates:\n",
    "dataset.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 1 Column_55\n",
      "57 1 Column_57\n",
      "66 1 Column_66\n",
      "69 1 Column_69\n",
      "70 1 Column_70\n",
      "71 1 Column_71\n",
      "72 1 Column_72\n",
      "75 1 Column_75\n",
      "76 1 Column_76\n",
      "77 1 Column_77\n"
     ]
    }
   ],
   "source": [
    "unique_values = list(dataset.nunique())\n",
    "for i in range(len(unique_values)):\n",
    "    if unique_values[i] == 1:\n",
    "        print(i, unique_values[i],dataset.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find 55\n",
      "find 57\n",
      "find 66\n",
      "find 69\n",
      "find 70\n",
      "find 71\n",
      "find 72\n",
      "find 75\n",
      "find 76\n",
      "find 77\n",
      "        Id  Column_1     Column_2     Column_3   Column_4   Column_5  \\\n",
      "0        1   77041.5  44471.03389  88955.41342  1602.4632  1787.3628   \n",
      "1        2   77120.0  44516.34682  89046.05288  1573.2480  2128.5120   \n",
      "2        3   77120.0  44516.34682  89046.05288  1789.1840  1511.5520   \n",
      "3        4   77117.5  44514.90373  89043.16628  1511.5030  1789.1260   \n",
      "4        5   77120.0  44516.34682  89046.05288  1974.2720  1696.6400   \n",
      "...    ...       ...          ...          ...        ...        ...   \n",
      "2495  2496   77117.5  44514.90373  89043.16628  1203.0330  2282.6780   \n",
      "2496  2497   77120.0  44516.34682  89046.05288   894.5920  1203.0720   \n",
      "2497  2498   77117.5  44514.90373  89043.16628  1789.1260  1604.0440   \n",
      "2498  2499   77117.5  44514.90373  89043.16628  1789.1260   524.3990   \n",
      "2499  2500   77120.0  44516.34682  89046.05288  1542.4000  1789.1840   \n",
      "\n",
      "       Column_6   Column_7   Column_8   Column_9  ...  Column_61    Column_62  \\\n",
      "0     1571.6466  1294.2972  1664.0964  1756.5462  ...   1.511108  63642.86256   \n",
      "1      987.1360   956.2880  1511.5520  1388.1600  ...   1.511097  63649.22304   \n",
      "2     1665.7920  1326.4640  1357.3120  1634.9440  ...   1.511247  63658.20567   \n",
      "3     1233.8800  1881.6670  1418.9620  2159.2900  ...   1.511245  63655.53620   \n",
      "4      832.8960  1820.0320  1758.3360  1727.4880  ...   1.511409  63637.01387   \n",
      "...         ...        ...        ...        ...  ...        ...          ...   \n",
      "2495  1542.3500  1758.2790  1850.8200  1295.5740  ...   1.511090  63689.52068   \n",
      "2496  1079.6800  1480.7040  1449.8560  1604.0960  ...   1.511129  63696.82226   \n",
      "2497  1326.4210  1418.9620  1542.3500  1511.5030  ...   1.511286  63695.04189   \n",
      "2498  1511.5030  1357.2680   863.7160   616.9400  ...   1.511245  63683.13411   \n",
      "2499  1850.8800  1511.5520  1758.3360  1326.4640  ...   1.511552  63697.79604   \n",
      "\n",
      "      Column_63  Column_64  Column_65  Column_67  Column_68  Column_73  \\\n",
      "0      1.527652   0.073507   1.511320         23         15         23   \n",
      "1      1.527373   0.073794   1.511169         23         15         23   \n",
      "2      1.527631   0.073571   1.511256         23         15         23   \n",
      "3      1.527550   0.073430   1.511489         23         16         23   \n",
      "4      1.527490   0.073543   1.511393         23         16         23   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "2495   1.527730   0.073834   1.510860         42         33         42   \n",
      "2496   1.527971   0.073253   1.511402         42         34         42   \n",
      "2497   1.527891   0.073301   1.511400         42         34         42   \n",
      "2498   1.527758   0.073542   1.511201         42         35         42   \n",
      "2499   1.527767   0.073461   1.511293         42         35         42   \n",
      "\n",
      "      Column_74  Category  \n",
      "0            15         0  \n",
      "1            15         0  \n",
      "2            15         0  \n",
      "3            16         0  \n",
      "4            16         0  \n",
      "...         ...       ...  \n",
      "2495         33         1  \n",
      "2496         34         1  \n",
      "2497         34         1  \n",
      "2498         35         0  \n",
      "2499         35         0  \n",
      "\n",
      "[2500 rows x 69 columns]\n"
     ]
    }
   ],
   "source": [
    "unique_values = list(dataset.nunique())\n",
    "k=0\n",
    "for i in range(len(unique_values)):\n",
    "    if unique_values[i] == 1:\n",
    "        print('find', i)\n",
    "        dataset.drop(dataset.columns[i-k], axis=1 ,inplace=True)\n",
    "        k+=1\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'Column_1', 'Column_2', 'Column_3', 'Column_4', 'Column_5',\n",
       "       'Column_6', 'Column_7', 'Column_8', 'Column_9', 'Column_10',\n",
       "       'Column_11', 'Column_12', 'Column_13', 'Column_14', 'Column_15',\n",
       "       'Column_16', 'Column_17', 'Column_18', 'Column_19', 'Column_20',\n",
       "       'Column_21', 'Column_22', 'Column_23', 'Column_24', 'Column_25',\n",
       "       'Column_26', 'Column_27', 'Column_28', 'Column_29', 'Column_30',\n",
       "       'Column_31', 'Column_32', 'Column_33', 'Column_34', 'Column_35',\n",
       "       'Column_36', 'Column_37', 'Column_38', 'Column_39', 'Column_40',\n",
       "       'Column_41', 'Column_42', 'Column_43', 'Column_44', 'Column_45',\n",
       "       'Column_46', 'Column_47', 'Column_48', 'Column_49', 'Column_50',\n",
       "       'Column_51', 'Column_52', 'Column_53', 'Column_54', 'Column_56',\n",
       "       'Column_58', 'Column_59', 'Column_60', 'Column_61', 'Column_62',\n",
       "       'Column_63', 'Column_64', 'Column_65', 'Column_67', 'Column_68',\n",
       "       'Column_73', 'Column_74', 'Category'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('CSE_DSIntro1_TEST.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 1 Column_55\n",
      "57 1 Column_57\n",
      "66 1 Column_66\n",
      "69 1 Column_69\n",
      "70 1 Column_70\n",
      "71 1 Column_71\n",
      "72 1 Column_72\n",
      "75 1 Column_75\n",
      "76 1 Column_76\n",
      "77 1 Column_77\n"
     ]
    }
   ],
   "source": [
    "unique_values_test = list(test_data.nunique())\n",
    "for i in range(len(unique_values_test)):\n",
    "    if unique_values_test[i] == 1:\n",
    "        print(i, unique_values_test[i],test_data.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find 55\n",
      "find 57\n",
      "find 66\n",
      "find 69\n",
      "find 70\n",
      "find 71\n",
      "find 72\n",
      "find 75\n",
      "find 76\n",
      "find 77\n",
      "        Id  Column_1     Column_2     Column_3   Column_4   Column_5  \\\n",
      "0        1  77117.50  44514.90373  89043.16628  1696.5850  1665.7380   \n",
      "1        2  77120.00  44516.34682  89046.05288  1357.3120   339.3280   \n",
      "2        3  77120.00  44516.34682  89046.05288  1758.3360  1974.2720   \n",
      "3        4  77120.00  44516.34682  89046.05288  1110.5280  1264.7680   \n",
      "4        5  77120.00  44516.34682  89046.05288  2652.9280  2005.1200   \n",
      "...    ...       ...          ...          ...        ...        ...   \n",
      "1586  1587  77120.00  44516.34682  89046.05288  1789.1840  1881.7280   \n",
      "1587  1588  77117.50  44514.90373  89043.16628  1696.5850  1357.2680   \n",
      "1588  1589  77122.25  44517.64560  89048.65083  1696.6895  1727.5384   \n",
      "1589  1590  77122.25  44517.64560  89048.65083  1449.8983  1789.2362   \n",
      "1590  1591  77122.25  44517.64560  89048.65083  1449.8983  1326.5027   \n",
      "\n",
      "       Column_6   Column_7   Column_8   Column_9  ...  Column_60  Column_61  \\\n",
      "0     1418.9620  1264.7270  1203.0330  1573.1970  ...   0.073235   1.511481   \n",
      "1     1326.4640  1017.9840  1573.2480  1604.0960  ...   0.073413   1.511241   \n",
      "2     1480.7040  1141.3760  1542.4000  1388.1600  ...   0.073253   1.511402   \n",
      "3     1388.1600  1449.8560  1573.2480  1419.0080  ...   0.073415   1.511293   \n",
      "4     1943.4240   493.5680  1388.1600   740.3520  ...   0.073395   1.511170   \n",
      "...         ...        ...        ...        ...  ...        ...        ...   \n",
      "1586  1449.8560  1573.2480  1419.0080  1542.4000  ...   0.073209   1.511755   \n",
      "1587  1727.4320  1542.3500  1295.5740  1449.8090  ...   0.073503   1.511498   \n",
      "1588  1573.2939  1449.8983   246.7912  1480.7472  ...   0.073398   1.511532   \n",
      "1589  1634.9917  1203.1071  1326.5027  1357.3516  ...   0.073327   1.511689   \n",
      "1590  1388.2005   154.2445  1480.7472  1048.8626  ...   0.073095   1.511757   \n",
      "\n",
      "        Column_62  Column_63  Column_64  Column_65  Column_67  Column_68  \\\n",
      "0     63697.96460   1.527815   0.073497   1.511214         42         36   \n",
      "1     63707.62973   1.527853   0.073633   1.511019         42         36   \n",
      "2     63699.33986   1.527973   0.073148   1.511530         42         36   \n",
      "3     63691.57205   1.527999   0.073202   1.511444         42         37   \n",
      "4     63691.78617   1.527921   0.073248   1.511445         42         37   \n",
      "...           ...        ...        ...        ...        ...        ...   \n",
      "1586  63656.58449   1.527551   0.073225   1.511742         56          0   \n",
      "1587  63655.56354   1.527707   0.073006   1.511899         56          0   \n",
      "1588  63659.57645   1.527553   0.073222   1.511745         56          1   \n",
      "1589  63638.76254   1.527492   0.073274   1.511726         56          1   \n",
      "1590  63657.61274   1.527457   0.073445   1.511539         56          2   \n",
      "\n",
      "      Column_73  Column_74  \n",
      "0            42         36  \n",
      "1            42         36  \n",
      "2            42         37  \n",
      "3            42         37  \n",
      "4            42         37  \n",
      "...         ...        ...  \n",
      "1586         56          0  \n",
      "1587         56          0  \n",
      "1588         56          1  \n",
      "1589         56          1  \n",
      "1590         56          2  \n",
      "\n",
      "[1591 rows x 68 columns]\n"
     ]
    }
   ],
   "source": [
    "k_test=0\n",
    "for i in range(len(unique_values_test)):\n",
    "    if unique_values_test[i] == 1:\n",
    "        print('find', i)\n",
    "        test_data.drop(test_data.columns[i-k_test], axis=1 ,inplace=True)\n",
    "        k_test+=1\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'Column_1', 'Column_2', 'Column_3', 'Column_4', 'Column_5',\n",
       "       'Column_6', 'Column_7', 'Column_8', 'Column_9', 'Column_10',\n",
       "       'Column_11', 'Column_12', 'Column_13', 'Column_14', 'Column_15',\n",
       "       'Column_16', 'Column_17', 'Column_18', 'Column_19', 'Column_20',\n",
       "       'Column_21', 'Column_22', 'Column_23', 'Column_24', 'Column_25',\n",
       "       'Column_26', 'Column_27', 'Column_28', 'Column_29', 'Column_30',\n",
       "       'Column_31', 'Column_32', 'Column_33', 'Column_34', 'Column_35',\n",
       "       'Column_36', 'Column_37', 'Column_38', 'Column_39', 'Column_40',\n",
       "       'Column_41', 'Column_42', 'Column_43', 'Column_44', 'Column_45',\n",
       "       'Column_46', 'Column_47', 'Column_48', 'Column_49', 'Column_50',\n",
       "       'Column_51', 'Column_52', 'Column_53', 'Column_54', 'Column_56',\n",
       "       'Column_58', 'Column_59', 'Column_60', 'Column_61', 'Column_62',\n",
       "       'Column_63', 'Column_64', 'Column_65', 'Column_67', 'Column_68',\n",
       "       'Column_73', 'Column_74'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 1:-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Sample_Test = test_data.values[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.71175000e+04, 4.45149037e+04, 8.90431663e+04, ...,\n",
       "        3.60000000e+01, 4.20000000e+01, 3.60000000e+01],\n",
       "       [7.71200000e+04, 4.45163468e+04, 8.90460529e+04, ...,\n",
       "        3.60000000e+01, 4.20000000e+01, 3.60000000e+01],\n",
       "       [7.71200000e+04, 4.45163468e+04, 8.90460529e+04, ...,\n",
       "        3.60000000e+01, 4.20000000e+01, 3.70000000e+01],\n",
       "       ...,\n",
       "       [7.71222500e+04, 4.45176456e+04, 8.90486508e+04, ...,\n",
       "        1.00000000e+00, 5.60000000e+01, 1.00000000e+00],\n",
       "       [7.71222500e+04, 4.45176456e+04, 8.90486508e+04, ...,\n",
       "        1.00000000e+00, 5.60000000e+01, 1.00000000e+00],\n",
       "       [7.71222500e+04, 4.45176456e+04, 8.90486508e+04, ...,\n",
       "        2.00000000e+00, 5.60000000e+01, 2.00000000e+00]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Sample_Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.70415000e+04, 4.44710339e+04, 8.89554134e+04, ...,\n",
       "        1.50000000e+01, 2.30000000e+01, 1.50000000e+01],\n",
       "       [7.71200000e+04, 4.45163468e+04, 8.90460529e+04, ...,\n",
       "        1.50000000e+01, 2.30000000e+01, 1.50000000e+01],\n",
       "       [7.71200000e+04, 4.45163468e+04, 8.90460529e+04, ...,\n",
       "        1.50000000e+01, 2.30000000e+01, 1.50000000e+01],\n",
       "       ...,\n",
       "       [7.71175000e+04, 4.45149037e+04, 8.90431663e+04, ...,\n",
       "        3.40000000e+01, 4.20000000e+01, 3.40000000e+01],\n",
       "       [7.71175000e+04, 4.45149037e+04, 8.90431663e+04, ...,\n",
       "        3.50000000e+01, 4.20000000e+01, 3.50000000e+01],\n",
       "       [7.71200000e+04, 4.45163468e+04, 8.90460529e+04, ...,\n",
       "        3.50000000e+01, 4.20000000e+01, 3.50000000e+01]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.01, random_state = rand_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn import  metrics   #Additional scklearn functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelfit(alg, X_train,y_train, X_test, y_test ,useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='auc', early_stopping_rounds=early_stopping_rounds)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(X_train, y_train ,eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(X_test)\n",
    "    dtrain_predprob = alg.predict_proba(X_test)[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"Accuracy : %.4g\" % metrics.accuracy_score(y_test, dtrain_predictions))\n",
    "    print(\"AUC Score (Train): %f\" % metrics.roc_auc_score(y_test, dtrain_predprob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Category'\n",
    "IDcol = 'Id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Accuracy : 0.64\n",
      "AUC Score (Train): 0.694444\n"
     ]
    }
   ],
   "source": [
    "#Choose all predictors except target & IDcols\n",
    "predictors = [x for x in dataset.columns if x not in ['Category', \"Id\"]]\n",
    "xgb1 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb1, X_train,y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:30:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=0.8, gamma=0, gpu_id=None,\n",
       "                                     importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=0.1, max_delta_step=None,\n",
       "                                     max_depth=5, min_child_weight=1,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=1000,...\n",
       "                                     objective='binary:logistic',\n",
       "                                     random_state=None, reg_alpha=None,\n",
       "                                     reg_lambda=None, scale_pos_weight=1,\n",
       "                                     seed=27, subsample=0.8, tree_method=None,\n",
       "                                     use_label_encoder=True,\n",
       "                                     validate_parameters=None, verbosity=None),\n",
       "             iid=False, n_jobs=4,\n",
       "             param_grid={'max_depth': range(1, 10),\n",
       "                         'min_child_weight': range(1, 10)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test1 = {\n",
    " 'max_depth':range(1,10),\n",
    " 'min_child_weight':range(1,10)\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=1000, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_depth': 1, 'min_child_weight': 5}, 0.6523015308926258)"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 5.14646025,  5.09098806,  5.02760334,  4.98404241,  4.8102704 ,\n",
       "         4.99972062,  4.98946576,  5.01885953,  5.04565806,  8.3889359 ,\n",
       "         8.74603558,  8.80695248,  8.70603218,  8.37955923,  8.4356061 ,\n",
       "         8.52354431,  8.25247879,  8.44954486, 12.58162136, 12.42001901,\n",
       "        12.11461592, 12.06438212, 11.91784768, 12.88632994, 11.84580235,\n",
       "        12.56151423, 11.17101879, 15.82269683, 15.15029473, 14.60495224,\n",
       "        14.11506257, 13.94770908, 13.80030432, 13.52783246, 13.39997392,\n",
       "        13.18614588, 18.11476874, 16.86351438, 16.84017677, 16.13486323,\n",
       "        15.46006598, 15.23506818, 15.00229053, 14.83772998, 14.5850059 ,\n",
       "        19.52759185, 17.82494464, 17.31191568, 16.64689298, 16.26631093,\n",
       "        16.01019597, 15.76724553, 15.51731339, 15.15687737, 20.10085826,\n",
       "        18.54103289, 18.00885606, 16.78372784, 16.43146925, 15.85620642,\n",
       "        15.76165967, 15.60308385, 15.1935791 , 19.97539392, 18.41337042,\n",
       "        17.89934468, 17.36008835, 16.70743747, 16.79150639, 16.52182736,\n",
       "        15.75428042, 15.38107738, 20.11981645, 18.51310415, 17.6097188 ,\n",
       "        17.12302041, 17.5590548 , 16.2760849 , 16.14802704, 15.73796401,\n",
       "        13.36090283]),\n",
       " 'std_fit_time': array([0.01578752, 0.04586244, 0.02366192, 0.05989663, 0.09223713,\n",
       "        0.02558021, 0.03905846, 0.02985938, 0.24985459, 0.34366379,\n",
       "        0.11899396, 0.11930959, 0.12815624, 0.08113795, 0.16039186,\n",
       "        0.19311581, 0.10375524, 0.18229775, 0.12548065, 0.21703769,\n",
       "        0.03485924, 0.16889936, 0.25307461, 0.56781273, 0.65614038,\n",
       "        1.00252951, 0.0563105 , 0.07798355, 0.06995638, 0.10229947,\n",
       "        0.08401135, 0.15818597, 0.18594556, 0.09719589, 0.15930357,\n",
       "        0.18234209, 0.15733285, 0.03130182, 0.28550187, 0.01657911,\n",
       "        0.15665577, 0.08421273, 0.15261216, 0.01863347, 0.1601567 ,\n",
       "        0.14226209, 0.14340916, 0.08516878, 0.12259505, 0.07936986,\n",
       "        0.03516523, 0.14622229, 0.04462611, 0.0960727 , 0.08781946,\n",
       "        0.42717048, 0.50465702, 0.09725662, 0.03958088, 0.11289472,\n",
       "        0.05490763, 0.05373903, 0.16411568, 0.27821394, 0.19066434,\n",
       "        0.17203222, 0.20721472, 0.29212961, 0.25101586, 0.3247434 ,\n",
       "        0.05389524, 0.19252729, 0.20746932, 0.12646025, 0.09499646,\n",
       "        0.07838069, 0.36186836, 0.34732427, 0.03720131, 0.04570669,\n",
       "        2.93655505]),\n",
       " 'mean_score_time': array([0.01058774, 0.00981035, 0.00909123, 0.01561875, 0.01039658,\n",
       "        0.0091032 , 0.00880046, 0.00898871, 0.01049976, 0.00999236,\n",
       "        0.00978684, 0.00880103, 0.00960488, 0.00860119, 0.00980515,\n",
       "        0.01339855, 0.01539378, 0.00939255, 0.01029882, 0.01138129,\n",
       "        0.01040187, 0.01144824, 0.01120806, 0.01170545, 0.01170492,\n",
       "        0.01158557, 0.01196847, 0.01037278, 0.01216822, 0.01137023,\n",
       "        0.0123672 , 0.0115694 , 0.01316471, 0.01256676, 0.01157007,\n",
       "        0.01156931, 0.01156988, 0.01236897, 0.01176891, 0.01156893,\n",
       "        0.01276679, 0.0127666 , 0.01316547, 0.01176887, 0.01077209,\n",
       "        0.01336465, 0.01236768, 0.01356368, 0.01176872, 0.01316533,\n",
       "        0.01196852, 0.014362  , 0.01117048, 0.01496024, 0.012567  ,\n",
       "        0.0155591 , 0.01196828, 0.01136961, 0.0127666 , 0.01216826,\n",
       "        0.01057234, 0.01216836, 0.01216769, 0.01376386, 0.01256642,\n",
       "        0.01156974, 0.01176915, 0.01216817, 0.01057229, 0.0113699 ,\n",
       "        0.01196833, 0.01156955, 0.01436286, 0.01276641, 0.01196861,\n",
       "        0.0113698 , 0.01476078, 0.01336417, 0.01117063, 0.01336498,\n",
       "        0.0125668 ]),\n",
       " 'std_score_time': array([0.00100431, 0.00162561, 0.00120375, 0.00407126, 0.00324675,\n",
       "        0.00080769, 0.00117306, 0.00143171, 0.00348838, 0.00062227,\n",
       "        0.00117471, 0.00039488, 0.0007966 , 0.00120169, 0.00074564,\n",
       "        0.0037273 , 0.0047056 , 0.00101026, 0.00153866, 0.00161113,\n",
       "        0.00048938, 0.00237009, 0.00195113, 0.00231137, 0.00171573,\n",
       "        0.00185471, 0.00209187, 0.0004886 , 0.00255367, 0.00135302,\n",
       "        0.00337291, 0.00119735, 0.00263098, 0.00293166, 0.00149232,\n",
       "        0.00079771, 0.00119695, 0.00135355, 0.00074689, 0.00135065,\n",
       "        0.0014662 , 0.00263134, 0.00239416, 0.00146527, 0.00074612,\n",
       "        0.00079746, 0.00174012, 0.00161969, 0.00074639, 0.00171561,\n",
       "        0.00154474, 0.00360117, 0.00146577, 0.00345481, 0.00079784,\n",
       "        0.00293138, 0.00126162, 0.00135292, 0.00146546, 0.00159638,\n",
       "        0.000798  , 0.00097705, 0.00116311, 0.00146584, 0.00119693,\n",
       "        0.00135304, 0.00182812, 0.00116336, 0.0004885 , 0.00079807,\n",
       "        0.0014101 , 0.00079801, 0.0032525 , 0.0007463 , 0.00109275,\n",
       "        0.00079806, 0.00203427, 0.00173863, 0.00039899, 0.00241057,\n",
       "        0.00184963]),\n",
       " 'param_max_depth': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_child_weight': masked_array(data=[1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                    1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                    1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                    1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                    1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'max_depth': 1, 'min_child_weight': 1},\n",
       "  {'max_depth': 1, 'min_child_weight': 2},\n",
       "  {'max_depth': 1, 'min_child_weight': 3},\n",
       "  {'max_depth': 1, 'min_child_weight': 4},\n",
       "  {'max_depth': 1, 'min_child_weight': 5},\n",
       "  {'max_depth': 1, 'min_child_weight': 6},\n",
       "  {'max_depth': 1, 'min_child_weight': 7},\n",
       "  {'max_depth': 1, 'min_child_weight': 8},\n",
       "  {'max_depth': 1, 'min_child_weight': 9},\n",
       "  {'max_depth': 2, 'min_child_weight': 1},\n",
       "  {'max_depth': 2, 'min_child_weight': 2},\n",
       "  {'max_depth': 2, 'min_child_weight': 3},\n",
       "  {'max_depth': 2, 'min_child_weight': 4},\n",
       "  {'max_depth': 2, 'min_child_weight': 5},\n",
       "  {'max_depth': 2, 'min_child_weight': 6},\n",
       "  {'max_depth': 2, 'min_child_weight': 7},\n",
       "  {'max_depth': 2, 'min_child_weight': 8},\n",
       "  {'max_depth': 2, 'min_child_weight': 9},\n",
       "  {'max_depth': 3, 'min_child_weight': 1},\n",
       "  {'max_depth': 3, 'min_child_weight': 2},\n",
       "  {'max_depth': 3, 'min_child_weight': 3},\n",
       "  {'max_depth': 3, 'min_child_weight': 4},\n",
       "  {'max_depth': 3, 'min_child_weight': 5},\n",
       "  {'max_depth': 3, 'min_child_weight': 6},\n",
       "  {'max_depth': 3, 'min_child_weight': 7},\n",
       "  {'max_depth': 3, 'min_child_weight': 8},\n",
       "  {'max_depth': 3, 'min_child_weight': 9},\n",
       "  {'max_depth': 4, 'min_child_weight': 1},\n",
       "  {'max_depth': 4, 'min_child_weight': 2},\n",
       "  {'max_depth': 4, 'min_child_weight': 3},\n",
       "  {'max_depth': 4, 'min_child_weight': 4},\n",
       "  {'max_depth': 4, 'min_child_weight': 5},\n",
       "  {'max_depth': 4, 'min_child_weight': 6},\n",
       "  {'max_depth': 4, 'min_child_weight': 7},\n",
       "  {'max_depth': 4, 'min_child_weight': 8},\n",
       "  {'max_depth': 4, 'min_child_weight': 9},\n",
       "  {'max_depth': 5, 'min_child_weight': 1},\n",
       "  {'max_depth': 5, 'min_child_weight': 2},\n",
       "  {'max_depth': 5, 'min_child_weight': 3},\n",
       "  {'max_depth': 5, 'min_child_weight': 4},\n",
       "  {'max_depth': 5, 'min_child_weight': 5},\n",
       "  {'max_depth': 5, 'min_child_weight': 6},\n",
       "  {'max_depth': 5, 'min_child_weight': 7},\n",
       "  {'max_depth': 5, 'min_child_weight': 8},\n",
       "  {'max_depth': 5, 'min_child_weight': 9},\n",
       "  {'max_depth': 6, 'min_child_weight': 1},\n",
       "  {'max_depth': 6, 'min_child_weight': 2},\n",
       "  {'max_depth': 6, 'min_child_weight': 3},\n",
       "  {'max_depth': 6, 'min_child_weight': 4},\n",
       "  {'max_depth': 6, 'min_child_weight': 5},\n",
       "  {'max_depth': 6, 'min_child_weight': 6},\n",
       "  {'max_depth': 6, 'min_child_weight': 7},\n",
       "  {'max_depth': 6, 'min_child_weight': 8},\n",
       "  {'max_depth': 6, 'min_child_weight': 9},\n",
       "  {'max_depth': 7, 'min_child_weight': 1},\n",
       "  {'max_depth': 7, 'min_child_weight': 2},\n",
       "  {'max_depth': 7, 'min_child_weight': 3},\n",
       "  {'max_depth': 7, 'min_child_weight': 4},\n",
       "  {'max_depth': 7, 'min_child_weight': 5},\n",
       "  {'max_depth': 7, 'min_child_weight': 6},\n",
       "  {'max_depth': 7, 'min_child_weight': 7},\n",
       "  {'max_depth': 7, 'min_child_weight': 8},\n",
       "  {'max_depth': 7, 'min_child_weight': 9},\n",
       "  {'max_depth': 8, 'min_child_weight': 1},\n",
       "  {'max_depth': 8, 'min_child_weight': 2},\n",
       "  {'max_depth': 8, 'min_child_weight': 3},\n",
       "  {'max_depth': 8, 'min_child_weight': 4},\n",
       "  {'max_depth': 8, 'min_child_weight': 5},\n",
       "  {'max_depth': 8, 'min_child_weight': 6},\n",
       "  {'max_depth': 8, 'min_child_weight': 7},\n",
       "  {'max_depth': 8, 'min_child_weight': 8},\n",
       "  {'max_depth': 8, 'min_child_weight': 9},\n",
       "  {'max_depth': 9, 'min_child_weight': 1},\n",
       "  {'max_depth': 9, 'min_child_weight': 2},\n",
       "  {'max_depth': 9, 'min_child_weight': 3},\n",
       "  {'max_depth': 9, 'min_child_weight': 4},\n",
       "  {'max_depth': 9, 'min_child_weight': 5},\n",
       "  {'max_depth': 9, 'min_child_weight': 6},\n",
       "  {'max_depth': 9, 'min_child_weight': 7},\n",
       "  {'max_depth': 9, 'min_child_weight': 8},\n",
       "  {'max_depth': 9, 'min_child_weight': 9}],\n",
       " 'split0_test_score': array([0.63577432, 0.64172917, 0.6441601 , 0.64397166, 0.64521539,\n",
       "        0.64048543, 0.63878943, 0.63944899, 0.64054197, 0.66253345,\n",
       "        0.65377078, 0.65497682, 0.65850073, 0.65101949, 0.64427317,\n",
       "        0.64299175, 0.64598801, 0.63095014, 0.65196171, 0.63656579,\n",
       "        0.63091245, 0.63698036, 0.64922926, 0.64938002, 0.62237591,\n",
       "        0.64956846, 0.63411601, 0.64655335, 0.63545396, 0.63522783,\n",
       "        0.6366977 , 0.63888365, 0.62192364, 0.64171032, 0.63202427,\n",
       "        0.62160329, 0.63392756, 0.61587457, 0.62205555, 0.63933592,\n",
       "        0.63115743, 0.62772774, 0.61681679, 0.62900916, 0.62431689,\n",
       "        0.63600045, 0.63854445, 0.63892134, 0.63053556, 0.63718765,\n",
       "        0.63304187, 0.61830551, 0.62009573, 0.61877662, 0.6339841 ,\n",
       "        0.63074285, 0.62763351, 0.63234463, 0.62456187, 0.62303547,\n",
       "        0.62169751, 0.61035315, 0.629028  , 0.64830588, 0.63257076,\n",
       "        0.63164738, 0.62908454, 0.62152791, 0.62622018, 0.63044134,\n",
       "        0.62103795, 0.61112577, 0.65051068, 0.63313609, 0.65659744,\n",
       "        0.63458712, 0.6508122 , 0.64615762, 0.62194249, 0.62825538,\n",
       "        0.61921004]),\n",
       " 'split1_test_score': array([0.67716133, 0.67695333, 0.67839044, 0.68124575, 0.68134029,\n",
       "        0.68438469, 0.6866349 , 0.68368505, 0.68446033, 0.67001361,\n",
       "        0.67805007, 0.68869601, 0.67854171, 0.679733  , 0.66791468,\n",
       "        0.67353075, 0.65732547, 0.66184479, 0.6683496 , 0.67154527,\n",
       "        0.66341427, 0.67995991, 0.66969216, 0.6626768 , 0.66460555,\n",
       "        0.67131836, 0.67228273, 0.66585357, 0.67005143, 0.67712352,\n",
       "        0.66948415, 0.67173436, 0.65859239, 0.6523145 , 0.66566447,\n",
       "        0.67027835, 0.66921942, 0.65912185, 0.65781711, 0.6602375 ,\n",
       "        0.65932985, 0.66619393, 0.65227668, 0.65707965, 0.65866803,\n",
       "        0.66640194, 0.66583466, 0.67211255, 0.66190152, 0.6775017 ,\n",
       "        0.65967022, 0.65866803, 0.64736026, 0.6703918 , 0.65950004,\n",
       "        0.65702292, 0.67067544, 0.66464337, 0.64684971, 0.65161486,\n",
       "        0.65448907, 0.65341124, 0.65811966, 0.66460555, 0.65891385,\n",
       "        0.64671734, 0.65645564, 0.66764995, 0.6478519 , 0.66944634,\n",
       "        0.6454126 , 0.64913774, 0.67008925, 0.64877846, 0.66719613,\n",
       "        0.67086453, 0.65006429, 0.65749565, 0.66229862, 0.65755238,\n",
       "        0.66383027]),\n",
       " 'split2_test_score': array([0.61975267, 0.6167839 , 0.61997958, 0.62317525, 0.62413963,\n",
       "        0.62187051, 0.61712427, 0.61381514, 0.61205658, 0.60063535,\n",
       "        0.6003328 , 0.59564329, 0.58703956, 0.60330157, 0.60222373,\n",
       "        0.59197489, 0.59902806, 0.60619469, 0.59394146, 0.59252326,\n",
       "        0.58581045, 0.58845776, 0.59152106, 0.58893049, 0.59893351,\n",
       "        0.60632706, 0.60473867, 0.58908176, 0.5901785 , 0.5909916 ,\n",
       "        0.60343393, 0.59486801, 0.59396037, 0.60218592, 0.61788064,\n",
       "        0.60146736, 0.58783375, 0.60333938, 0.59745859, 0.61084638,\n",
       "        0.5987066 , 0.60199682, 0.60574087, 0.6031692 , 0.60483322,\n",
       "        0.61113002, 0.60628924, 0.60080554, 0.60402012, 0.59825278,\n",
       "        0.59486801, 0.601543  , 0.60371757, 0.59235307, 0.61128129,\n",
       "        0.61572498, 0.62009303, 0.61814537, 0.59959534, 0.58840103,\n",
       "        0.62056577, 0.60443612, 0.60173209, 0.61147039, 0.61226458,\n",
       "        0.62118977, 0.6121133 , 0.61094093, 0.5871341 , 0.59639967,\n",
       "        0.60091899, 0.60523032, 0.61396642, 0.60891763, 0.60545723,\n",
       "        0.60207246, 0.61269949, 0.61031692, 0.61086529, 0.60940927,\n",
       "        0.60683761]),\n",
       " 'split3_test_score': array([0.65554799, 0.65452689, 0.65492398, 0.65482944, 0.65675819,\n",
       "        0.65507526, 0.66139097, 0.66277135, 0.66681794, 0.68111338,\n",
       "        0.67005143, 0.65846003, 0.66360336, 0.66649648, 0.68750473,\n",
       "        0.67629151, 0.67046744, 0.67780425, 0.66963543, 0.67146963,\n",
       "        0.67441948, 0.67716133, 0.67179109, 0.66995689, 0.68340141,\n",
       "        0.65999168, 0.67076999, 0.68043265, 0.67740716, 0.68241812,\n",
       "        0.67048635, 0.67290674, 0.67757734, 0.66401936, 0.6736442 ,\n",
       "        0.66931397, 0.65823311, 0.67298238, 0.67228273, 0.65728765,\n",
       "        0.66880342, 0.67536495, 0.65664473, 0.66076696, 0.66080478,\n",
       "        0.67353075, 0.68697527, 0.66872778, 0.65961349, 0.67687769,\n",
       "        0.67014598, 0.68209666, 0.66097496, 0.66014295, 0.6742493 ,\n",
       "        0.6742493 , 0.6691627 , 0.66080478, 0.67493004, 0.67148854,\n",
       "        0.67657515, 0.65785493, 0.65013993, 0.67719915, 0.67532713,\n",
       "        0.66366009, 0.6622608 , 0.67846608, 0.67001361, 0.66313063,\n",
       "        0.65849784, 0.65460253, 0.65776038, 0.671602  , 0.66120188,\n",
       "        0.67944936, 0.66591029, 0.67691551, 0.66884124, 0.66965434,\n",
       "        0.64524242]),\n",
       " 'split4_test_score': array([0.64981847, 0.65263596, 0.65706074, 0.6571931 , 0.65405416,\n",
       "        0.6545458 , 0.65197413, 0.65346797, 0.65499962, 0.63556085,\n",
       "        0.63747069, 0.640534  , 0.63605249, 0.63028515, 0.62777021,\n",
       "        0.65108539, 0.63883216, 0.64125255, 0.62807276, 0.63083352,\n",
       "        0.63051206, 0.62353453, 0.62990697, 0.63784888, 0.64295439,\n",
       "        0.62168142, 0.63743287, 0.63104152, 0.63531503, 0.62325089,\n",
       "        0.63486121, 0.63028515, 0.62175705, 0.63355646, 0.61665154,\n",
       "        0.6291695 , 0.62716512, 0.62620074, 0.64717117, 0.63858634,\n",
       "        0.63278118, 0.63629831, 0.63826488, 0.62650329, 0.6338401 ,\n",
       "        0.64242493, 0.6273353 , 0.61754028, 0.63089025, 0.62913168,\n",
       "        0.61742682, 0.64026927, 0.63461538, 0.61665154, 0.63970199,\n",
       "        0.6452046 , 0.61841011, 0.62584146, 0.62724075, 0.63370774,\n",
       "        0.6332161 , 0.62086832, 0.63036079, 0.63593904, 0.62966115,\n",
       "        0.63431284, 0.63858634, 0.62258906, 0.63143862, 0.61436351,\n",
       "        0.62500945, 0.64874064, 0.63557976, 0.63340519, 0.60878527,\n",
       "        0.63183572, 0.64346494, 0.62296725, 0.62030104, 0.6411391 ,\n",
       "        0.63013388]),\n",
       " 'mean_test_score': array([0.64761096, 0.64852585, 0.65090297, 0.65208304, 0.65230153,\n",
       "        0.65127234, 0.65118274, 0.6506377 , 0.65177529, 0.64997133,\n",
       "        0.64793516, 0.64766203, 0.64474757, 0.64616714, 0.64593731,\n",
       "        0.64717486, 0.64232823, 0.64360928, 0.64239219, 0.64058749,\n",
       "        0.63701374, 0.64121878, 0.64242811, 0.64175861, 0.64245415,\n",
       "        0.64177739, 0.64386805, 0.64259257, 0.64168122, 0.64180239,\n",
       "        0.64299267, 0.64173558, 0.63476216, 0.63875731, 0.64117303,\n",
       "        0.63836649, 0.63527579, 0.63550378, 0.63935703, 0.64125876,\n",
       "        0.6381557 , 0.64151635, 0.63394879, 0.63530565, 0.6364926 ,\n",
       "        0.64589762, 0.64499578, 0.6396215 , 0.63739219, 0.6437903 ,\n",
       "        0.63503058, 0.64017649, 0.63335278, 0.6316632 , 0.64374334,\n",
       "        0.64458893, 0.64119496, 0.64035592, 0.63463554, 0.63364953,\n",
       "        0.64130872, 0.62938475, 0.63387609, 0.647504  , 0.64174749,\n",
       "        0.63950548, 0.63970012, 0.64023479, 0.63253168, 0.6347563 ,\n",
       "        0.63017537, 0.6337674 , 0.6455813 , 0.63916787, 0.63984759,\n",
       "        0.64376184, 0.64459024, 0.64277059, 0.63684973, 0.64120209,\n",
       "        0.63305084]),\n",
       " 'std_test_score': array([0.01927322, 0.01956923, 0.0190335 , 0.01889748, 0.01849048,\n",
       "        0.02050576, 0.0231312 , 0.02336001, 0.02453061, 0.02888262,\n",
       "        0.02758834, 0.03036659, 0.03191411, 0.02703031, 0.0298481 ,\n",
       "        0.03040473, 0.02415472, 0.02476889, 0.02849588, 0.02944002,\n",
       "        0.03097564, 0.03437198, 0.02966505, 0.0286248 , 0.02988242,\n",
       "        0.02418968, 0.0252932 , 0.03157678, 0.03102595, 0.034253  ,\n",
       "        0.02501337, 0.02900822, 0.02966401, 0.0209533 , 0.02400728,\n",
       "        0.02721488, 0.02827563, 0.02633955, 0.02661112, 0.01762311,\n",
       "        0.02458341, 0.02658517, 0.01979312, 0.0213179 , 0.02116805,\n",
       "        0.02237327, 0.02845433, 0.02791986, 0.02143585, 0.03021049,\n",
       "        0.02744843, 0.02853115, 0.02007378, 0.02914687, 0.02165293,\n",
       "        0.02029563, 0.02366283, 0.01884778, 0.02512692, 0.02798082,\n",
       "        0.02143736, 0.02211329, 0.01960286, 0.02283453, 0.02245801,\n",
       "        0.01455771, 0.01824662, 0.02732278, 0.02735534, 0.02797934,\n",
       "        0.02000225, 0.02107869, 0.01935355, 0.02063494, 0.02695207,\n",
       "        0.02818712, 0.01755852, 0.02383102, 0.02384273, 0.02123802,\n",
       "        0.01991591]),\n",
       " 'rank_test_score': array([12,  9,  6,  2,  1,  4,  5,  7,  3,  8, 10, 11, 20, 15, 16, 14, 34,\n",
       "        27, 33, 48, 62, 44, 32, 37, 31, 36, 23, 30, 40, 35, 28, 39, 69, 58,\n",
       "        47, 59, 67, 65, 56, 43, 60, 41, 72, 66, 64, 17, 19, 54, 61, 24, 68,\n",
       "        51, 76, 79, 26, 22, 46, 49, 71, 75, 42, 81, 73, 13, 38, 55, 53, 50,\n",
       "        78, 70, 80, 74, 18, 57, 52, 25, 21, 29, 63, 45, 77])}"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch1.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:08:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'mean_fit_time': array([1.29450064, 1.35703187, 1.30870318, 1.17358313, 1.2200448 ,\n",
       "         1.37775064, 1.25058193, 1.20548854, 1.22828074, 1.14615927]),\n",
       "  'std_fit_time': array([0.01871787, 0.13179628, 0.15883482, 0.0069903 , 0.10386065,\n",
       "         0.11388048, 0.02302355, 0.00977679, 0.12776886, 0.3938971 ]),\n",
       "  'mean_score_time': array([0.01013741, 0.00861335, 0.01141787, 0.01040468, 0.01000395,\n",
       "         0.01279922, 0.01058207, 0.00840831, 0.00829778, 0.00739684]),\n",
       "  'std_score_time': array([0.00397752, 0.0010227 , 0.00276584, 0.00150835, 0.00209385,\n",
       "         0.00324164, 0.00280259, 0.00135624, 0.0015278 , 0.00102197]),\n",
       "  'param_max_depth': masked_array(data=[2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_min_child_weight': masked_array(data=[6.025, 6.026, 6.027, 6.028, 6.029, 6.03, 6.031, 6.032,\n",
       "                     6.033, 6.034],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'max_depth': 2, 'min_child_weight': 6.025},\n",
       "   {'max_depth': 2, 'min_child_weight': 6.026},\n",
       "   {'max_depth': 2, 'min_child_weight': 6.027},\n",
       "   {'max_depth': 2, 'min_child_weight': 6.028},\n",
       "   {'max_depth': 2, 'min_child_weight': 6.029},\n",
       "   {'max_depth': 2, 'min_child_weight': 6.03},\n",
       "   {'max_depth': 2, 'min_child_weight': 6.031},\n",
       "   {'max_depth': 2, 'min_child_weight': 6.032},\n",
       "   {'max_depth': 2, 'min_child_weight': 6.033},\n",
       "   {'max_depth': 2, 'min_child_weight': 6.034}],\n",
       "  'split0_test_score': array([0.66668517, 0.66670368, 0.67419868, 0.67419868, 0.67419868,\n",
       "         0.67419868, 0.67419868, 0.67419868, 0.67466134, 0.67466134]),\n",
       "  'split1_test_score': array([0.58072396, 0.58418462, 0.58418462, 0.58418462, 0.58418462,\n",
       "         0.58418462, 0.58418462, 0.58418462, 0.58418462, 0.58418462]),\n",
       "  'split2_test_score': array([0.50882745, 0.50882745, 0.50882745, 0.50882745, 0.50882745,\n",
       "         0.50882745, 0.50882745, 0.50882745, 0.50882745, 0.50882745]),\n",
       "  'split3_test_score': array([0.71570805, 0.71570805, 0.71570805, 0.71570805, 0.71570805,\n",
       "         0.71570805, 0.71570805, 0.71570805, 0.71570805, 0.71570805]),\n",
       "  'split4_test_score': array([0.67403213, 0.67403213, 0.67403213, 0.67403213, 0.67403213,\n",
       "         0.67403213, 0.67403213, 0.67377304, 0.67377304, 0.67377304]),\n",
       "  'mean_test_score': array([0.62919535, 0.62989118, 0.63139018, 0.63139018, 0.63139018,\n",
       "         0.63139018, 0.63139018, 0.63133837, 0.6314309 , 0.6314309 ]),\n",
       "  'std_test_score': array([0.07448245, 0.07404544, 0.07484704, 0.07484704, 0.07484704,\n",
       "         0.07484704, 0.07484704, 0.07481758, 0.0748708 , 0.0748708 ]),\n",
       "  'rank_test_score': array([10,  9,  3,  3,  3,  3,  3,  8,  1,  1])},\n",
       " {'max_depth': 2, 'min_child_weight': 6.033},\n",
       " 0.6314308979199053)"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test2 = {\n",
    " 'max_depth':[2],\n",
    " 'min_child_weight':[i/1000.0 for i in range(6025,6035)]\n",
    "}\n",
    "gsearch2 = GridSearchCV(estimator = XGBClassifier( learning_rate=0.1, n_estimators=140, max_depth=1,\n",
    " min_child_weight=1, gamma=0, subsample=0.79, colsample_bytree=0.93,reg_alpha=0.1086,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test2, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch2.fit(X,y)\n",
    "gsearch2.cv_results_, gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:09:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'mean_fit_time': array([0.0145762 , 0.01575742, 0.01296539, 0.01718225, 0.01791186,\n",
       "         1.31445489, 1.24004755, 1.23427696, 1.22817998, 1.28840237,\n",
       "         1.22558765, 1.16580334, 1.40215306, 1.16023436, 1.16878395,\n",
       "         1.2891789 , 1.3552772 ]),\n",
       "  'std_fit_time': array([0.00184208, 0.00369966, 0.00178531, 0.00791544, 0.00460621,\n",
       "         0.19709741, 0.15463248, 0.1523133 , 0.12144875, 0.15532396,\n",
       "         0.11748955, 0.01236883, 0.11907587, 0.00905165, 0.01082869,\n",
       "         0.10323876, 0.03853755]),\n",
       "  'mean_score_time': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.0092844 , 0.00910583, 0.00871038, 0.00842061, 0.0105988 ,\n",
       "         0.00859833, 0.00900774, 0.00881267, 0.00820847, 0.00898485,\n",
       "         0.01260095, 0.00830812]),\n",
       "  'std_score_time': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.00247433, 0.00079978, 0.00165849, 0.00049042, 0.00293279,\n",
       "         0.00187348, 0.00109245, 0.00080174, 0.00038292, 0.00141652,\n",
       "         0.00293206, 0.00108325]),\n",
       "  'param_gamma': masked_array(data=[-0.005, -0.004, -0.003, -0.002, -0.001, 0.0, 0.001,\n",
       "                     0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008,\n",
       "                     0.009000000000000001, 0.01, 0.011],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'gamma': -0.005},\n",
       "   {'gamma': -0.004},\n",
       "   {'gamma': -0.003},\n",
       "   {'gamma': -0.002},\n",
       "   {'gamma': -0.001},\n",
       "   {'gamma': 0.0},\n",
       "   {'gamma': 0.001},\n",
       "   {'gamma': 0.002},\n",
       "   {'gamma': 0.003},\n",
       "   {'gamma': 0.004},\n",
       "   {'gamma': 0.005},\n",
       "   {'gamma': 0.006},\n",
       "   {'gamma': 0.007},\n",
       "   {'gamma': 0.008},\n",
       "   {'gamma': 0.009000000000000001},\n",
       "   {'gamma': 0.01},\n",
       "   {'gamma': 0.011}],\n",
       "  'split0_test_score': array([      nan,       nan,       nan,       nan,       nan, 0.6688275,\n",
       "         0.6688275, 0.6688275, 0.6688275, 0.6688275, 0.6688275, 0.6688275,\n",
       "         0.6688275, 0.6688275, 0.6688275, 0.6688275, 0.6688275]),\n",
       "  'split1_test_score': array([       nan,        nan,        nan,        nan,        nan,\n",
       "         0.67755843, 0.67755843, 0.67755843, 0.67755843, 0.67755843,\n",
       "         0.67755843, 0.67755843, 0.67755843, 0.67755843, 0.67755843,\n",
       "         0.67755843, 0.67755843]),\n",
       "  'split2_test_score': array([       nan,        nan,        nan,        nan,        nan,\n",
       "         0.64463732, 0.64463732, 0.64463732, 0.64463732, 0.64463732,\n",
       "         0.64463732, 0.64463732, 0.64463732, 0.64463732, 0.64463732,\n",
       "         0.64463732, 0.64463732]),\n",
       "  'split3_test_score': array([       nan,        nan,        nan,        nan,        nan,\n",
       "         0.68557598, 0.68557598, 0.68557598, 0.68557598, 0.68557598,\n",
       "         0.68557598, 0.68557598, 0.68557598, 0.68557598, 0.68557598,\n",
       "         0.68557598, 0.68557598]),\n",
       "  'split4_test_score': array([       nan,        nan,        nan,        nan,        nan,\n",
       "         0.63631722, 0.63631722, 0.63631722, 0.63631722, 0.63631722,\n",
       "         0.63631722, 0.63631722, 0.63631722, 0.63631722, 0.63631722,\n",
       "         0.63631722, 0.63631722]),\n",
       "  'mean_test_score': array([       nan,        nan,        nan,        nan,        nan,\n",
       "         0.66258329, 0.66258329, 0.66258329, 0.66258329, 0.66258329,\n",
       "         0.66258329, 0.66258329, 0.66258329, 0.66258329, 0.66258329,\n",
       "         0.66258329, 0.66258329]),\n",
       "  'std_test_score': array([       nan,        nan,        nan,        nan,        nan,\n",
       "         0.01899407, 0.01899407, 0.01899407, 0.01899407, 0.01899407,\n",
       "         0.01899407, 0.01899407, 0.01899407, 0.01899407, 0.01899407,\n",
       "         0.01899407, 0.01899407]),\n",
       "  'rank_test_score': array([17, 16, 15, 14, 13,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1])},\n",
       " {'gamma': 0.0},\n",
       " 0.6625832894463143)"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test3 = {\n",
    " 'gamma':[i*0.001 for i in range(-5,12)]\n",
    "}\n",
    "gsearch3 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=2,\n",
    " min_child_weight=6.033, subsample=0.79, colsample_bytree=0.93, reg_alpha=0.1086,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test3, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch3.fit(X_train,y_train)\n",
    "gsearch3.cv_results_, gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Accuracy : 0.68\n",
      "AUC Score (Train): 0.701389\n"
     ]
    }
   ],
   "source": [
    "xgb10 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=2,\n",
    " min_child_weight=6.033,\n",
    " gamma=0.0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb10, X_train,y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:45:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'mean_fit_time': array([1.26627402, 1.00409985, 0.99650245, 0.97895164, 1.23459444,\n",
       "         0.98205485, 1.04549909, 1.08139973, 1.38679805, 1.10398383,\n",
       "         1.11196852, 1.2815403 , 1.23438306, 1.18087277, 1.20039673,\n",
       "         1.44989667, 1.22787409, 1.2853199 , 1.51392207, 1.36769586,\n",
       "         1.43600912, 1.99363232, 1.64759092, 1.73790154, 2.04005423,\n",
       "         1.49838686, 1.74135466, 1.69679666, 1.85404139, 1.68988428,\n",
       "         1.54763775, 2.11828914, 3.44746933, 2.31169767, 2.53572116,\n",
       "         4.26136069]),\n",
       "  'std_fit_time': array([0.13618429, 0.02141388, 0.0206384 , 0.0069247 , 0.10133148,\n",
       "         0.01609119, 0.02000364, 0.00700649, 0.13348603, 0.00646279,\n",
       "         0.00594077, 0.11664273, 0.0596438 , 0.01308375, 0.00928489,\n",
       "         0.11652959, 0.02701388, 0.06550828, 0.13115106, 0.12721747,\n",
       "         0.21209854, 0.15610192, 0.06734094, 0.06764347, 0.27991544,\n",
       "         0.0174275 , 0.19215256, 0.14268544, 0.10630699, 0.1579774 ,\n",
       "         0.01243392, 0.3889141 , 0.51735636, 0.17981125, 0.5312038 ,\n",
       "         0.59592097]),\n",
       "  'mean_score_time': array([0.01137753, 0.00981073, 0.00801163, 0.00969396, 0.01161489,\n",
       "         0.00941086, 0.009407  , 0.00900803, 0.00928431, 0.00791545,\n",
       "         0.00978818, 0.01180387, 0.00849962, 0.00919976, 0.00859547,\n",
       "         0.00879984, 0.00879164, 0.0093946 , 0.00861034, 0.00869784,\n",
       "         0.01101012, 0.01218915, 0.0098052 , 0.01149554, 0.00952616,\n",
       "         0.01179781, 0.00759687, 0.00939536, 0.00880718, 0.00860877,\n",
       "         0.00861034, 0.01499209, 0.01181464, 0.0302238 , 0.01230245,\n",
       "         0.0083786 ]),\n",
       "  'std_score_time': array([0.00184029, 0.00213502, 0.00063121, 0.00074527, 0.00421072,\n",
       "         0.00047543, 0.00286543, 0.00141061, 0.00107138, 0.00101324,\n",
       "         0.00147468, 0.00369878, 0.0007899 , 0.00248193, 0.00163014,\n",
       "         0.00114903, 0.00172494, 0.00204518, 0.00079523, 0.00176513,\n",
       "         0.0029011 , 0.00437344, 0.00312165, 0.00258098, 0.00168445,\n",
       "         0.00711682, 0.00080892, 0.00051339, 0.0013261 , 0.00101486,\n",
       "         0.00048939, 0.00536372, 0.00129912, 0.04093804, 0.00262998,\n",
       "         0.00101662]),\n",
       "  'param_colsample_bytree': masked_array(data=[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.6, 0.6, 0.6, 0.6, 0.6,\n",
       "                     0.6, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.8, 0.8, 0.8, 0.8,\n",
       "                     0.8, 0.8, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 1.0, 1.0, 1.0,\n",
       "                     1.0, 1.0, 1.0],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_subsample': masked_array(data=[0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 0.5, 0.6, 0.7, 0.8, 0.9,\n",
       "                     1.0, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 0.5, 0.6, 0.7, 0.8,\n",
       "                     0.9, 1.0, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 0.5, 0.6, 0.7,\n",
       "                     0.8, 0.9, 1.0],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'colsample_bytree': 0.5, 'subsample': 0.5},\n",
       "   {'colsample_bytree': 0.5, 'subsample': 0.6},\n",
       "   {'colsample_bytree': 0.5, 'subsample': 0.7},\n",
       "   {'colsample_bytree': 0.5, 'subsample': 0.8},\n",
       "   {'colsample_bytree': 0.5, 'subsample': 0.9},\n",
       "   {'colsample_bytree': 0.5, 'subsample': 1.0},\n",
       "   {'colsample_bytree': 0.6, 'subsample': 0.5},\n",
       "   {'colsample_bytree': 0.6, 'subsample': 0.6},\n",
       "   {'colsample_bytree': 0.6, 'subsample': 0.7},\n",
       "   {'colsample_bytree': 0.6, 'subsample': 0.8},\n",
       "   {'colsample_bytree': 0.6, 'subsample': 0.9},\n",
       "   {'colsample_bytree': 0.6, 'subsample': 1.0},\n",
       "   {'colsample_bytree': 0.7, 'subsample': 0.5},\n",
       "   {'colsample_bytree': 0.7, 'subsample': 0.6},\n",
       "   {'colsample_bytree': 0.7, 'subsample': 0.7},\n",
       "   {'colsample_bytree': 0.7, 'subsample': 0.8},\n",
       "   {'colsample_bytree': 0.7, 'subsample': 0.9},\n",
       "   {'colsample_bytree': 0.7, 'subsample': 1.0},\n",
       "   {'colsample_bytree': 0.8, 'subsample': 0.5},\n",
       "   {'colsample_bytree': 0.8, 'subsample': 0.6},\n",
       "   {'colsample_bytree': 0.8, 'subsample': 0.7},\n",
       "   {'colsample_bytree': 0.8, 'subsample': 0.8},\n",
       "   {'colsample_bytree': 0.8, 'subsample': 0.9},\n",
       "   {'colsample_bytree': 0.8, 'subsample': 1.0},\n",
       "   {'colsample_bytree': 0.9, 'subsample': 0.5},\n",
       "   {'colsample_bytree': 0.9, 'subsample': 0.6},\n",
       "   {'colsample_bytree': 0.9, 'subsample': 0.7},\n",
       "   {'colsample_bytree': 0.9, 'subsample': 0.8},\n",
       "   {'colsample_bytree': 0.9, 'subsample': 0.9},\n",
       "   {'colsample_bytree': 0.9, 'subsample': 1.0},\n",
       "   {'colsample_bytree': 1.0, 'subsample': 0.5},\n",
       "   {'colsample_bytree': 1.0, 'subsample': 0.6},\n",
       "   {'colsample_bytree': 1.0, 'subsample': 0.7},\n",
       "   {'colsample_bytree': 1.0, 'subsample': 0.8},\n",
       "   {'colsample_bytree': 1.0, 'subsample': 0.9},\n",
       "   {'colsample_bytree': 1.0, 'subsample': 1.0}],\n",
       "  'split0_test_score': array([0.60950107, 0.63450292, 0.63613147, 0.64423718, 0.6380191 ,\n",
       "         0.67447628, 0.61553409, 0.6577837 , 0.60261677, 0.61806944,\n",
       "         0.63206011, 0.66420534, 0.62258494, 0.6353357 , 0.62939522,\n",
       "         0.63513213, 0.62817381, 0.66550078, 0.62458361, 0.65700644,\n",
       "         0.63692723, 0.67188541, 0.63141239, 0.68100896, 0.637723  ,\n",
       "         0.65857947, 0.6266563 , 0.66753646, 0.65215782, 0.6838219 ,\n",
       "         0.62269598, 0.66189207, 0.64203494, 0.66563032, 0.65041824,\n",
       "         0.67199645]),\n",
       "  'split1_test_score': array([0.58196388, 0.57713376, 0.57502406, 0.57820712, 0.56973129,\n",
       "         0.57489451, 0.5766526 , 0.58405507, 0.56001555, 0.58535051,\n",
       "         0.56055222, 0.5760604 , 0.57037901, 0.58821897, 0.56399437,\n",
       "         0.5760604 , 0.56832482, 0.56793619, 0.5694537 , 0.586831  ,\n",
       "         0.57147087, 0.57583833, 0.56027463, 0.5667703 , 0.57613443,\n",
       "         0.59786069, 0.58461026, 0.58514694, 0.57944704, 0.58224147,\n",
       "         0.5757458 , 0.58543378, 0.58607225, 0.57705974, 0.5796321 ,\n",
       "         0.57541269]),\n",
       "  'split2_test_score': array([0.50631061, 0.49487379, 0.50198016, 0.50579243, 0.4940225 ,\n",
       "         0.5021097 , 0.50051817, 0.51056703, 0.50847583, 0.51452735,\n",
       "         0.49591013, 0.50793915, 0.50048116, 0.51208454, 0.50549634,\n",
       "         0.52289215, 0.50333111, 0.49798283, 0.51930195, 0.5020912 ,\n",
       "         0.50708787, 0.52392849, 0.49616922, 0.49091347, 0.51323192,\n",
       "         0.50064772, 0.5021097 , 0.50856836, 0.51582278, 0.49267155,\n",
       "         0.52098601, 0.50608853, 0.5125842 , 0.51837664, 0.51201051,\n",
       "         0.50166556]),\n",
       "  'split3_test_score': array([0.6673514 , 0.66216966, 0.67092309, 0.68295211, 0.71789178,\n",
       "         0.70515952, 0.6706455 , 0.66433489, 0.67727071, 0.70290177,\n",
       "         0.70132874, 0.71293212, 0.67582723, 0.66128137, 0.66746243,\n",
       "         0.66133689, 0.70145829, 0.70256866, 0.66940558, 0.66242875,\n",
       "         0.67327337, 0.68889259, 0.69738693, 0.69359316, 0.65939374,\n",
       "         0.67144126, 0.6832482 , 0.67591976, 0.71731808, 0.7014953 ,\n",
       "         0.66222518, 0.68074987, 0.67473536, 0.69411133, 0.68600563,\n",
       "         0.69150196]),\n",
       "  'split4_test_score': array([0.64170183, 0.63030202, 0.65857947, 0.6820268 , 0.64525502,\n",
       "         0.64875268, 0.637723  , 0.62834037, 0.64658746, 0.67108964,\n",
       "         0.6455141 , 0.6637612 , 0.65430454, 0.64786439, 0.66315049,\n",
       "         0.65587756, 0.64090606, 0.6640573 , 0.64323784, 0.62878451,\n",
       "         0.66191058, 0.66089274, 0.63311496, 0.65558146, 0.65543341,\n",
       "         0.640721  , 0.66681472, 0.66202162, 0.64762381, 0.6571915 ,\n",
       "         0.62534236, 0.62789622, 0.65876453, 0.66966467, 0.64103561,\n",
       "         0.64408913]),\n",
       "  'mean_test_score': array([0.60136576, 0.59979643, 0.60852765, 0.61864313, 0.61298394,\n",
       "         0.62107854, 0.60021467, 0.60901621, 0.59899326, 0.61838774,\n",
       "         0.60707306, 0.62497964, 0.60471537, 0.60895699, 0.60589977,\n",
       "         0.61025983, 0.60843882, 0.61960915, 0.60519654, 0.60742838,\n",
       "         0.61013398, 0.62428751, 0.60367163, 0.61757347, 0.6083833 ,\n",
       "         0.61385003, 0.61268784, 0.61983863, 0.62247391, 0.62348434,\n",
       "         0.60139907, 0.6124121 , 0.61483826, 0.62496854, 0.61382042,\n",
       "         0.61693316]),\n",
       "  'std_test_score': array([0.05560432, 0.05924172, 0.06266611, 0.06808603, 0.0757581 ,\n",
       "         0.0734484 , 0.05847499, 0.05679286, 0.06019695, 0.06602825,\n",
       "         0.0714249 , 0.0733074 , 0.06305404, 0.05433562, 0.06238037,\n",
       "         0.05312474, 0.0674581 , 0.07540161, 0.0540393 , 0.05909193,\n",
       "         0.06244776, 0.06355875, 0.06907834, 0.07729344, 0.05616114,\n",
       "         0.06182224, 0.0649915 , 0.06447351, 0.06889825, 0.07703955,\n",
       "         0.04868471, 0.06227456, 0.05922873, 0.06646644, 0.06135938,\n",
       "         0.06977175]),\n",
       "  'rank_test_score': array([33, 35, 23,  9, 16,  6, 34, 21, 36, 10, 27,  1, 30, 22, 28, 19, 24,\n",
       "          8, 29, 26, 20,  3, 31, 11, 25, 14, 17,  7,  5,  4, 32, 18, 13,  2,\n",
       "         15, 12])},\n",
       " {'colsample_bytree': 0.6, 'subsample': 1.0},\n",
       " 0.624979643200829)"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test4 = {\n",
    " 'subsample':[i/10.0 for i in range(5,11)],\n",
    " 'colsample_bytree':[i/10.0 for i in range(5,11)]\n",
    "}\n",
    "gsearch4 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=177, max_depth=2,\n",
    " min_child_weight=6.033, gamma=0.0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test4, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch4.fit(X,y)\n",
    "gsearch4.cv_results_, gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'colsample_bytree': 0.62, 'subsample': 0.95}, 0.6255385298689762)"
      ]
     },
     "execution_count": 590,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test5 = {\n",
    " 'subsample':[i/100.0 for i in range(95,105)], #0.79\n",
    " 'colsample_bytree':[i/100.0 for i in range(55,65)] #0.92\n",
    "}\n",
    "gsearch5 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=177, max_depth=2,\n",
    " min_child_weight=6.033, gamma=0.0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test5, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch5.fit(X,y)\n",
    "gsearch5.best_params_, gsearch5.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:29:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'colsample_bytree': 0.612, 'subsample': 0.951}, 0.6255385298689762)"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test15 = {\n",
    " 'subsample':[i/1000.0 for i in range(945,955)], #0.79\n",
    " 'colsample_bytree':[i/1000.0 for i in range(610,616)] #0.92\n",
    "}\n",
    "gsearch15 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=177, max_depth=2,\n",
    " min_child_weight=6.033, gamma=0.0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test15, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch15.fit(X,y)\n",
    "gsearch15.best_params_, gsearch5.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:35:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'colsample_bytree': 0.612, 'subsample': 0.9512}, 0.6255385298689762)"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test16 = {\n",
    " 'subsample':[i/10000.0 for i in range(9505,9515)], #0.79\n",
    " 'colsample_bytree':[i/10000.0 for i in range(6115,6125)] #0.92\n",
    "}\n",
    "gsearch16 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=177, max_depth=2,\n",
    " min_child_weight=6.033, gamma=0.0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test16, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch16.fit(X,y)\n",
    "gsearch16.best_params_, gsearch5.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([1.09367537, 1.06535139, 1.19739838, 1.07572331, 1.02326565,\n",
       "        0.97200069, 0.08118124, 0.013165  , 0.01276603, 0.01276689,\n",
       "        1.66874018, 1.60929546, 1.34260979, 1.94280548, 1.39167838,\n",
       "        1.15092211, 0.0111692 , 0.0117681 , 0.01057096, 0.01037183,\n",
       "        1.35218325, 1.18044438, 1.06116161, 1.06834431, 1.67432384,\n",
       "        1.05617328, 0.01176786, 0.01216688, 0.0119679 , 0.01216712,\n",
       "        1.06754513, 1.16628208, 1.18961883, 1.10963216, 1.16608138,\n",
       "        1.29254489, 0.01136913, 0.01037173, 0.0115685 , 0.01515975,\n",
       "        1.24108129, 1.16348877, 1.22193136, 1.31608   , 1.16987109,\n",
       "        1.31448536, 0.0145607 , 0.01396213, 0.01456037, 0.01316481,\n",
       "        1.59573483, 1.24327497, 1.18164001, 1.39287248, 1.33303547,\n",
       "        1.15211844, 0.0115675 , 0.0111701 , 0.01176767, 0.01116982,\n",
       "        1.92804556, 2.50929136, 2.59727015, 2.03028126, 2.00826144,\n",
       "        1.94606628, 0.01356359, 0.01476092, 0.01616354, 0.02134323,\n",
       "        1.62984734, 1.72944078, 1.55294456, 1.92438569, 2.15830741,\n",
       "        1.46122026, 0.01579299, 0.01740217, 0.01827912, 0.01858916,\n",
       "        2.14745493, 1.37859015, 1.7206399 , 1.63398867, 1.55271592,\n",
       "        1.5407517 , 0.01938848, 0.01618838, 0.01839743, 0.01879334,\n",
       "        1.31401033, 1.19958344, 1.47327714, 2.05457492, 2.10338278,\n",
       "        3.13343906, 0.02218146, 0.01610327, 0.01470323, 0.02000694]),\n",
       " 'std_fit_time': array([1.02218828e-02, 2.91482918e-02, 1.50330884e-01, 1.19144164e-01,\n",
       "        1.43137828e-02, 3.56575982e-01, 1.36940781e-01, 2.03358730e-03,\n",
       "        9.76921722e-04, 1.16312181e-03, 4.40651136e-01, 4.92637086e-01,\n",
       "        4.30974341e-01, 5.18533315e-01, 7.40250285e-02, 6.59956718e-02,\n",
       "        7.46034646e-04, 1.71581719e-03, 4.88577656e-04, 4.88305129e-04,\n",
       "        1.57541173e-01, 1.30828080e-01, 5.27758411e-03, 1.22379420e-02,\n",
       "        2.44364513e-01, 3.06762432e-02, 1.46529836e-03, 3.99280801e-04,\n",
       "        6.31128070e-04, 3.99041414e-04, 1.32403080e-02, 1.12334960e-01,\n",
       "        1.35633750e-01, 4.56801217e-02, 3.42676871e-02, 1.94472799e-01,\n",
       "        1.01720538e-03, 4.89161892e-04, 2.72052988e-03, 1.71563428e-03,\n",
       "        1.21149352e-01, 1.61389938e-02, 5.59707375e-02, 1.14597442e-01,\n",
       "        2.19505093e-02, 9.65772840e-02, 4.89201275e-04, 1.26195446e-03,\n",
       "        2.99782036e-03, 1.46590881e-03, 2.28750026e-01, 1.30318048e-01,\n",
       "        4.54255515e-02, 2.16260791e-01, 2.24683680e-01, 2.70602953e-02,\n",
       "        4.89806298e-04, 7.45920337e-04, 1.16336655e-03, 3.98803281e-04,\n",
       "        7.39833286e-01, 5.82391999e-01, 8.01971586e-02, 3.01124900e-01,\n",
       "        2.09133604e-01, 2.19588597e-01, 1.19692498e-03, 2.39336110e-03,\n",
       "        1.12636922e-03, 7.48026268e-03, 1.47429385e-01, 1.91351280e-01,\n",
       "        4.35069478e-02, 3.40148181e-01, 3.88628821e-01, 1.27284839e-01,\n",
       "        3.48121287e-03, 4.83846019e-03, 2.44370882e-03, 2.83105533e-03,\n",
       "        3.89791025e-01, 9.76084213e-02, 2.24639257e-01, 7.46807530e-02,\n",
       "        1.24465805e-01, 2.47328199e-01, 3.93900659e-03, 3.42698512e-03,\n",
       "        2.63628614e-03, 2.99331644e-03, 1.36875968e-01, 9.76850275e-03,\n",
       "        3.30683545e-01, 4.74266696e-01, 4.28632931e-01, 4.87366944e-01,\n",
       "        1.01638706e-02, 2.97357177e-03, 1.94496455e-03, 5.61035522e-03]),\n",
       " 'mean_score_time': array([0.01775308, 0.01077161, 0.01057186, 0.0109715 , 0.01037064,\n",
       "        0.00957532, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.02293892, 0.01216798, 0.00897622, 0.01077156, 0.01137009,\n",
       "        0.0085793 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.01117191, 0.00917516, 0.0091763 , 0.00917559, 0.00957685,\n",
       "        0.00738239, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00718102, 0.00997376, 0.00758009, 0.00917602, 0.0091763 ,\n",
       "        0.009374  , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00817819, 0.00837817, 0.00917625, 0.00797939, 0.0083786 ,\n",
       "        0.00857697, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.01156888, 0.00777955, 0.00957513, 0.00797863, 0.00817776,\n",
       "        0.00797954, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00977445, 0.01576056, 0.01266775, 0.0095747 , 0.01705942,\n",
       "        0.01096992, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00917587, 0.00967956, 0.00878315, 0.01327791, 0.00989943,\n",
       "        0.00998077, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0088068 , 0.0099967 , 0.01037617, 0.00861335, 0.01162124,\n",
       "        0.00968566, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00799999, 0.00820765, 0.00871119, 0.00980582, 0.01111751,\n",
       "        0.0130856 , 0.        , 0.        , 0.        , 0.        ]),\n",
       " 'std_score_time': array([0.00589731, 0.00247542, 0.00286318, 0.00295831, 0.00184997,\n",
       "        0.00257004, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.02246139, 0.00291805, 0.00199454, 0.00336171, 0.00444233,\n",
       "        0.00119696, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00317949, 0.00311463, 0.00097688, 0.00116319, 0.00241124,\n",
       "        0.00048969, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00039883, 0.00109249, 0.00079819, 0.0009767 , 0.00159615,\n",
       "        0.00161924, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00039818, 0.00048879, 0.00116373, 0.00063068, 0.00079806,\n",
       "        0.00101702, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00622963, 0.00074615, 0.00241001, 0.00109206, 0.00039911,\n",
       "        0.0008925 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00230921, 0.00318023, 0.00291551, 0.00119771, 0.00897602,\n",
       "        0.00244297, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00074614, 0.00153678, 0.001159  , 0.00348623, 0.00198062,\n",
       "        0.00302038, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00171528, 0.00208902, 0.00391832, 0.00047272, 0.00232708,\n",
       "        0.00118345, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00095372, 0.00041032, 0.00058749, 0.00159474, 0.0022639 ,\n",
       "        0.00653447, 0.        , 0.        , 0.        , 0.        ]),\n",
       " 'param_colsample_bytree': masked_array(data=[0.55, 0.55, 0.55, 0.55, 0.55, 0.55, 0.55, 0.55, 0.55,\n",
       "                    0.55, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56,\n",
       "                    0.56, 0.56, 0.57, 0.57, 0.57, 0.57, 0.57, 0.57, 0.57,\n",
       "                    0.57, 0.57, 0.57, 0.58, 0.58, 0.58, 0.58, 0.58, 0.58,\n",
       "                    0.58, 0.58, 0.58, 0.58, 0.59, 0.59, 0.59, 0.59, 0.59,\n",
       "                    0.59, 0.59, 0.59, 0.59, 0.59, 0.6, 0.6, 0.6, 0.6, 0.6,\n",
       "                    0.6, 0.6, 0.6, 0.6, 0.6, 0.61, 0.61, 0.61, 0.61, 0.61,\n",
       "                    0.61, 0.61, 0.61, 0.61, 0.61, 0.62, 0.62, 0.62, 0.62,\n",
       "                    0.62, 0.62, 0.62, 0.62, 0.62, 0.62, 0.63, 0.63, 0.63,\n",
       "                    0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.64, 0.64,\n",
       "                    0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_subsample': masked_array(data=[0.95, 0.96, 0.97, 0.98, 0.99, 1.0, 1.01, 1.02, 1.03,\n",
       "                    1.04, 0.95, 0.96, 0.97, 0.98, 0.99, 1.0, 1.01, 1.02,\n",
       "                    1.03, 1.04, 0.95, 0.96, 0.97, 0.98, 0.99, 1.0, 1.01,\n",
       "                    1.02, 1.03, 1.04, 0.95, 0.96, 0.97, 0.98, 0.99, 1.0,\n",
       "                    1.01, 1.02, 1.03, 1.04, 0.95, 0.96, 0.97, 0.98, 0.99,\n",
       "                    1.0, 1.01, 1.02, 1.03, 1.04, 0.95, 0.96, 0.97, 0.98,\n",
       "                    0.99, 1.0, 1.01, 1.02, 1.03, 1.04, 0.95, 0.96, 0.97,\n",
       "                    0.98, 0.99, 1.0, 1.01, 1.02, 1.03, 1.04, 0.95, 0.96,\n",
       "                    0.97, 0.98, 0.99, 1.0, 1.01, 1.02, 1.03, 1.04, 0.95,\n",
       "                    0.96, 0.97, 0.98, 0.99, 1.0, 1.01, 1.02, 1.03, 1.04,\n",
       "                    0.95, 0.96, 0.97, 0.98, 0.99, 1.0, 1.01, 1.02, 1.03,\n",
       "                    1.04],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'colsample_bytree': 0.55, 'subsample': 0.95},\n",
       "  {'colsample_bytree': 0.55, 'subsample': 0.96},\n",
       "  {'colsample_bytree': 0.55, 'subsample': 0.97},\n",
       "  {'colsample_bytree': 0.55, 'subsample': 0.98},\n",
       "  {'colsample_bytree': 0.55, 'subsample': 0.99},\n",
       "  {'colsample_bytree': 0.55, 'subsample': 1.0},\n",
       "  {'colsample_bytree': 0.55, 'subsample': 1.01},\n",
       "  {'colsample_bytree': 0.55, 'subsample': 1.02},\n",
       "  {'colsample_bytree': 0.55, 'subsample': 1.03},\n",
       "  {'colsample_bytree': 0.55, 'subsample': 1.04},\n",
       "  {'colsample_bytree': 0.56, 'subsample': 0.95},\n",
       "  {'colsample_bytree': 0.56, 'subsample': 0.96},\n",
       "  {'colsample_bytree': 0.56, 'subsample': 0.97},\n",
       "  {'colsample_bytree': 0.56, 'subsample': 0.98},\n",
       "  {'colsample_bytree': 0.56, 'subsample': 0.99},\n",
       "  {'colsample_bytree': 0.56, 'subsample': 1.0},\n",
       "  {'colsample_bytree': 0.56, 'subsample': 1.01},\n",
       "  {'colsample_bytree': 0.56, 'subsample': 1.02},\n",
       "  {'colsample_bytree': 0.56, 'subsample': 1.03},\n",
       "  {'colsample_bytree': 0.56, 'subsample': 1.04},\n",
       "  {'colsample_bytree': 0.57, 'subsample': 0.95},\n",
       "  {'colsample_bytree': 0.57, 'subsample': 0.96},\n",
       "  {'colsample_bytree': 0.57, 'subsample': 0.97},\n",
       "  {'colsample_bytree': 0.57, 'subsample': 0.98},\n",
       "  {'colsample_bytree': 0.57, 'subsample': 0.99},\n",
       "  {'colsample_bytree': 0.57, 'subsample': 1.0},\n",
       "  {'colsample_bytree': 0.57, 'subsample': 1.01},\n",
       "  {'colsample_bytree': 0.57, 'subsample': 1.02},\n",
       "  {'colsample_bytree': 0.57, 'subsample': 1.03},\n",
       "  {'colsample_bytree': 0.57, 'subsample': 1.04},\n",
       "  {'colsample_bytree': 0.58, 'subsample': 0.95},\n",
       "  {'colsample_bytree': 0.58, 'subsample': 0.96},\n",
       "  {'colsample_bytree': 0.58, 'subsample': 0.97},\n",
       "  {'colsample_bytree': 0.58, 'subsample': 0.98},\n",
       "  {'colsample_bytree': 0.58, 'subsample': 0.99},\n",
       "  {'colsample_bytree': 0.58, 'subsample': 1.0},\n",
       "  {'colsample_bytree': 0.58, 'subsample': 1.01},\n",
       "  {'colsample_bytree': 0.58, 'subsample': 1.02},\n",
       "  {'colsample_bytree': 0.58, 'subsample': 1.03},\n",
       "  {'colsample_bytree': 0.58, 'subsample': 1.04},\n",
       "  {'colsample_bytree': 0.59, 'subsample': 0.95},\n",
       "  {'colsample_bytree': 0.59, 'subsample': 0.96},\n",
       "  {'colsample_bytree': 0.59, 'subsample': 0.97},\n",
       "  {'colsample_bytree': 0.59, 'subsample': 0.98},\n",
       "  {'colsample_bytree': 0.59, 'subsample': 0.99},\n",
       "  {'colsample_bytree': 0.59, 'subsample': 1.0},\n",
       "  {'colsample_bytree': 0.59, 'subsample': 1.01},\n",
       "  {'colsample_bytree': 0.59, 'subsample': 1.02},\n",
       "  {'colsample_bytree': 0.59, 'subsample': 1.03},\n",
       "  {'colsample_bytree': 0.59, 'subsample': 1.04},\n",
       "  {'colsample_bytree': 0.6, 'subsample': 0.95},\n",
       "  {'colsample_bytree': 0.6, 'subsample': 0.96},\n",
       "  {'colsample_bytree': 0.6, 'subsample': 0.97},\n",
       "  {'colsample_bytree': 0.6, 'subsample': 0.98},\n",
       "  {'colsample_bytree': 0.6, 'subsample': 0.99},\n",
       "  {'colsample_bytree': 0.6, 'subsample': 1.0},\n",
       "  {'colsample_bytree': 0.6, 'subsample': 1.01},\n",
       "  {'colsample_bytree': 0.6, 'subsample': 1.02},\n",
       "  {'colsample_bytree': 0.6, 'subsample': 1.03},\n",
       "  {'colsample_bytree': 0.6, 'subsample': 1.04},\n",
       "  {'colsample_bytree': 0.61, 'subsample': 0.95},\n",
       "  {'colsample_bytree': 0.61, 'subsample': 0.96},\n",
       "  {'colsample_bytree': 0.61, 'subsample': 0.97},\n",
       "  {'colsample_bytree': 0.61, 'subsample': 0.98},\n",
       "  {'colsample_bytree': 0.61, 'subsample': 0.99},\n",
       "  {'colsample_bytree': 0.61, 'subsample': 1.0},\n",
       "  {'colsample_bytree': 0.61, 'subsample': 1.01},\n",
       "  {'colsample_bytree': 0.61, 'subsample': 1.02},\n",
       "  {'colsample_bytree': 0.61, 'subsample': 1.03},\n",
       "  {'colsample_bytree': 0.61, 'subsample': 1.04},\n",
       "  {'colsample_bytree': 0.62, 'subsample': 0.95},\n",
       "  {'colsample_bytree': 0.62, 'subsample': 0.96},\n",
       "  {'colsample_bytree': 0.62, 'subsample': 0.97},\n",
       "  {'colsample_bytree': 0.62, 'subsample': 0.98},\n",
       "  {'colsample_bytree': 0.62, 'subsample': 0.99},\n",
       "  {'colsample_bytree': 0.62, 'subsample': 1.0},\n",
       "  {'colsample_bytree': 0.62, 'subsample': 1.01},\n",
       "  {'colsample_bytree': 0.62, 'subsample': 1.02},\n",
       "  {'colsample_bytree': 0.62, 'subsample': 1.03},\n",
       "  {'colsample_bytree': 0.62, 'subsample': 1.04},\n",
       "  {'colsample_bytree': 0.63, 'subsample': 0.95},\n",
       "  {'colsample_bytree': 0.63, 'subsample': 0.96},\n",
       "  {'colsample_bytree': 0.63, 'subsample': 0.97},\n",
       "  {'colsample_bytree': 0.63, 'subsample': 0.98},\n",
       "  {'colsample_bytree': 0.63, 'subsample': 0.99},\n",
       "  {'colsample_bytree': 0.63, 'subsample': 1.0},\n",
       "  {'colsample_bytree': 0.63, 'subsample': 1.01},\n",
       "  {'colsample_bytree': 0.63, 'subsample': 1.02},\n",
       "  {'colsample_bytree': 0.63, 'subsample': 1.03},\n",
       "  {'colsample_bytree': 0.63, 'subsample': 1.04},\n",
       "  {'colsample_bytree': 0.64, 'subsample': 0.95},\n",
       "  {'colsample_bytree': 0.64, 'subsample': 0.96},\n",
       "  {'colsample_bytree': 0.64, 'subsample': 0.97},\n",
       "  {'colsample_bytree': 0.64, 'subsample': 0.98},\n",
       "  {'colsample_bytree': 0.64, 'subsample': 0.99},\n",
       "  {'colsample_bytree': 0.64, 'subsample': 1.0},\n",
       "  {'colsample_bytree': 0.64, 'subsample': 1.01},\n",
       "  {'colsample_bytree': 0.64, 'subsample': 1.02},\n",
       "  {'colsample_bytree': 0.64, 'subsample': 1.03},\n",
       "  {'colsample_bytree': 0.64, 'subsample': 1.04}],\n",
       " 'split0_test_score': array([0.64862314, 0.62802576, 0.6359279 , 0.66311348, 0.67131172,\n",
       "        0.66742542,        nan,        nan,        nan,        nan,\n",
       "        0.65276852, 0.66559331, 0.64386705, 0.67220001, 0.66068917,\n",
       "        0.66335406,        nan,        nan,        nan,        nan,\n",
       "        0.64680953, 0.63368865, 0.63774151, 0.65378636, 0.67584573,\n",
       "        0.66920201,        nan,        nan,        nan,        nan,\n",
       "        0.64680953, 0.63368865, 0.63774151, 0.65378636, 0.67584573,\n",
       "        0.66920201,        nan,        nan,        nan,        nan,\n",
       "        0.6628729 , 0.6404064 , 0.6458102 , 0.66244726, 0.65641424,\n",
       "        0.66139241,        nan,        nan,        nan,        nan,\n",
       "        0.6476053 , 0.65014065, 0.64925235, 0.6616885 , 0.6622807 ,\n",
       "        0.66420534,        nan,        nan,        nan,        nan,\n",
       "        0.6476053 , 0.65014065, 0.64925235, 0.6616885 , 0.6622807 ,\n",
       "        0.66420534,        nan,        nan,        nan,        nan,\n",
       "        0.66231771, 0.6727552 , 0.64468132, 0.64545858, 0.67220001,\n",
       "        0.65974535,        nan,        nan,        nan,        nan,\n",
       "        0.6503072 , 0.66846177, 0.64725368, 0.66655563, 0.65176919,\n",
       "        0.65578503,        nan,        nan,        nan,        nan,\n",
       "        0.6503072 , 0.66846177, 0.64725368, 0.66655563, 0.65176919,\n",
       "        0.65578503,        nan,        nan,        nan,        nan]),\n",
       " 'split1_test_score': array([0.59097639, 0.57308091, 0.58620179, 0.56414242, 0.57158191,\n",
       "        0.56417944,        nan,        nan,        nan,        nan,\n",
       "        0.59264194, 0.57778148, 0.59267895, 0.56171811, 0.57448738,\n",
       "        0.57506107,        nan,        nan,        nan,        nan,\n",
       "        0.58797838, 0.57748538, 0.58697905, 0.56351321, 0.57937301,\n",
       "        0.57169295,        nan,        nan,        nan,        nan,\n",
       "        0.58797838, 0.57748538, 0.58697905, 0.56351321, 0.57937301,\n",
       "        0.57169295,        nan,        nan,        nan,        nan,\n",
       "        0.57852173, 0.59675031, 0.57829965, 0.56440151, 0.57687468,\n",
       "        0.57805907,        nan,        nan,        nan,        nan,\n",
       "        0.58190836, 0.58994004, 0.57622696, 0.57343253, 0.57163743,\n",
       "        0.5760604 ,        nan,        nan,        nan,        nan,\n",
       "        0.58190836, 0.58994004, 0.57622696, 0.57343253, 0.57163743,\n",
       "        0.5760604 ,        nan,        nan,        nan,        nan,\n",
       "        0.58485084, 0.58240802, 0.57752239, 0.57781849, 0.56456807,\n",
       "        0.57121178,        nan,        nan,        nan,        nan,\n",
       "        0.58355541, 0.57915094, 0.5631801 , 0.58490636, 0.55394552,\n",
       "        0.57550522,        nan,        nan,        nan,        nan,\n",
       "        0.58355541, 0.57915094, 0.5631801 , 0.58490636, 0.55394552,\n",
       "        0.57550522,        nan,        nan,        nan,        nan]),\n",
       " 'split2_test_score': array([0.492505  , 0.50551484, 0.49966689, 0.50005552, 0.49922274,\n",
       "        0.48543564,        nan,        nan,        nan,        nan,\n",
       "        0.49844548, 0.50025909, 0.4913206 , 0.50705085, 0.50074025,\n",
       "        0.50507069,        nan,        nan,        nan,        nan,\n",
       "        0.49690947, 0.49263454, 0.49385595, 0.50736546, 0.50257236,\n",
       "        0.49927826,        nan,        nan,        nan,        nan,\n",
       "        0.49690947, 0.49263454, 0.49385595, 0.50736546, 0.50257236,\n",
       "        0.49927826,        nan,        nan,        nan,        nan,\n",
       "        0.50123991, 0.51145533, 0.51158487, 0.49987046, 0.50433045,\n",
       "        0.49776075,        nan,        nan,        nan,        nan,\n",
       "        0.4982049 , 0.50947516, 0.50455252, 0.49846399, 0.49468873,\n",
       "        0.50793915,        nan,        nan,        nan,        nan,\n",
       "        0.4982049 , 0.50947516, 0.50455252, 0.49846399, 0.49468873,\n",
       "        0.50793915,        nan,        nan,        nan,        nan,\n",
       "        0.50185062, 0.50914205, 0.51576727, 0.50444148, 0.49800133,\n",
       "        0.50305352,        nan,        nan,        nan,        nan,\n",
       "        0.51162188, 0.4997039 , 0.50012954, 0.50603302, 0.49657636,\n",
       "        0.48885928,        nan,        nan,        nan,        nan,\n",
       "        0.51162188, 0.4997039 , 0.50012954, 0.50603302, 0.49657636,\n",
       "        0.48885928,        nan,        nan,        nan,        nan]),\n",
       " 'split3_test_score': array([0.71652232, 0.7122844 , 0.71152565, 0.68150862, 0.67097861,\n",
       "        0.69059516,        nan,        nan,        nan,        nan,\n",
       "        0.69623954, 0.70562218, 0.71208083, 0.70651047, 0.70825006,\n",
       "        0.68680139,        nan,        nan,        nan,        nan,\n",
       "        0.72142646, 0.71818787, 0.71202532, 0.69722037, 0.68254497,\n",
       "        0.70314235,        nan,        nan,        nan,        nan,\n",
       "        0.72142646, 0.71818787, 0.71202532, 0.69722037, 0.68254497,\n",
       "        0.70314235,        nan,        nan,        nan,        nan,\n",
       "        0.71232142, 0.69455548, 0.69492561, 0.71461618, 0.70643645,\n",
       "        0.70691761,        nan,        nan,        nan,        nan,\n",
       "        0.69616552, 0.69055815, 0.71461618, 0.70495596, 0.70201347,\n",
       "        0.71293212,        nan,        nan,        nan,        nan,\n",
       "        0.69616552, 0.69055815, 0.71461618, 0.70495596, 0.70201347,\n",
       "        0.71293212,        nan,        nan,        nan,        nan,\n",
       "        0.70886076, 0.6760493 , 0.69474054, 0.69226072, 0.70638093,\n",
       "        0.71750315,        nan,        nan,        nan,        nan,\n",
       "        0.71409801, 0.71752165, 0.68150862, 0.69496262, 0.7039011 ,\n",
       "        0.70027389,        nan,        nan,        nan,        nan,\n",
       "        0.71409801, 0.71752165, 0.68150862, 0.69496262, 0.7039011 ,\n",
       "        0.70027389,        nan,        nan,        nan,        nan]),\n",
       " 'split4_test_score': array([0.6736435 , 0.6613739 , 0.66276186, 0.66202162, 0.65782071,\n",
       "        0.63959212,        nan,        nan,        nan,        nan,\n",
       "        0.67804797, 0.67070101, 0.66914649, 0.65759864, 0.64667999,\n",
       "        0.64608779,        nan,        nan,        nan,        nan,\n",
       "        0.672163  , 0.66183655, 0.65391591, 0.64823451, 0.66683322,\n",
       "        0.64708713,        nan,        nan,        nan,        nan,\n",
       "        0.672163  , 0.66183655, 0.65391591, 0.64823451, 0.66683322,\n",
       "        0.64708713,        nan,        nan,        nan,        nan,\n",
       "        0.6682582 , 0.66461248, 0.65558146, 0.65500777, 0.64597676,\n",
       "        0.64118366,        nan,        nan,        nan,        nan,\n",
       "        0.67893626, 0.63790806, 0.66170701, 0.64908579, 0.65091791,\n",
       "        0.6637612 ,        nan,        nan,        nan,        nan,\n",
       "        0.67893626, 0.63790806, 0.66170701, 0.64908579, 0.65091791,\n",
       "        0.6637612 ,        nan,        nan,        nan,        nan,\n",
       "        0.66981272, 0.63361463, 0.65237989, 0.64408913, 0.66126286,\n",
       "        0.66953512,        nan,        nan,        nan,        nan,\n",
       "        0.66313199, 0.66124436, 0.66031905, 0.64510697, 0.64296025,\n",
       "        0.6583944 ,        nan,        nan,        nan,        nan,\n",
       "        0.66313199, 0.66124436, 0.66031905, 0.64510697, 0.64296025,\n",
       "        0.6583944 ,        nan,        nan,        nan,        nan]),\n",
       " 'mean_test_score': array([0.62445407, 0.61605596, 0.61921682, 0.61416833, 0.61418314,\n",
       "        0.60944555,        nan,        nan,        nan,        nan,\n",
       "        0.62362869, 0.62399141, 0.62181879, 0.62101562, 0.61816937,\n",
       "        0.615275  ,        nan,        nan,        nan,        nan,\n",
       "        0.62505737, 0.6167666 , 0.61690355, 0.61402398, 0.62143386,\n",
       "        0.61808054,        nan,        nan,        nan,        nan,\n",
       "        0.62505737, 0.6167666 , 0.61690355, 0.61402398, 0.62143386,\n",
       "        0.61808054,        nan,        nan,        nan,        nan,\n",
       "        0.62464283, 0.621556  , 0.61724036, 0.61926864, 0.61800651,\n",
       "        0.6170627 ,        nan,        nan,        nan,        nan,\n",
       "        0.62056407, 0.61560441, 0.621271  , 0.61752535, 0.61630765,\n",
       "        0.62497964,        nan,        nan,        nan,        nan,\n",
       "        0.62056407, 0.61560441, 0.621271  , 0.61752535, 0.61630765,\n",
       "        0.62497964,        nan,        nan,        nan,        nan,\n",
       "        0.62553853, 0.61479384, 0.61701828, 0.61281368, 0.62048264,\n",
       "        0.62420979,        nan,        nan,        nan,        nan,\n",
       "        0.6245429 , 0.62521652, 0.6104782 , 0.61951292, 0.60983048,\n",
       "        0.61576357,        nan,        nan,        nan,        nan,\n",
       "        0.6245429 , 0.62521652, 0.6104782 , 0.61951292, 0.60983048,\n",
       "        0.61576357,        nan,        nan,        nan,        nan]),\n",
       " 'std_test_score': array([0.07747467, 0.07144662, 0.07221984, 0.07034857, 0.06844618,\n",
       "        0.07521066,        nan,        nan,        nan,        nan,\n",
       "        0.07171323, 0.07486138, 0.07583163, 0.07452743, 0.07270906,\n",
       "        0.06654201,        nan,        nan,        nan,        nan,\n",
       "        0.07716973, 0.07688396, 0.07333277, 0.06870287, 0.07021893,\n",
       "        0.07342491,        nan,        nan,        nan,        nan,\n",
       "        0.07716973, 0.07688396, 0.07333277, 0.06870287, 0.07021893,\n",
       "        0.07342491,        nan,        nan,        nan,        nan,\n",
       "        0.07537481, 0.06367983, 0.06480854, 0.07681036, 0.07027292,\n",
       "        0.07262931,        nan,        nan,        nan,        nan,\n",
       "        0.07255364, 0.06201668, 0.07318951, 0.07308945, 0.07408572,\n",
       "        0.0733074 ,        nan,        nan,        nan,        nan,\n",
       "        0.07255364, 0.06201668, 0.07318951, 0.07308945, 0.07408572,\n",
       "        0.0733074 ,        nan,        nan,        nan,        nan,\n",
       "        0.0737695 , 0.06273295, 0.06303671, 0.06530677, 0.07725845,\n",
       "        0.07682245,        nan,        nan,        nan,        nan,\n",
       "        0.07014865, 0.07689454, 0.06825804, 0.06728452, 0.07437116,\n",
       "        0.07521507,        nan,        nan,        nan,        nan,\n",
       "        0.07014865, 0.07689454, 0.06825804, 0.06728452, 0.07437116,\n",
       "        0.07521507,        nan,        nan,        nan,        nan]),\n",
       " 'rank_test_score': array([ 11,  44,  28,  52,  51,  60,  73,  74,  75,  76,  14,  13,  15,\n",
       "         21,  29,  49,  77,  78,  79,  80,   4,  40,  38,  53,  17,  30,\n",
       "         81,  82,  83,  84,   4,  40,  38,  53,  17,  30,  86,  99,  87,\n",
       "         88,   8,  16,  35,  27,  32,  36,  89,  90,  91,  71,  22,  47,\n",
       "         19,  33,  42,   6,  93,  94,  95,  96,  22,  47,  19,  33,  42,\n",
       "          6,  97,  98,  72,  85,   1,  50,  37,  55,  24,  12,  70,  61,\n",
       "         62,  63,   9,   2,  56,  25,  58,  45,  65,  66,  67,  68,   9,\n",
       "          2,  56,  25,  58,  45,  69,  64,  92, 100])}"
      ]
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch5.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Accuracy : 0.76\n",
      "AUC Score (Train): 0.833333\n"
     ]
    }
   ],
   "source": [
    "xgb15 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=177,\n",
    " max_depth=2,\n",
    " min_child_weight=6.033,\n",
    " gamma=0.0,\n",
    " subsample=0.9512,\n",
    " colsample_bytree=0.612,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb15, X,y, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:50:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'reg_alpha': 1e-05}, 0.6323710119179806)"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test6 = {\n",
    " 'reg_alpha':[1e-5, 1e-2,0.0, 0.1, 1, 100]\n",
    "}\n",
    "gsearch6 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=177, max_depth=2,\n",
    " min_child_weight=6.033, gamma=0.0, subsample=0.9512, colsample_bytree=0.612,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test6, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch6.fit(X,y)\n",
    "gsearch6.best_params_, gsearch6.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:52:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'reg_alpha': 0.0}, 0.6323710119179806)"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test7 = {\n",
    " 'reg_alpha':[i*0.000001 for i in range(0,11)] #0.1086\n",
    "}\n",
    "gsearch7 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=177, max_depth=2,\n",
    " min_child_weight=6.033, gamma=0.0, subsample=0.9512, colsample_bytree=0.612,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test7, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch7.fit(X,y)\n",
    "gsearch7.best_params_, gsearch7.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Accuracy : 0.76\n",
      "AUC Score (Train): 0.854167\n"
     ]
    }
   ],
   "source": [
    "xgb3 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=2,\n",
    " min_child_weight=6.033,\n",
    " gamma=0.0,\n",
    " subsample=0.9512,\n",
    " colsample_bytree=0.612,\n",
    " reg_alpha=0.0,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb3, X,y, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:06:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'reg_lambda': 1}, 0.6323710119179806)"
      ]
     },
     "execution_count": 618,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test8 = {\n",
    " 'reg_lambda':[1e-5, 1e-6,0.0, 0.1, 1, 10, 2 , 1.5, 6, 4, 100]\n",
    "}\n",
    "gsearch8 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=177, max_depth=2,\n",
    " min_child_weight=6.033, gamma=0.0, subsample=0.9512, colsample_bytree=0.612,reg_lambda = 0.1,reg_alpha=0.0,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test8, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch8.fit(X,y)\n",
    "gsearch8.best_params_, gsearch8.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:05:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'reg_lambda': 1.00042}, 0.6328632763342956)"
      ]
     },
     "execution_count": 617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test9 = {\n",
    " 'reg_lambda':[i*0.00001 for i in range(100040,100046)]\n",
    "}\n",
    "gsearch9 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=177, max_depth=2,\n",
    " min_child_weight=6.033, gamma=0.0, subsample=0.9512, colsample_bytree=0.612,reg_lambda = 0.1,reg_alpha=0.0,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test9, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch9.fit(X,y)\n",
    "gsearch9.best_params_, gsearch9.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test9 = {\n",
    " 'reg_lambda':[i*0.000001 for i in range(0,11)]\n",
    "}\n",
    "gsearch9 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=177, max_depth=2,\n",
    " min_child_weight=8, gamma=0.0, subsample=0.926, colsample_bytree=0.79,reg_lambda = 0.1,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test9, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch9.fit(X,y)\n",
    "gsearch9.best_params_, gsearch9.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test10 = {\n",
    " 'learning_rate':[i*0.000001 for i in range(50000,50001)],\n",
    " 'n_estimators':[7000],\n",
    "}\n",
    "gsearch10 = GridSearchCV(estimator = XGBClassifier( max_depth=2,\n",
    " min_child_weight=6.033, gamma=0.0, subsample=0.9512, colsample_bytree=0.612,reg_alpha=0.0,reg_lambda = 1.00042,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test10, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch10.fit(X,y)\n",
    "gsearch10.best_params_, gsearch10.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Accuracy : 0.68\n",
      "AUC Score (Train): 0.770833\n"
     ]
    }
   ],
   "source": [
    "xgb4 = XGBClassifier(\n",
    " learning_rate =0.005,\n",
    " n_estimators=7000,\n",
    " max_depth=2,\n",
    " min_child_weight=6.033,\n",
    " gamma=0.0,\n",
    " subsample=0.9512,\n",
    " colsample_bytree=0.612,\n",
    " reg_alpha=0.10857,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb4, X,y, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_xgb = Pipeline([('scalar1', StandardScaler()),\n",
    "                         ('pca1', PCA(n_components=2) ),\n",
    "                         ('xgb_classifier', XGBClassifier(\n",
    " learning_rate =0.005,\n",
    " n_estimators=7000,\n",
    " max_depth=2,\n",
    " min_child_weight=6.033,\n",
    " gamma=0.0,\n",
    " subsample=0.9512,\n",
    " colsample_bytree=0.612,\n",
    " reg_alpha=0.10857,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:44:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scalar1',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('pca1',\n",
       "                 PCA(copy=True, iterated_power='auto', n_components=2,\n",
       "                     random_state=None, svd_solver='auto', tol=0.0,\n",
       "                     whiten=False)),\n",
       "                ('xgb_classifier',\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=0.612, gamma=0.0, g...\n",
       "                               max_delta_step=0, max_depth=2,\n",
       "                               min_child_weight=6.033, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=7000,\n",
       "                               n_jobs=4, nthread=4, num_parallel_tree=1,\n",
       "                               objective='binary:logistic', random_state=27,\n",
       "                               reg_alpha=0.10857, reg_lambda=1,\n",
       "                               scale_pos_weight=1, seed=27, subsample=0.9512,\n",
       "                               tree_method='exact', use_label_encoder=True,\n",
       "                               validate_parameters=1, verbosity=None))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_xgb.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_xgb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1591\n"
     ]
    }
   ],
   "source": [
    "predicted_y = pipeline_xgb.predict(X_Sample_Test)\n",
    "predicted_y = list(predicted_y)\n",
    "w_list = []\n",
    "for j in range(len(predicted_y)):\n",
    "    w_list.append({\"Id\":(j+1), \"Category\":predicted_y[j]})\n",
    "print(len(w_list))\n",
    "with open('predictions'+'.csv', 'w', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=[\"Id\", \"Category\"])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(w_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base')",
   "language": "python",
   "name": "python37664bitbase3d920d87e3644dc8a79788ca4d0afcae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

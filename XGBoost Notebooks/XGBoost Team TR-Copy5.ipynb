{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set() # if you want to use seaborn themes with matplotlib functions\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('CSE_DSIntro1_TRAIN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_state = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Column_1</th>\n",
       "      <th>Column_2</th>\n",
       "      <th>Column_3</th>\n",
       "      <th>Column_4</th>\n",
       "      <th>Column_5</th>\n",
       "      <th>Column_6</th>\n",
       "      <th>Column_7</th>\n",
       "      <th>Column_8</th>\n",
       "      <th>Column_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Column_69</th>\n",
       "      <th>Column_70</th>\n",
       "      <th>Column_71</th>\n",
       "      <th>Column_72</th>\n",
       "      <th>Column_73</th>\n",
       "      <th>Column_74</th>\n",
       "      <th>Column_75</th>\n",
       "      <th>Column_76</th>\n",
       "      <th>Column_77</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>77041.5</td>\n",
       "      <td>44471.03389</td>\n",
       "      <td>88955.41342</td>\n",
       "      <td>1602.4632</td>\n",
       "      <td>1787.3628</td>\n",
       "      <td>1571.6466</td>\n",
       "      <td>1294.2972</td>\n",
       "      <td>1664.0964</td>\n",
       "      <td>1756.5462</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>77120.0</td>\n",
       "      <td>44516.34682</td>\n",
       "      <td>89046.05288</td>\n",
       "      <td>1573.2480</td>\n",
       "      <td>2128.5120</td>\n",
       "      <td>987.1360</td>\n",
       "      <td>956.2880</td>\n",
       "      <td>1511.5520</td>\n",
       "      <td>1388.1600</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>77120.0</td>\n",
       "      <td>44516.34682</td>\n",
       "      <td>89046.05288</td>\n",
       "      <td>1789.1840</td>\n",
       "      <td>1511.5520</td>\n",
       "      <td>1665.7920</td>\n",
       "      <td>1326.4640</td>\n",
       "      <td>1357.3120</td>\n",
       "      <td>1634.9440</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>77117.5</td>\n",
       "      <td>44514.90373</td>\n",
       "      <td>89043.16628</td>\n",
       "      <td>1511.5030</td>\n",
       "      <td>1789.1260</td>\n",
       "      <td>1233.8800</td>\n",
       "      <td>1881.6670</td>\n",
       "      <td>1418.9620</td>\n",
       "      <td>2159.2900</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>77120.0</td>\n",
       "      <td>44516.34682</td>\n",
       "      <td>89046.05288</td>\n",
       "      <td>1974.2720</td>\n",
       "      <td>1696.6400</td>\n",
       "      <td>832.8960</td>\n",
       "      <td>1820.0320</td>\n",
       "      <td>1758.3360</td>\n",
       "      <td>1727.4880</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>2496</td>\n",
       "      <td>77117.5</td>\n",
       "      <td>44514.90373</td>\n",
       "      <td>89043.16628</td>\n",
       "      <td>1203.0330</td>\n",
       "      <td>2282.6780</td>\n",
       "      <td>1542.3500</td>\n",
       "      <td>1758.2790</td>\n",
       "      <td>1850.8200</td>\n",
       "      <td>1295.5740</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>42</td>\n",
       "      <td>33</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>2497</td>\n",
       "      <td>77120.0</td>\n",
       "      <td>44516.34682</td>\n",
       "      <td>89046.05288</td>\n",
       "      <td>894.5920</td>\n",
       "      <td>1203.0720</td>\n",
       "      <td>1079.6800</td>\n",
       "      <td>1480.7040</td>\n",
       "      <td>1449.8560</td>\n",
       "      <td>1604.0960</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>42</td>\n",
       "      <td>34</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>2498</td>\n",
       "      <td>77117.5</td>\n",
       "      <td>44514.90373</td>\n",
       "      <td>89043.16628</td>\n",
       "      <td>1789.1260</td>\n",
       "      <td>1604.0440</td>\n",
       "      <td>1326.4210</td>\n",
       "      <td>1418.9620</td>\n",
       "      <td>1542.3500</td>\n",
       "      <td>1511.5030</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>42</td>\n",
       "      <td>34</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>2499</td>\n",
       "      <td>77117.5</td>\n",
       "      <td>44514.90373</td>\n",
       "      <td>89043.16628</td>\n",
       "      <td>1789.1260</td>\n",
       "      <td>524.3990</td>\n",
       "      <td>1511.5030</td>\n",
       "      <td>1357.2680</td>\n",
       "      <td>863.7160</td>\n",
       "      <td>616.9400</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>42</td>\n",
       "      <td>35</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>2500</td>\n",
       "      <td>77120.0</td>\n",
       "      <td>44516.34682</td>\n",
       "      <td>89046.05288</td>\n",
       "      <td>1542.4000</td>\n",
       "      <td>1789.1840</td>\n",
       "      <td>1850.8800</td>\n",
       "      <td>1511.5520</td>\n",
       "      <td>1758.3360</td>\n",
       "      <td>1326.4640</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>42</td>\n",
       "      <td>35</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows Ã— 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  Column_1     Column_2     Column_3   Column_4   Column_5  \\\n",
       "0        1   77041.5  44471.03389  88955.41342  1602.4632  1787.3628   \n",
       "1        2   77120.0  44516.34682  89046.05288  1573.2480  2128.5120   \n",
       "2        3   77120.0  44516.34682  89046.05288  1789.1840  1511.5520   \n",
       "3        4   77117.5  44514.90373  89043.16628  1511.5030  1789.1260   \n",
       "4        5   77120.0  44516.34682  89046.05288  1974.2720  1696.6400   \n",
       "...    ...       ...          ...          ...        ...        ...   \n",
       "2495  2496   77117.5  44514.90373  89043.16628  1203.0330  2282.6780   \n",
       "2496  2497   77120.0  44516.34682  89046.05288   894.5920  1203.0720   \n",
       "2497  2498   77117.5  44514.90373  89043.16628  1789.1260  1604.0440   \n",
       "2498  2499   77117.5  44514.90373  89043.16628  1789.1260   524.3990   \n",
       "2499  2500   77120.0  44516.34682  89046.05288  1542.4000  1789.1840   \n",
       "\n",
       "       Column_6   Column_7   Column_8   Column_9  ...  Column_69  Column_70  \\\n",
       "0     1571.6466  1294.2972  1664.0964  1756.5462  ...         22          2   \n",
       "1      987.1360   956.2880  1511.5520  1388.1600  ...         22          2   \n",
       "2     1665.7920  1326.4640  1357.3120  1634.9440  ...         22          2   \n",
       "3     1233.8800  1881.6670  1418.9620  2159.2900  ...         22          2   \n",
       "4      832.8960  1820.0320  1758.3360  1727.4880  ...         22          2   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "2495  1542.3500  1758.2790  1850.8200  1295.5740  ...         22          2   \n",
       "2496  1079.6800  1480.7040  1449.8560  1604.0960  ...         22          2   \n",
       "2497  1326.4210  1418.9620  1542.3500  1511.5030  ...         22          2   \n",
       "2498  1511.5030  1357.2680   863.7160   616.9400  ...         22          2   \n",
       "2499  1850.8800  1511.5520  1758.3360  1326.4640  ...         22          2   \n",
       "\n",
       "      Column_71  Column_72  Column_73  Column_74  Column_75  Column_76  \\\n",
       "0          2021         11         23         15         22          2   \n",
       "1          2021         11         23         15         22          2   \n",
       "2          2021         11         23         15         22          2   \n",
       "3          2021         11         23         16         22          2   \n",
       "4          2021         11         23         16         22          2   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "2495       2021         11         42         33         22          2   \n",
       "2496       2021         11         42         34         22          2   \n",
       "2497       2021         11         42         34         22          2   \n",
       "2498       2021         11         42         35         22          2   \n",
       "2499       2021         11         42         35         22          2   \n",
       "\n",
       "      Column_77  Category  \n",
       "0          2021         0  \n",
       "1          2021         0  \n",
       "2          2021         0  \n",
       "3          2021         0  \n",
       "4          2021         0  \n",
       "...         ...       ...  \n",
       "2495       2021         1  \n",
       "2496       2021         1  \n",
       "2497       2021         1  \n",
       "2498       2021         0  \n",
       "2499       2021         0  \n",
       "\n",
       "[2500 rows x 79 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id           0.0\n",
       "Column_1     0.0\n",
       "Column_2     0.0\n",
       "Column_3     0.0\n",
       "Column_4     0.0\n",
       "            ... \n",
       "Column_74    0.0\n",
       "Column_75    0.0\n",
       "Column_76    0.0\n",
       "Column_77    0.0\n",
       "Category     0.0\n",
       "Length: 79, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()/len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(dataset.duplicated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the duplicates:\n",
    "dataset.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 1 Column_55\n",
      "57 1 Column_57\n",
      "66 1 Column_66\n",
      "69 1 Column_69\n",
      "70 1 Column_70\n",
      "71 1 Column_71\n",
      "72 1 Column_72\n",
      "75 1 Column_75\n",
      "76 1 Column_76\n",
      "77 1 Column_77\n"
     ]
    }
   ],
   "source": [
    "unique_values = list(dataset.nunique())\n",
    "for i in range(len(unique_values)):\n",
    "    if unique_values[i] == 1:\n",
    "        print(i, unique_values[i],dataset.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find 55\n",
      "find 57\n",
      "find 66\n",
      "find 69\n",
      "find 70\n",
      "find 71\n",
      "find 72\n",
      "find 75\n",
      "find 76\n",
      "find 77\n",
      "        Id  Column_1     Column_2     Column_3   Column_4   Column_5  \\\n",
      "0        1   77041.5  44471.03389  88955.41342  1602.4632  1787.3628   \n",
      "1        2   77120.0  44516.34682  89046.05288  1573.2480  2128.5120   \n",
      "2        3   77120.0  44516.34682  89046.05288  1789.1840  1511.5520   \n",
      "3        4   77117.5  44514.90373  89043.16628  1511.5030  1789.1260   \n",
      "4        5   77120.0  44516.34682  89046.05288  1974.2720  1696.6400   \n",
      "...    ...       ...          ...          ...        ...        ...   \n",
      "2495  2496   77117.5  44514.90373  89043.16628  1203.0330  2282.6780   \n",
      "2496  2497   77120.0  44516.34682  89046.05288   894.5920  1203.0720   \n",
      "2497  2498   77117.5  44514.90373  89043.16628  1789.1260  1604.0440   \n",
      "2498  2499   77117.5  44514.90373  89043.16628  1789.1260   524.3990   \n",
      "2499  2500   77120.0  44516.34682  89046.05288  1542.4000  1789.1840   \n",
      "\n",
      "       Column_6   Column_7   Column_8   Column_9  ...  Column_61    Column_62  \\\n",
      "0     1571.6466  1294.2972  1664.0964  1756.5462  ...   1.511108  63642.86256   \n",
      "1      987.1360   956.2880  1511.5520  1388.1600  ...   1.511097  63649.22304   \n",
      "2     1665.7920  1326.4640  1357.3120  1634.9440  ...   1.511247  63658.20567   \n",
      "3     1233.8800  1881.6670  1418.9620  2159.2900  ...   1.511245  63655.53620   \n",
      "4      832.8960  1820.0320  1758.3360  1727.4880  ...   1.511409  63637.01387   \n",
      "...         ...        ...        ...        ...  ...        ...          ...   \n",
      "2495  1542.3500  1758.2790  1850.8200  1295.5740  ...   1.511090  63689.52068   \n",
      "2496  1079.6800  1480.7040  1449.8560  1604.0960  ...   1.511129  63696.82226   \n",
      "2497  1326.4210  1418.9620  1542.3500  1511.5030  ...   1.511286  63695.04189   \n",
      "2498  1511.5030  1357.2680   863.7160   616.9400  ...   1.511245  63683.13411   \n",
      "2499  1850.8800  1511.5520  1758.3360  1326.4640  ...   1.511552  63697.79604   \n",
      "\n",
      "      Column_63  Column_64  Column_65  Column_67  Column_68  Column_73  \\\n",
      "0      1.527652   0.073507   1.511320         23         15         23   \n",
      "1      1.527373   0.073794   1.511169         23         15         23   \n",
      "2      1.527631   0.073571   1.511256         23         15         23   \n",
      "3      1.527550   0.073430   1.511489         23         16         23   \n",
      "4      1.527490   0.073543   1.511393         23         16         23   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "2495   1.527730   0.073834   1.510860         42         33         42   \n",
      "2496   1.527971   0.073253   1.511402         42         34         42   \n",
      "2497   1.527891   0.073301   1.511400         42         34         42   \n",
      "2498   1.527758   0.073542   1.511201         42         35         42   \n",
      "2499   1.527767   0.073461   1.511293         42         35         42   \n",
      "\n",
      "      Column_74  Category  \n",
      "0            15         0  \n",
      "1            15         0  \n",
      "2            15         0  \n",
      "3            16         0  \n",
      "4            16         0  \n",
      "...         ...       ...  \n",
      "2495         33         1  \n",
      "2496         34         1  \n",
      "2497         34         1  \n",
      "2498         35         0  \n",
      "2499         35         0  \n",
      "\n",
      "[2500 rows x 69 columns]\n"
     ]
    }
   ],
   "source": [
    "unique_values = list(dataset.nunique())\n",
    "k=0\n",
    "for i in range(len(unique_values)):\n",
    "    if unique_values[i] == 1:\n",
    "        print('find', i)\n",
    "        dataset.drop(dataset.columns[i-k], axis=1 ,inplace=True)\n",
    "        k+=1\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'Column_1', 'Column_2', 'Column_3', 'Column_4', 'Column_5',\n",
       "       'Column_6', 'Column_7', 'Column_8', 'Column_9', 'Column_10',\n",
       "       'Column_11', 'Column_12', 'Column_13', 'Column_14', 'Column_15',\n",
       "       'Column_16', 'Column_17', 'Column_18', 'Column_19', 'Column_20',\n",
       "       'Column_21', 'Column_22', 'Column_23', 'Column_24', 'Column_25',\n",
       "       'Column_26', 'Column_27', 'Column_28', 'Column_29', 'Column_30',\n",
       "       'Column_31', 'Column_32', 'Column_33', 'Column_34', 'Column_35',\n",
       "       'Column_36', 'Column_37', 'Column_38', 'Column_39', 'Column_40',\n",
       "       'Column_41', 'Column_42', 'Column_43', 'Column_44', 'Column_45',\n",
       "       'Column_46', 'Column_47', 'Column_48', 'Column_49', 'Column_50',\n",
       "       'Column_51', 'Column_52', 'Column_53', 'Column_54', 'Column_56',\n",
       "       'Column_58', 'Column_59', 'Column_60', 'Column_61', 'Column_62',\n",
       "       'Column_63', 'Column_64', 'Column_65', 'Column_67', 'Column_68',\n",
       "       'Column_73', 'Column_74', 'Category'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('CSE_DSIntro1_TEST.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 1 Column_55\n",
      "57 1 Column_57\n",
      "66 1 Column_66\n",
      "69 1 Column_69\n",
      "70 1 Column_70\n",
      "71 1 Column_71\n",
      "72 1 Column_72\n",
      "75 1 Column_75\n",
      "76 1 Column_76\n",
      "77 1 Column_77\n"
     ]
    }
   ],
   "source": [
    "unique_values_test = list(test_data.nunique())\n",
    "for i in range(len(unique_values_test)):\n",
    "    if unique_values_test[i] == 1:\n",
    "        print(i, unique_values_test[i],test_data.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find 55\n",
      "find 57\n",
      "find 66\n",
      "find 69\n",
      "find 70\n",
      "find 71\n",
      "find 72\n",
      "find 75\n",
      "find 76\n",
      "find 77\n",
      "        Id  Column_1     Column_2     Column_3   Column_4   Column_5  \\\n",
      "0        1  77117.50  44514.90373  89043.16628  1696.5850  1665.7380   \n",
      "1        2  77120.00  44516.34682  89046.05288  1357.3120   339.3280   \n",
      "2        3  77120.00  44516.34682  89046.05288  1758.3360  1974.2720   \n",
      "3        4  77120.00  44516.34682  89046.05288  1110.5280  1264.7680   \n",
      "4        5  77120.00  44516.34682  89046.05288  2652.9280  2005.1200   \n",
      "...    ...       ...          ...          ...        ...        ...   \n",
      "1586  1587  77120.00  44516.34682  89046.05288  1789.1840  1881.7280   \n",
      "1587  1588  77117.50  44514.90373  89043.16628  1696.5850  1357.2680   \n",
      "1588  1589  77122.25  44517.64560  89048.65083  1696.6895  1727.5384   \n",
      "1589  1590  77122.25  44517.64560  89048.65083  1449.8983  1789.2362   \n",
      "1590  1591  77122.25  44517.64560  89048.65083  1449.8983  1326.5027   \n",
      "\n",
      "       Column_6   Column_7   Column_8   Column_9  ...  Column_60  Column_61  \\\n",
      "0     1418.9620  1264.7270  1203.0330  1573.1970  ...   0.073235   1.511481   \n",
      "1     1326.4640  1017.9840  1573.2480  1604.0960  ...   0.073413   1.511241   \n",
      "2     1480.7040  1141.3760  1542.4000  1388.1600  ...   0.073253   1.511402   \n",
      "3     1388.1600  1449.8560  1573.2480  1419.0080  ...   0.073415   1.511293   \n",
      "4     1943.4240   493.5680  1388.1600   740.3520  ...   0.073395   1.511170   \n",
      "...         ...        ...        ...        ...  ...        ...        ...   \n",
      "1586  1449.8560  1573.2480  1419.0080  1542.4000  ...   0.073209   1.511755   \n",
      "1587  1727.4320  1542.3500  1295.5740  1449.8090  ...   0.073503   1.511498   \n",
      "1588  1573.2939  1449.8983   246.7912  1480.7472  ...   0.073398   1.511532   \n",
      "1589  1634.9917  1203.1071  1326.5027  1357.3516  ...   0.073327   1.511689   \n",
      "1590  1388.2005   154.2445  1480.7472  1048.8626  ...   0.073095   1.511757   \n",
      "\n",
      "        Column_62  Column_63  Column_64  Column_65  Column_67  Column_68  \\\n",
      "0     63697.96460   1.527815   0.073497   1.511214         42         36   \n",
      "1     63707.62973   1.527853   0.073633   1.511019         42         36   \n",
      "2     63699.33986   1.527973   0.073148   1.511530         42         36   \n",
      "3     63691.57205   1.527999   0.073202   1.511444         42         37   \n",
      "4     63691.78617   1.527921   0.073248   1.511445         42         37   \n",
      "...           ...        ...        ...        ...        ...        ...   \n",
      "1586  63656.58449   1.527551   0.073225   1.511742         56          0   \n",
      "1587  63655.56354   1.527707   0.073006   1.511899         56          0   \n",
      "1588  63659.57645   1.527553   0.073222   1.511745         56          1   \n",
      "1589  63638.76254   1.527492   0.073274   1.511726         56          1   \n",
      "1590  63657.61274   1.527457   0.073445   1.511539         56          2   \n",
      "\n",
      "      Column_73  Column_74  \n",
      "0            42         36  \n",
      "1            42         36  \n",
      "2            42         37  \n",
      "3            42         37  \n",
      "4            42         37  \n",
      "...         ...        ...  \n",
      "1586         56          0  \n",
      "1587         56          0  \n",
      "1588         56          1  \n",
      "1589         56          1  \n",
      "1590         56          2  \n",
      "\n",
      "[1591 rows x 68 columns]\n"
     ]
    }
   ],
   "source": [
    "k_test=0\n",
    "for i in range(len(unique_values_test)):\n",
    "    if unique_values_test[i] == 1:\n",
    "        print('find', i)\n",
    "        test_data.drop(test_data.columns[i-k_test], axis=1 ,inplace=True)\n",
    "        k_test+=1\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'Column_1', 'Column_2', 'Column_3', 'Column_4', 'Column_5',\n",
       "       'Column_6', 'Column_7', 'Column_8', 'Column_9', 'Column_10',\n",
       "       'Column_11', 'Column_12', 'Column_13', 'Column_14', 'Column_15',\n",
       "       'Column_16', 'Column_17', 'Column_18', 'Column_19', 'Column_20',\n",
       "       'Column_21', 'Column_22', 'Column_23', 'Column_24', 'Column_25',\n",
       "       'Column_26', 'Column_27', 'Column_28', 'Column_29', 'Column_30',\n",
       "       'Column_31', 'Column_32', 'Column_33', 'Column_34', 'Column_35',\n",
       "       'Column_36', 'Column_37', 'Column_38', 'Column_39', 'Column_40',\n",
       "       'Column_41', 'Column_42', 'Column_43', 'Column_44', 'Column_45',\n",
       "       'Column_46', 'Column_47', 'Column_48', 'Column_49', 'Column_50',\n",
       "       'Column_51', 'Column_52', 'Column_53', 'Column_54', 'Column_56',\n",
       "       'Column_58', 'Column_59', 'Column_60', 'Column_61', 'Column_62',\n",
       "       'Column_63', 'Column_64', 'Column_65', 'Column_67', 'Column_68',\n",
       "       'Column_73', 'Column_74'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 1:-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Sample_Test = test_data.values[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.71175000e+04, 4.45149037e+04, 8.90431663e+04, ...,\n",
       "        3.60000000e+01, 4.20000000e+01, 3.60000000e+01],\n",
       "       [7.71200000e+04, 4.45163468e+04, 8.90460529e+04, ...,\n",
       "        3.60000000e+01, 4.20000000e+01, 3.60000000e+01],\n",
       "       [7.71200000e+04, 4.45163468e+04, 8.90460529e+04, ...,\n",
       "        3.60000000e+01, 4.20000000e+01, 3.70000000e+01],\n",
       "       ...,\n",
       "       [7.71222500e+04, 4.45176456e+04, 8.90486508e+04, ...,\n",
       "        1.00000000e+00, 5.60000000e+01, 1.00000000e+00],\n",
       "       [7.71222500e+04, 4.45176456e+04, 8.90486508e+04, ...,\n",
       "        1.00000000e+00, 5.60000000e+01, 1.00000000e+00],\n",
       "       [7.71222500e+04, 4.45176456e+04, 8.90486508e+04, ...,\n",
       "        2.00000000e+00, 5.60000000e+01, 2.00000000e+00]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Sample_Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.70415000e+04, 4.44710339e+04, 8.89554134e+04, ...,\n",
       "        1.50000000e+01, 2.30000000e+01, 1.50000000e+01],\n",
       "       [7.71200000e+04, 4.45163468e+04, 8.90460529e+04, ...,\n",
       "        1.50000000e+01, 2.30000000e+01, 1.50000000e+01],\n",
       "       [7.71200000e+04, 4.45163468e+04, 8.90460529e+04, ...,\n",
       "        1.50000000e+01, 2.30000000e+01, 1.50000000e+01],\n",
       "       ...,\n",
       "       [7.71175000e+04, 4.45149037e+04, 8.90431663e+04, ...,\n",
       "        3.40000000e+01, 4.20000000e+01, 3.40000000e+01],\n",
       "       [7.71175000e+04, 4.45149037e+04, 8.90431663e+04, ...,\n",
       "        3.50000000e+01, 4.20000000e+01, 3.50000000e+01],\n",
       "       [7.71200000e+04, 4.45163468e+04, 8.90460529e+04, ...,\n",
       "        3.50000000e+01, 4.20000000e+01, 3.50000000e+01]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.01, random_state = rand_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn import  metrics   #Additional scklearn functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelfit(alg, X_train,y_train, X_test, y_test ,useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='auc', early_stopping_rounds=early_stopping_rounds)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(X_train, y_train ,eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(X_test)\n",
    "    dtrain_predprob = alg.predict_proba(X_test)[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"Accuracy : %.4g\" % metrics.accuracy_score(y_test, dtrain_predictions))\n",
    "    print(\"AUC Score (Train): %f\" % metrics.roc_auc_score(y_test, dtrain_predprob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Category'\n",
    "IDcol = 'Id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Accuracy : 0.72\n",
      "AUC Score (Train): 0.729167\n"
     ]
    }
   ],
   "source": [
    "#Choose all predictors except target & IDcols\n",
    "predictors = [x for x in dataset.columns if x not in ['Category', \"Id\"]]\n",
    "xgb1 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=seed)\n",
    "modelfit(xgb1, X_train,y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate =0.1\n",
    "n_estimators=170\n",
    "max_depth=5\n",
    "min_child_weight=1\n",
    "gamma=0.0\n",
    "subsample=0.8\n",
    "colsample_bytree=0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:25:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'mean_fit_time': array([2.20730028, 2.20031562, 2.61480803, 2.17618198, 1.9852921 ,\n",
       "         2.01421442, 2.14207492, 2.32019777, 1.80297818, 2.59446278,\n",
       "         2.60483475, 2.61799903, 2.40776095, 2.49692326, 2.39120555,\n",
       "         2.43209748, 2.28110104, 2.38402557, 3.36959043, 3.23415251,\n",
       "         3.12285008, 3.14658642, 3.1140728 , 3.0151382 , 2.99898105,\n",
       "         3.06340785, 2.85576401, 4.07590199, 3.95462565, 3.74618325,\n",
       "         3.79624987, 3.67198205, 3.48368516, 3.41726308, 3.34306107,\n",
       "         3.33727703, 4.68028574, 4.37390547, 4.25262895, 4.14292216,\n",
       "         4.02782979, 3.89179406, 3.89478607, 3.84352345, 3.48328567,\n",
       "         5.16379313, 4.87217321, 4.67968721, 4.5223084 , 4.32802806,\n",
       "         4.21652603, 4.20615335, 4.23208408, 4.1122046 , 5.51086473,\n",
       "         5.49610586, 5.01080194, 4.81492558, 4.56579218, 4.36911793,\n",
       "         4.40781488, 4.23387966, 4.1235745 , 5.85873566, 5.45700974,\n",
       "         5.2000967 , 4.94717264, 4.77583003, 4.65076528, 4.46107249,\n",
       "         4.52230773, 4.45030112]),\n",
       "  'std_fit_time': array([0.05702264, 0.15320721, 0.22612092, 0.29241777, 0.02338653,\n",
       "         0.13606001, 0.024266  , 0.11160351, 0.02138489, 0.14849033,\n",
       "         0.12064602, 0.09833694, 0.06850619, 0.06968674, 0.08091247,\n",
       "         0.07762424, 0.11471515, 0.1392513 , 0.11583917, 0.10860643,\n",
       "         0.09459292, 0.11364176, 0.14032307, 0.1179985 , 0.12025005,\n",
       "         0.07015061, 0.10528427, 0.14438228, 0.11488249, 0.15588855,\n",
       "         0.10060089, 0.08148027, 0.14311376, 0.12317059, 0.14007185,\n",
       "         0.14329314, 0.02725691, 0.13341747, 0.12879058, 0.13474377,\n",
       "         0.13358205, 0.1644059 , 0.11045941, 0.0323015 , 0.0749119 ,\n",
       "         0.00638884, 0.03244266, 0.03388247, 0.11316053, 0.13777529,\n",
       "         0.16675403, 0.04633698, 0.20778231, 0.14294315, 0.0421322 ,\n",
       "         0.23581823, 0.01982047, 0.01913777, 0.12660499, 0.11949282,\n",
       "         0.16551275, 0.13382033, 0.174864  , 0.04425091, 0.00831087,\n",
       "         0.0246167 , 0.02895782, 0.12274014, 0.13337704, 0.0575591 ,\n",
       "         0.24761141, 0.94177847]),\n",
       "  'mean_score_time': array([0.00977173, 0.01117153, 0.01117029, 0.01097097, 0.01077271,\n",
       "         0.01336546, 0.01575646, 0.01176877, 0.00877676, 0.00977478,\n",
       "         0.0095747 , 0.00877686, 0.008779  , 0.00937572, 0.0087779 ,\n",
       "         0.00857778, 0.00817876, 0.00837779, 0.00937533, 0.00837865,\n",
       "         0.00797954, 0.00817876, 0.00857749, 0.00917597, 0.00857792,\n",
       "         0.00897694, 0.00937572, 0.0079793 , 0.00837841, 0.00957451,\n",
       "         0.00877666, 0.00917611, 0.00917754, 0.00817823, 0.00877709,\n",
       "         0.00877719, 0.00778012, 0.00817871, 0.00877767, 0.00897665,\n",
       "         0.00897689, 0.01057243, 0.00857792, 0.00897698, 0.00857768,\n",
       "         0.00837841, 0.00897679, 0.00837865, 0.00897713, 0.00977449,\n",
       "         0.00857759, 0.0091764 , 0.00897698, 0.00877714, 0.00877795,\n",
       "         0.00897603, 0.00857806, 0.00877724, 0.00897713, 0.00917654,\n",
       "         0.00897675, 0.01037331, 0.00897732, 0.0079792 , 0.00857787,\n",
       "         0.0083786 , 0.00817862, 0.0077796 , 0.00837812, 0.00937543,\n",
       "         0.00977554, 0.00897722]),\n",
       "  'std_score_time': array([2.31027329e-03, 2.47501134e-03, 1.59565823e-03, 1.40989650e-03,\n",
       "         2.55534507e-03, 2.23896109e-03, 6.41527420e-03, 5.65390741e-03,\n",
       "         9.77107156e-04, 1.16333375e-03, 1.35318995e-03, 1.16294151e-03,\n",
       "         1.16208620e-03, 1.73922166e-03, 1.16332553e-03, 1.84959660e-03,\n",
       "         1.16281848e-03, 7.97390972e-04, 2.49121727e-03, 4.89279041e-04,\n",
       "         6.30977274e-04, 7.46531409e-04, 1.01778491e-03, 3.99017761e-04,\n",
       "         4.88792525e-04, 1.26146442e-03, 1.84975599e-03, 1.09301516e-03,\n",
       "         7.97975075e-04, 1.84983313e-03, 7.46608030e-04, 2.39450955e-03,\n",
       "         1.16362982e-03, 7.46352932e-04, 7.46531348e-04, 7.46429644e-04,\n",
       "         3.98659745e-04, 9.77525188e-04, 1.71571203e-03, 6.30374168e-04,\n",
       "         8.92069989e-04, 2.32700260e-03, 4.88889458e-04, 8.92336544e-04,\n",
       "         7.97677131e-04, 4.88402973e-04, 2.09207820e-03, 1.01739224e-03,\n",
       "         6.29772022e-04, 1.46566156e-03, 7.97808289e-04, 7.46442273e-04,\n",
       "         5.30983387e-07, 7.45971082e-04, 7.46633422e-04, 8.92389899e-04,\n",
       "         1.01721449e-03, 7.46442213e-04, 6.30675890e-04, 1.16290032e-03,\n",
       "         8.92336646e-04, 1.84951434e-03, 6.30677137e-04, 6.30600338e-04,\n",
       "         7.97951237e-04, 4.88149487e-04, 9.77447351e-04, 7.45970579e-04,\n",
       "         7.98177812e-04, 7.97820168e-04, 7.46776340e-04, 6.29921836e-04]),\n",
       "  'param_max_depth': masked_array(data=[3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                     5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                     7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                     9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10,\n",
       "                     10, 10],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_min_child_weight': masked_array(data=[2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 3, 4, 5, 6, 7, 8, 9, 10,\n",
       "                     2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 3, 4, 5, 6, 7, 8, 9, 10,\n",
       "                     2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 3, 4, 5, 6, 7, 8, 9, 10,\n",
       "                     2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'max_depth': 3, 'min_child_weight': 2},\n",
       "   {'max_depth': 3, 'min_child_weight': 3},\n",
       "   {'max_depth': 3, 'min_child_weight': 4},\n",
       "   {'max_depth': 3, 'min_child_weight': 5},\n",
       "   {'max_depth': 3, 'min_child_weight': 6},\n",
       "   {'max_depth': 3, 'min_child_weight': 7},\n",
       "   {'max_depth': 3, 'min_child_weight': 8},\n",
       "   {'max_depth': 3, 'min_child_weight': 9},\n",
       "   {'max_depth': 3, 'min_child_weight': 10},\n",
       "   {'max_depth': 4, 'min_child_weight': 2},\n",
       "   {'max_depth': 4, 'min_child_weight': 3},\n",
       "   {'max_depth': 4, 'min_child_weight': 4},\n",
       "   {'max_depth': 4, 'min_child_weight': 5},\n",
       "   {'max_depth': 4, 'min_child_weight': 6},\n",
       "   {'max_depth': 4, 'min_child_weight': 7},\n",
       "   {'max_depth': 4, 'min_child_weight': 8},\n",
       "   {'max_depth': 4, 'min_child_weight': 9},\n",
       "   {'max_depth': 4, 'min_child_weight': 10},\n",
       "   {'max_depth': 5, 'min_child_weight': 2},\n",
       "   {'max_depth': 5, 'min_child_weight': 3},\n",
       "   {'max_depth': 5, 'min_child_weight': 4},\n",
       "   {'max_depth': 5, 'min_child_weight': 5},\n",
       "   {'max_depth': 5, 'min_child_weight': 6},\n",
       "   {'max_depth': 5, 'min_child_weight': 7},\n",
       "   {'max_depth': 5, 'min_child_weight': 8},\n",
       "   {'max_depth': 5, 'min_child_weight': 9},\n",
       "   {'max_depth': 5, 'min_child_weight': 10},\n",
       "   {'max_depth': 6, 'min_child_weight': 2},\n",
       "   {'max_depth': 6, 'min_child_weight': 3},\n",
       "   {'max_depth': 6, 'min_child_weight': 4},\n",
       "   {'max_depth': 6, 'min_child_weight': 5},\n",
       "   {'max_depth': 6, 'min_child_weight': 6},\n",
       "   {'max_depth': 6, 'min_child_weight': 7},\n",
       "   {'max_depth': 6, 'min_child_weight': 8},\n",
       "   {'max_depth': 6, 'min_child_weight': 9},\n",
       "   {'max_depth': 6, 'min_child_weight': 10},\n",
       "   {'max_depth': 7, 'min_child_weight': 2},\n",
       "   {'max_depth': 7, 'min_child_weight': 3},\n",
       "   {'max_depth': 7, 'min_child_weight': 4},\n",
       "   {'max_depth': 7, 'min_child_weight': 5},\n",
       "   {'max_depth': 7, 'min_child_weight': 6},\n",
       "   {'max_depth': 7, 'min_child_weight': 7},\n",
       "   {'max_depth': 7, 'min_child_weight': 8},\n",
       "   {'max_depth': 7, 'min_child_weight': 9},\n",
       "   {'max_depth': 7, 'min_child_weight': 10},\n",
       "   {'max_depth': 8, 'min_child_weight': 2},\n",
       "   {'max_depth': 8, 'min_child_weight': 3},\n",
       "   {'max_depth': 8, 'min_child_weight': 4},\n",
       "   {'max_depth': 8, 'min_child_weight': 5},\n",
       "   {'max_depth': 8, 'min_child_weight': 6},\n",
       "   {'max_depth': 8, 'min_child_weight': 7},\n",
       "   {'max_depth': 8, 'min_child_weight': 8},\n",
       "   {'max_depth': 8, 'min_child_weight': 9},\n",
       "   {'max_depth': 8, 'min_child_weight': 10},\n",
       "   {'max_depth': 9, 'min_child_weight': 2},\n",
       "   {'max_depth': 9, 'min_child_weight': 3},\n",
       "   {'max_depth': 9, 'min_child_weight': 4},\n",
       "   {'max_depth': 9, 'min_child_weight': 5},\n",
       "   {'max_depth': 9, 'min_child_weight': 6},\n",
       "   {'max_depth': 9, 'min_child_weight': 7},\n",
       "   {'max_depth': 9, 'min_child_weight': 8},\n",
       "   {'max_depth': 9, 'min_child_weight': 9},\n",
       "   {'max_depth': 9, 'min_child_weight': 10},\n",
       "   {'max_depth': 10, 'min_child_weight': 2},\n",
       "   {'max_depth': 10, 'min_child_weight': 3},\n",
       "   {'max_depth': 10, 'min_child_weight': 4},\n",
       "   {'max_depth': 10, 'min_child_weight': 5},\n",
       "   {'max_depth': 10, 'min_child_weight': 6},\n",
       "   {'max_depth': 10, 'min_child_weight': 7},\n",
       "   {'max_depth': 10, 'min_child_weight': 8},\n",
       "   {'max_depth': 10, 'min_child_weight': 9},\n",
       "   {'max_depth': 10, 'min_child_weight': 10}],\n",
       "  'split0_test_score': array([0.62602709, 0.63389222, 0.61810645, 0.64059146, 0.65304612,\n",
       "         0.63603894, 0.65526686, 0.61982752, 0.63881486, 0.62060478,\n",
       "         0.61508994, 0.61170331, 0.61464579, 0.60557776, 0.61831002,\n",
       "         0.6521023 , 0.62589755, 0.60039603, 0.61116663, 0.63777852,\n",
       "         0.61960545, 0.64862314, 0.61038937, 0.61323932, 0.63131986,\n",
       "         0.60872381, 0.6044859 , 0.62162262, 0.62378785, 0.60713228,\n",
       "         0.59364128, 0.61066696, 0.60709527, 0.61595973, 0.6065771 ,\n",
       "         0.59393738, 0.63990673, 0.58200089, 0.60093271, 0.57098971,\n",
       "         0.56601155, 0.61494189, 0.61934636, 0.59937819, 0.59417796,\n",
       "         0.58348138, 0.59047672, 0.58246354, 0.57602339, 0.57841069,\n",
       "         0.60752091, 0.59854541, 0.61777334, 0.57520912, 0.59142053,\n",
       "         0.63509512, 0.60992672, 0.60559627, 0.56584499, 0.61379451,\n",
       "         0.60850174, 0.59273447, 0.63496558, 0.57896587, 0.58429565,\n",
       "         0.56973129, 0.58122363, 0.6134799 , 0.58327781, 0.60561478,\n",
       "         0.62419498, 0.62104893]),\n",
       "  'split1_test_score': array([0.55783182, 0.54528463, 0.57195203, 0.56479014, 0.56862092,\n",
       "         0.55311274, 0.55266859, 0.55622178, 0.56321711, 0.56164409,\n",
       "         0.53971426, 0.55707306, 0.56086683, 0.55651788, 0.56652972,\n",
       "         0.55363091, 0.55046636, 0.56131098, 0.53401436, 0.55022578,\n",
       "         0.5532978 , 0.57128581, 0.54347102, 0.53419942, 0.56791768,\n",
       "         0.57334   , 0.55246502, 0.53312606, 0.5434155 , 0.55575912,\n",
       "         0.55379747, 0.54793101, 0.53986231, 0.55168776, 0.54174994,\n",
       "         0.54528463, 0.55616626, 0.55054038, 0.53928862, 0.56493819,\n",
       "         0.5434155 , 0.53736398, 0.55525946, 0.55825746, 0.54467392,\n",
       "         0.54593234, 0.55083648, 0.54720927, 0.54302687, 0.55407506,\n",
       "         0.56619661, 0.54811607, 0.53716041, 0.55202087, 0.54563624,\n",
       "         0.5365312 , 0.54237915, 0.55422311, 0.53956622, 0.54045451,\n",
       "         0.55742468, 0.53917759, 0.54683914, 0.54304538, 0.53447702,\n",
       "         0.54504404, 0.54744985, 0.52711156, 0.55651788, 0.54535865,\n",
       "         0.55640684, 0.55883115]),\n",
       "  'split2_test_score': array([0.52213339, 0.51591532, 0.51970908, 0.50218373, 0.52200385,\n",
       "         0.52883263, 0.50412688, 0.52435413, 0.50782811, 0.5059775 ,\n",
       "         0.49578059, 0.50662521, 0.51693316, 0.51658154, 0.50821674,\n",
       "         0.51321341, 0.51025242, 0.51693316, 0.50514472, 0.52746317,\n",
       "         0.5095862 , 0.5164705 , 0.50081427, 0.51863572, 0.51867274,\n",
       "         0.51041898, 0.52901769, 0.51523059, 0.5173588 , 0.51933896,\n",
       "         0.52285513, 0.51439781, 0.51743282, 0.5185617 , 0.51330594,\n",
       "         0.51238064, 0.51310238, 0.53320009, 0.53834481, 0.51637797,\n",
       "         0.52559405, 0.52587164, 0.51695166, 0.51791398, 0.51349101,\n",
       "         0.51998668, 0.5143793 , 0.5179695 , 0.50921608, 0.51994966,\n",
       "         0.52672293, 0.54463691, 0.51965356, 0.53029462, 0.51882079,\n",
       "         0.5170627 , 0.53031312, 0.53664224, 0.5245392 , 0.50253535,\n",
       "         0.52211489, 0.52870309, 0.529943  , 0.49929677, 0.52370642,\n",
       "         0.53416241, 0.54752387, 0.51012288, 0.52198534, 0.50986379,\n",
       "         0.51336146, 0.51961655]),\n",
       "  'split3_test_score': array([0.59216078, 0.63346658, 0.65286106, 0.66951662, 0.66424236,\n",
       "         0.64716115, 0.66774003, 0.67321785, 0.66929454, 0.56747354,\n",
       "         0.56521578, 0.65041824, 0.64262714, 0.63420683, 0.64756829,\n",
       "         0.65476719, 0.63661263, 0.68539492, 0.58631283, 0.58627582,\n",
       "         0.59267895, 0.63468799, 0.63096824, 0.62128951, 0.6242505 ,\n",
       "         0.64481087, 0.65528537, 0.52563106, 0.57219261, 0.59395588,\n",
       "         0.64965949, 0.60929751, 0.62832186, 0.63065364, 0.63594641,\n",
       "         0.64249759, 0.5724517 , 0.59256792, 0.61114812, 0.59203124,\n",
       "         0.58573914, 0.64375601, 0.60977867, 0.62521282, 0.6071878 ,\n",
       "         0.57074913, 0.59506625, 0.60048856, 0.58607225, 0.62711896,\n",
       "         0.60574432, 0.62182619, 0.64271967, 0.63487305, 0.55938634,\n",
       "         0.60505959, 0.5850174 , 0.64286772, 0.60530017, 0.60341254,\n",
       "         0.62110445, 0.63809312, 0.61283219, 0.51315789, 0.59018062,\n",
       "         0.6134614 , 0.61042638, 0.56219927, 0.61100007, 0.63566881,\n",
       "         0.62743356, 0.59776815]),\n",
       "  'split4_test_score': array([0.64864165, 0.64962247, 0.64688356, 0.65065882, 0.65125102,\n",
       "         0.60622548, 0.62537938, 0.60567029, 0.6086868 , 0.64059146,\n",
       "         0.66191058, 0.64212747, 0.63990673, 0.6625768 , 0.64227552,\n",
       "         0.62902509, 0.61688504, 0.62069731, 0.63387371, 0.64658746,\n",
       "         0.66624102, 0.63629802, 0.62075283, 0.60696573, 0.61366496,\n",
       "         0.60102524, 0.61223999, 0.64323784, 0.65443408, 0.633226  ,\n",
       "         0.64845658, 0.63986972, 0.62985787, 0.62747058, 0.62223333,\n",
       "         0.60211711, 0.64236805, 0.64775335, 0.63505811, 0.65467466,\n",
       "         0.64262714, 0.6215671 , 0.60887186, 0.58392553, 0.60631801,\n",
       "         0.63970316, 0.63167148, 0.63494707, 0.64973351, 0.65221334,\n",
       "         0.64523651, 0.634725  , 0.59830483, 0.60914946, 0.62708195,\n",
       "         0.62489822, 0.64582871, 0.63838922, 0.62478718, 0.61906877,\n",
       "         0.61431268, 0.60940854, 0.60746539, 0.6350396 , 0.63070916,\n",
       "         0.64629136, 0.6515101 , 0.63091272, 0.61131468, 0.62241839,\n",
       "         0.61982752, 0.64458879]),\n",
       "  'mean_test_score': array([0.58935895, 0.59563624, 0.60190244, 0.60554815, 0.61183285,\n",
       "         0.59427419, 0.60103635, 0.59585832, 0.59756829, 0.57925827,\n",
       "         0.57554223, 0.59358946, 0.59499593, 0.59509216, 0.59658006,\n",
       "         0.60054778, 0.5880228 , 0.59694648, 0.57410245, 0.58966615,\n",
       "         0.58828189, 0.60147309, 0.58127915, 0.57886594, 0.59116515,\n",
       "         0.58766378, 0.59069879, 0.56776964, 0.58223777, 0.58188245,\n",
       "         0.59368199, 0.5844326 , 0.58451403, 0.58886668, 0.58396254,\n",
       "         0.57924347, 0.58479902, 0.58121252, 0.58495447, 0.57980235,\n",
       "         0.57267747, 0.58870013, 0.5820416 , 0.5769376 , 0.57316974,\n",
       "         0.57197054, 0.57648605, 0.57661559, 0.57281442, 0.58635354,\n",
       "         0.59028425, 0.58956992, 0.58312236, 0.58030942, 0.56846917,\n",
       "         0.58372937, 0.58269302, 0.59554371, 0.57200755, 0.57585313,\n",
       "         0.58469169, 0.58162336, 0.58640906, 0.5539011 , 0.57267377,\n",
       "         0.5817381 , 0.58762677, 0.56876527, 0.57681916, 0.58378488,\n",
       "         0.58824487, 0.58837072]),\n",
       "  'std_test_score': array([0.04556331, 0.05422154, 0.0500708 , 0.06277004, 0.05645459,\n",
       "         0.0461758 , 0.0627914 , 0.05165114, 0.05692602, 0.04751948,\n",
       "         0.05792359, 0.05442387, 0.04884756, 0.05262314, 0.05267099,\n",
       "         0.05698606, 0.0491675 , 0.05669418, 0.04786998, 0.04688514,\n",
       "         0.05384241, 0.05035046, 0.0505542 , 0.04334435, 0.04244733,\n",
       "         0.04485482, 0.04492641, 0.05353836, 0.05050955, 0.04003398,\n",
       "         0.05047961, 0.0460804 , 0.04685887, 0.04537732, 0.04785948,\n",
       "         0.0455281 , 0.04992745, 0.03950499, 0.03926733, 0.04489246,\n",
       "         0.04045024, 0.04771339, 0.03958494, 0.03664872, 0.0376057 ,\n",
       "         0.04025422, 0.04025306, 0.04076953, 0.046978  , 0.04798707,\n",
       "         0.04043791, 0.03714136, 0.04716742, 0.03778008, 0.0374994 ,\n",
       "         0.04787568, 0.04266627, 0.04325073, 0.03804668, 0.0462498 ,\n",
       "         0.03854752, 0.04168095, 0.04062876, 0.04893095, 0.03915727,\n",
       "         0.04225531, 0.03965938, 0.04707181, 0.03411416, 0.0481704 ,\n",
       "         0.04570955, 0.04453397]),\n",
       "  'rank_test_score': array([23, 11,  3,  2,  1, 15,  5, 10,  7, 53, 61, 17, 14, 13,  9,  6, 29,\n",
       "          8, 62, 21, 27,  4, 49, 55, 18, 30, 19, 71, 44, 46, 16, 38, 37, 24,\n",
       "         39, 54, 35, 50, 34, 52, 65, 25, 45, 56, 63, 68, 59, 58, 64, 33, 20,\n",
       "         22, 42, 51, 70, 41, 43, 12, 67, 60, 36, 48, 32, 72, 66, 47, 31, 69,\n",
       "         57, 40, 28, 26])},\n",
       " {'max_depth': 3, 'min_child_weight': 6},\n",
       " 0.6118328521726257)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test2 = {\n",
    " 'max_depth':[3,4,5,6,7,8,9,10],\n",
    " 'min_child_weight':[2,3,4,5,6,7,8,9,10]\n",
    "}\n",
    "gsearch2 = GridSearchCV(estimator = XGBClassifier( learning_rate=learning_rate, n_estimators=n_estimators,  gamma=gamma, subsample=subsample, colsample_bytree=colsample_bytree,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=seed), \n",
    " param_grid = param_test2, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch2.fit(X,y)\n",
    "gsearch2.cv_results_, gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth= 3\n",
    "min_child_weight= 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:28:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'mean_fit_time': array([0.01934829, 0.0157577 , 0.01835093, 0.017554  , 0.01735258,\n",
       "         1.86222086, 1.90211372, 1.84686184, 1.92146173, 2.11474352]),\n",
       "  'std_fit_time': array([0.00135377, 0.00230864, 0.00448689, 0.0013533 , 0.00149344,\n",
       "         0.10659648, 0.12495556, 0.10893716, 0.08131684, 0.73425979]),\n",
       "  'mean_score_time': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.00877733, 0.0091774 , 0.00857749, 0.01296639, 0.0081789 ]),\n",
       "  'std_score_time': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.00116396, 0.00097768, 0.00119627, 0.00209222, 0.00171607]),\n",
       "  'param_gamma': masked_array(data=[-0.005, -0.004, -0.003, -0.002, -0.001, 0.0, 0.001,\n",
       "                     0.002, 0.003, 0.004],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'gamma': -0.005},\n",
       "   {'gamma': -0.004},\n",
       "   {'gamma': -0.003},\n",
       "   {'gamma': -0.002},\n",
       "   {'gamma': -0.001},\n",
       "   {'gamma': 0.0},\n",
       "   {'gamma': 0.001},\n",
       "   {'gamma': 0.002},\n",
       "   {'gamma': 0.003},\n",
       "   {'gamma': 0.004}],\n",
       "  'split0_test_score': array([       nan,        nan,        nan,        nan,        nan,\n",
       "         0.65304612, 0.65304612, 0.65304612, 0.65304612, 0.65304612]),\n",
       "  'split1_test_score': array([       nan,        nan,        nan,        nan,        nan,\n",
       "         0.56862092, 0.56862092, 0.56862092, 0.56862092, 0.56862092]),\n",
       "  'split2_test_score': array([       nan,        nan,        nan,        nan,        nan,\n",
       "         0.52200385, 0.52200385, 0.52200385, 0.52200385, 0.52200385]),\n",
       "  'split3_test_score': array([       nan,        nan,        nan,        nan,        nan,\n",
       "         0.66424236, 0.66424236, 0.66424236, 0.66424236, 0.66424236]),\n",
       "  'split4_test_score': array([       nan,        nan,        nan,        nan,        nan,\n",
       "         0.65125102, 0.65125102, 0.65125102, 0.65125102, 0.65125102]),\n",
       "  'mean_test_score': array([       nan,        nan,        nan,        nan,        nan,\n",
       "         0.61183285, 0.61183285, 0.61183285, 0.61183285, 0.61183285]),\n",
       "  'std_test_score': array([       nan,        nan,        nan,        nan,        nan,\n",
       "         0.05645459, 0.05645459, 0.05645459, 0.05645459, 0.05645459]),\n",
       "  'rank_test_score': array([ 6,  7,  8,  9, 10,  1,  1,  1,  1,  1])},\n",
       " {'gamma': 0.0},\n",
       " 0.6118328521726257)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test3 = {\n",
    " 'gamma':[i*0.001 for i in range(-5,5)]\n",
    "}\n",
    "gsearch3 = GridSearchCV(estimator = XGBClassifier( learning_rate=learning_rate, n_estimators=n_estimators, max_depth=max_depth,\n",
    " min_child_weight=min_child_weight,  subsample=subsample, colsample_bytree=colsample_bytree,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=seed),  \n",
    " param_grid = param_test3, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch3.fit(X,y)\n",
    "gsearch3.cv_results_, gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Accuracy : 0.88\n",
      "AUC Score (Train): 0.958333\n"
     ]
    }
   ],
   "source": [
    "xgb10 = XGBClassifier(\n",
    " learning_rate =learning_rate,\n",
    " n_estimators=n_estimators,\n",
    " max_depth=max_depth,\n",
    " min_child_weight=min_child_weight,\n",
    " gamma=gamma,\n",
    " subsample=subsample,\n",
    " colsample_bytree=colsample_bytree,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=seed)\n",
    "modelfit(xgb10, X,y, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:47:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'mean_fit_time': array([1.57917771, 1.46667776, 1.64360423, 1.54367213, 1.63582668,\n",
       "         1.79978762, 1.60989518, 1.7610909 , 1.85962768, 1.91448016,\n",
       "         2.00364227, 1.82890978, 2.12990484, 1.92644749, 2.12810974,\n",
       "         2.02518511]),\n",
       "  'std_fit_time': array([0.05287772, 0.02009315, 0.13607483, 0.09888533, 0.14940649,\n",
       "         0.14777154, 0.01155236, 0.08657243, 0.0653438 , 0.20240302,\n",
       "         0.12170937, 0.0401689 , 0.09881048, 0.0197612 , 0.15109067,\n",
       "         0.09449288]),\n",
       "  'mean_score_time': array([0.01037302, 0.00977407, 0.00937538, 0.01575899, 0.01117034,\n",
       "         0.00957475, 0.00917654, 0.01236773, 0.01017408, 0.01017408,\n",
       "         0.00857782, 0.00977402, 0.01017361, 0.00857825, 0.00957508,\n",
       "         0.0079792 ]),\n",
       "  'std_score_time': array([0.00223948, 0.00193503, 0.00205311, 0.00370044, 0.00193441,\n",
       "         0.00135226, 0.00146562, 0.00173797, 0.00203541, 0.00239418,\n",
       "         0.00079745, 0.00171629, 0.00222158, 0.00079767, 0.00184962,\n",
       "         0.00089191]),\n",
       "  'param_colsample_bytree': masked_array(data=[0.6, 0.6, 0.6, 0.6, 0.7, 0.7, 0.7, 0.7, 0.8, 0.8, 0.8,\n",
       "                     0.8, 0.9, 0.9, 0.9, 0.9],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_subsample': masked_array(data=[0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8,\n",
       "                     0.9, 0.6, 0.7, 0.8, 0.9],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'colsample_bytree': 0.6, 'subsample': 0.6},\n",
       "   {'colsample_bytree': 0.6, 'subsample': 0.7},\n",
       "   {'colsample_bytree': 0.6, 'subsample': 0.8},\n",
       "   {'colsample_bytree': 0.6, 'subsample': 0.9},\n",
       "   {'colsample_bytree': 0.7, 'subsample': 0.6},\n",
       "   {'colsample_bytree': 0.7, 'subsample': 0.7},\n",
       "   {'colsample_bytree': 0.7, 'subsample': 0.8},\n",
       "   {'colsample_bytree': 0.7, 'subsample': 0.9},\n",
       "   {'colsample_bytree': 0.8, 'subsample': 0.6},\n",
       "   {'colsample_bytree': 0.8, 'subsample': 0.7},\n",
       "   {'colsample_bytree': 0.8, 'subsample': 0.8},\n",
       "   {'colsample_bytree': 0.8, 'subsample': 0.9},\n",
       "   {'colsample_bytree': 0.9, 'subsample': 0.6},\n",
       "   {'colsample_bytree': 0.9, 'subsample': 0.7},\n",
       "   {'colsample_bytree': 0.9, 'subsample': 0.8},\n",
       "   {'colsample_bytree': 0.9, 'subsample': 0.9}],\n",
       "  'split0_test_score': array([0.63814864, 0.62310312, 0.64297875, 0.66809164, 0.65319417,\n",
       "         0.63126434, 0.65576653, 0.636224  , 0.63376268, 0.64144274,\n",
       "         0.65304612, 0.64566215, 0.62349175, 0.62030868, 0.66596343,\n",
       "         0.64486639]),\n",
       "  'split1_test_score': array([0.57589385, 0.55638833, 0.56157006, 0.56508624, 0.57968762,\n",
       "         0.56747354, 0.55992301, 0.55031831, 0.57428381, 0.56745503,\n",
       "         0.56862092, 0.5700459 , 0.56847287, 0.57879932, 0.56245836,\n",
       "         0.57169295]),\n",
       "  'split2_test_score': array([0.52180028, 0.52139315, 0.5245577 , 0.49981494, 0.51399067,\n",
       "         0.52213339, 0.51182545, 0.51815456, 0.51356503, 0.51793249,\n",
       "         0.52200385, 0.50557036, 0.49592864, 0.51656303, 0.51889481,\n",
       "         0.51149234]),\n",
       "  'split3_test_score': array([0.65102894, 0.64508846, 0.66329854, 0.6428122 , 0.69237175,\n",
       "         0.6622807 , 0.67240358, 0.69020653, 0.67295877, 0.68944778,\n",
       "         0.66424236, 0.6401288 , 0.63737138, 0.68965134, 0.68987342,\n",
       "         0.68522837]),\n",
       "  'split4_test_score': array([0.65909764, 0.66551928, 0.65321267, 0.64349693, 0.6589681 ,\n",
       "         0.68328522, 0.65278703, 0.65091791, 0.63572433, 0.64177585,\n",
       "         0.65125102, 0.65917166, 0.65770968, 0.64495892, 0.66725886,\n",
       "         0.66278037]),\n",
       "  'mean_test_score': array([0.60919387, 0.60229847, 0.60912355, 0.60386039, 0.61964246,\n",
       "         0.61328744, 0.61054112, 0.60916426, 0.60605892, 0.61161078,\n",
       "         0.61183285, 0.60411577, 0.59659486, 0.61005626, 0.62088978,\n",
       "         0.61521208]),\n",
       "  'std_test_score': array([0.05258416, 0.0546152 , 0.05556559, 0.06251855, 0.06437463,\n",
       "         0.06005193, 0.0631886 , 0.06448109, 0.05601411, 0.06096528,\n",
       "         0.05645459, 0.05818272, 0.05838788, 0.05895195, 0.06746506,\n",
       "         0.06433677]),\n",
       "  'rank_test_score': array([ 9, 15, 11, 14,  2,  4,  7, 10, 12,  6,  5, 13, 16,  8,  1,  3])},\n",
       " {'colsample_bytree': 0.9, 'subsample': 0.8},\n",
       " 0.6208897771855799)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test4 = {\n",
    " 'subsample':[i/10.0 for i in range(6,10)],\n",
    " 'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
    "}\n",
    "gsearch4 = GridSearchCV(estimator =XGBClassifier( learning_rate=learning_rate, n_estimators=n_estimators, max_depth=max_depth,\n",
    " min_child_weight=min_child_weight, gamma=gamma, subsample=subsample, colsample_bytree=colsample_bytree,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=seed), \n",
    " param_grid = param_test4, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch4.fit(X,y)\n",
    "gsearch4.cv_results_, gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:53:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'colsample_bytree': 0.92, 'subsample': 0.83}, 0.6229069509216079)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test5 = {\n",
    " 'subsample':[i/100.0 for i in range(75,85)],\n",
    " 'colsample_bytree':[i/100.0 for i in range(85,95)]\n",
    "}\n",
    "gsearch5 = GridSearchCV(estimator =XGBClassifier( learning_rate=learning_rate, n_estimators=n_estimators, max_depth=max_depth,\n",
    " min_child_weight=min_child_weight, gamma=gamma, subsample=subsample, colsample_bytree=colsample_bytree,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=seed),  \n",
    " param_grid = param_test5, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch5.fit(X,y)\n",
    "gsearch5.best_params_, gsearch5.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:07:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'colsample_bytree': 0.911, 'subsample': 0.83}, 0.6229069509216079)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test17 = {\n",
    " 'subsample':[i/1000.0 for i in range(825,835)],\n",
    " 'colsample_bytree':[i/1000.0 for i in range(911,916)]\n",
    "}\n",
    "gsearch17 = GridSearchCV(estimator =XGBClassifier( learning_rate=learning_rate, n_estimators=n_estimators, max_depth=max_depth,\n",
    " min_child_weight=min_child_weight, gamma=gamma, subsample=subsample, colsample_bytree=colsample_bytree,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=seed),  \n",
    " param_grid = param_test17, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch17.fit(X,y)\n",
    "gsearch17.best_params_, gsearch17.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:15:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'colsample_bytree': 0.9105, 'subsample': 0.83}, 0.6229069509216079)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test18 = {\n",
    " 'subsample':[i/10000.0 for i in range(8295,8305)],\n",
    " 'colsample_bytree':[i/10000.0 for i in range(9105,9115)]\n",
    "}\n",
    "gsearch18 = GridSearchCV(estimator =XGBClassifier( learning_rate=learning_rate, n_estimators=n_estimators, max_depth=max_depth,\n",
    " min_child_weight=min_child_weight, gamma=gamma, subsample=subsample, colsample_bytree=colsample_bytree,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=seed),  \n",
    " param_grid = param_test18, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch18.fit(X,y)\n",
    "gsearch18.best_params_, gsearch18.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample = 0.83\n",
    "colsample_bytree = 0.9105"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([1.82865977, 1.49363742, 1.66804447, 1.57808161, 1.58201437,\n",
       "        1.73275294, 1.62233663, 1.570892  , 1.82465005, 1.55816913,\n",
       "        1.7656239 , 1.56898975, 1.51744294, 1.72106924, 1.61919842,\n",
       "        1.57737684, 2.18282266, 1.69979773, 1.9504178 , 1.72833738,\n",
       "        1.82021217, 1.88311977, 1.58461781, 1.84187007, 1.74422131,\n",
       "        1.95648756, 1.6419631 , 1.4882071 , 1.72617159, 1.48952947,\n",
       "        1.48432364, 1.76736059, 1.56793079, 1.838696  , 2.00181489,\n",
       "        1.6578845 , 2.04253788, 1.64081101, 1.99606318, 1.73675537,\n",
       "        1.56740899, 1.78422914, 1.6465971 , 2.05291066, 1.6092967 ,\n",
       "        1.8819694 , 1.93682094, 3.86746192, 2.29107332, 1.6336318 ,\n",
       "        1.63123598, 1.61627817, 1.84227605, 1.64997296, 2.37545409,\n",
       "        3.48498263, 2.14586172, 1.71282125, 2.1360877 , 1.91168842,\n",
       "        2.03934755, 2.43488884, 2.20270877, 2.03356295, 2.21288095,\n",
       "        3.74099779, 3.42404604, 2.29805322, 1.60450969, 1.61149073,\n",
       "        1.84905577, 1.58436332, 1.64779291, 1.69646311, 1.66933608,\n",
       "        4.10981193, 2.57112427, 2.09380312, 1.59054685, 1.76787233,\n",
       "        1.57259483, 1.63403053, 1.65457578, 1.58057246, 1.77345781,\n",
       "        1.70364375, 1.74593177, 1.92904153, 1.7086309 , 1.6854928 ,\n",
       "        1.70962939, 1.57977576, 1.82771244, 1.62186279, 2.49971628,\n",
       "        1.99958105, 1.69253635, 1.82082553, 1.6512073 , 1.83380308]),\n",
       " 'std_fit_time': array([0.16138451, 0.01071457, 0.15124946, 0.10711063, 0.06509946,\n",
       "        0.05634005, 0.0426248 , 0.03377823, 0.14306106, 0.03066638,\n",
       "        0.11902989, 0.15314951, 0.00670067, 0.14649867, 0.09506897,\n",
       "        0.01479888, 0.17578046, 0.10135398, 0.31000415, 0.2595692 ,\n",
       "        0.11399931, 0.22169865, 0.00739677, 0.12712339, 0.1993256 ,\n",
       "        0.12690204, 0.17788681, 0.01019794, 0.11932759, 0.01141525,\n",
       "        0.0187935 , 0.14526601, 0.06207235, 0.14180082, 0.02156028,\n",
       "        0.15728417, 0.20919929, 0.00959466, 0.2672592 , 0.24071502,\n",
       "        0.2020977 , 0.22240816, 0.09072349, 0.18198166, 0.03386008,\n",
       "        0.30259146, 0.24693886, 1.05775572, 0.40891045, 0.16915779,\n",
       "        0.17588494, 0.05517877, 0.10029262, 0.16079949, 0.36626887,\n",
       "        0.4549862 , 0.27557985, 0.17491406, 0.15527274, 0.17269526,\n",
       "        0.39304215, 0.36906071, 0.26730631, 0.18628898, 0.6446404 ,\n",
       "        0.09671904, 0.34418362, 0.42838152, 0.04094395, 0.11703846,\n",
       "        0.13558393, 0.03707427, 0.1167241 , 0.16106359, 0.14155475,\n",
       "        1.20613356, 0.36697785, 0.26428097, 0.02859698, 0.10127854,\n",
       "        0.03785342, 0.16365341, 0.16513968, 0.0471994 , 0.15075653,\n",
       "        0.09541622, 0.01738449, 0.06894546, 0.10199261, 0.16804654,\n",
       "        0.13558088, 0.0187649 , 0.14273313, 0.11168071, 0.59320306,\n",
       "        0.50529909, 0.09660045, 0.08981422, 0.03389309, 0.11251968]),\n",
       " 'mean_score_time': array([0.00922856, 0.01100192, 0.01061401, 0.01360497, 0.00960717,\n",
       "        0.01360273, 0.00880446, 0.00879717, 0.00970383, 0.00959344,\n",
       "        0.00861135, 0.00849118, 0.01059508, 0.01241193, 0.00889983,\n",
       "        0.00781851, 0.01009078, 0.00870094, 0.00960002, 0.00969996,\n",
       "        0.0120038 , 0.00987463, 0.00900683, 0.00832543, 0.00910196,\n",
       "        0.00920782, 0.00890408, 0.00859632, 0.00839272, 0.00799513,\n",
       "        0.00781183, 0.01057677, 0.00979352, 0.00959277, 0.01198716,\n",
       "        0.00937567, 0.00897665, 0.00857782, 0.00857706, 0.00897679,\n",
       "        0.00837932, 0.00937586, 0.00857778, 0.01037521, 0.00857739,\n",
       "        0.01117001, 0.00957508, 0.01815057, 0.00837908, 0.01097131,\n",
       "        0.00897684, 0.00817847, 0.01057024, 0.00959044, 0.00940237,\n",
       "        0.01017799, 0.00837898, 0.01077023, 0.01077166, 0.01017632,\n",
       "        0.01356115, 0.01017456, 0.0103724 , 0.01076999, 0.01356306,\n",
       "        0.01416178, 0.01256628, 0.00957541, 0.00877719, 0.01017509,\n",
       "        0.0095746 , 0.00937591, 0.01097131, 0.00897651, 0.00877724,\n",
       "        0.01196856, 0.01316538, 0.01076913, 0.00837774, 0.00937676,\n",
       "        0.00817924, 0.00837784, 0.00837817, 0.00937557, 0.01216803,\n",
       "        0.00937538, 0.00877647, 0.00997376, 0.00897684, 0.00797963,\n",
       "        0.00877571, 0.0095747 , 0.00897837, 0.00897655, 0.00797858,\n",
       "        0.01039085, 0.00899453, 0.00861216, 0.00860734, 0.00857735]),\n",
       " 'std_score_time': array([0.00040131, 0.00242575, 0.00144645, 0.00215041, 0.00279878,\n",
       "        0.00407851, 0.0009758 , 0.00111712, 0.00087716, 0.0010213 ,\n",
       "        0.00079943, 0.00063401, 0.00340093, 0.00340328, 0.00110494,\n",
       "        0.00073547, 0.00189974, 0.00097694, 0.00149215, 0.0013405 ,\n",
       "        0.00274374, 0.00420178, 0.00062113, 0.00116754, 0.00112704,\n",
       "        0.0007436 , 0.00168088, 0.00101875, 0.00102592, 0.0006306 ,\n",
       "        0.0007479 , 0.00135156, 0.00147212, 0.00241295, 0.00518196,\n",
       "        0.00048951, 0.0008917 , 0.00135279, 0.00135292, 0.00141003,\n",
       "        0.00135209, 0.0014932 , 0.00048858, 0.00101743, 0.00135337,\n",
       "        0.00390913, 0.00149199, 0.01316032, 0.0004902 , 0.00454902,\n",
       "        0.00063007, 0.00039852, 0.00376155, 0.00101628, 0.00186102,\n",
       "        0.00270318, 0.00101675, 0.00239332, 0.00330226, 0.00146901,\n",
       "        0.00499072, 0.00132381, 0.00149255, 0.00193462, 0.00506805,\n",
       "        0.00353668, 0.00249048, 0.00119731, 0.00074592, 0.00255554,\n",
       "        0.00048906, 0.000798  , 0.00274895, 0.00089218, 0.00132358,\n",
       "        0.0026008 , 0.0093854 , 0.00311719, 0.00079789, 0.00331598,\n",
       "        0.00116331, 0.00048877, 0.00101725, 0.00101726, 0.00347805,\n",
       "        0.00184883, 0.00039842, 0.00236058, 0.00089244, 0.00063128,\n",
       "        0.00116095, 0.00079688, 0.00166901, 0.00063052, 0.00089282,\n",
       "        0.00173629, 0.00109734, 0.00048956, 0.00079653, 0.00048862]),\n",
       " 'param_colsample_bytree': masked_array(data=[0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.91,\n",
       "                    0.91, 0.91, 0.91, 0.91, 0.91, 0.91, 0.91, 0.91, 0.91,\n",
       "                    0.92, 0.92, 0.92, 0.92, 0.92, 0.92, 0.92, 0.92, 0.92,\n",
       "                    0.92, 0.93, 0.93, 0.93, 0.93, 0.93, 0.93, 0.93, 0.93,\n",
       "                    0.93, 0.93, 0.94, 0.94, 0.94, 0.94, 0.94, 0.94, 0.94,\n",
       "                    0.94, 0.94, 0.94, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95,\n",
       "                    0.95, 0.95, 0.95, 0.95, 0.96, 0.96, 0.96, 0.96, 0.96,\n",
       "                    0.96, 0.96, 0.96, 0.96, 0.96, 0.97, 0.97, 0.97, 0.97,\n",
       "                    0.97, 0.97, 0.97, 0.97, 0.97, 0.97, 0.98, 0.98, 0.98,\n",
       "                    0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.99, 0.99,\n",
       "                    0.99, 0.99, 0.99, 0.99, 0.99, 0.99, 0.99, 0.99],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_subsample': masked_array(data=[0.75, 0.76, 0.77, 0.78, 0.79, 0.8, 0.81, 0.82, 0.83,\n",
       "                    0.84, 0.75, 0.76, 0.77, 0.78, 0.79, 0.8, 0.81, 0.82,\n",
       "                    0.83, 0.84, 0.75, 0.76, 0.77, 0.78, 0.79, 0.8, 0.81,\n",
       "                    0.82, 0.83, 0.84, 0.75, 0.76, 0.77, 0.78, 0.79, 0.8,\n",
       "                    0.81, 0.82, 0.83, 0.84, 0.75, 0.76, 0.77, 0.78, 0.79,\n",
       "                    0.8, 0.81, 0.82, 0.83, 0.84, 0.75, 0.76, 0.77, 0.78,\n",
       "                    0.79, 0.8, 0.81, 0.82, 0.83, 0.84, 0.75, 0.76, 0.77,\n",
       "                    0.78, 0.79, 0.8, 0.81, 0.82, 0.83, 0.84, 0.75, 0.76,\n",
       "                    0.77, 0.78, 0.79, 0.8, 0.81, 0.82, 0.83, 0.84, 0.75,\n",
       "                    0.76, 0.77, 0.78, 0.79, 0.8, 0.81, 0.82, 0.83, 0.84,\n",
       "                    0.75, 0.76, 0.77, 0.78, 0.79, 0.8, 0.81, 0.82, 0.83,\n",
       "                    0.84],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'colsample_bytree': 0.9, 'subsample': 0.75},\n",
       "  {'colsample_bytree': 0.9, 'subsample': 0.76},\n",
       "  {'colsample_bytree': 0.9, 'subsample': 0.77},\n",
       "  {'colsample_bytree': 0.9, 'subsample': 0.78},\n",
       "  {'colsample_bytree': 0.9, 'subsample': 0.79},\n",
       "  {'colsample_bytree': 0.9, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.9, 'subsample': 0.81},\n",
       "  {'colsample_bytree': 0.9, 'subsample': 0.82},\n",
       "  {'colsample_bytree': 0.9, 'subsample': 0.83},\n",
       "  {'colsample_bytree': 0.9, 'subsample': 0.84},\n",
       "  {'colsample_bytree': 0.91, 'subsample': 0.75},\n",
       "  {'colsample_bytree': 0.91, 'subsample': 0.76},\n",
       "  {'colsample_bytree': 0.91, 'subsample': 0.77},\n",
       "  {'colsample_bytree': 0.91, 'subsample': 0.78},\n",
       "  {'colsample_bytree': 0.91, 'subsample': 0.79},\n",
       "  {'colsample_bytree': 0.91, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.91, 'subsample': 0.81},\n",
       "  {'colsample_bytree': 0.91, 'subsample': 0.82},\n",
       "  {'colsample_bytree': 0.91, 'subsample': 0.83},\n",
       "  {'colsample_bytree': 0.91, 'subsample': 0.84},\n",
       "  {'colsample_bytree': 0.92, 'subsample': 0.75},\n",
       "  {'colsample_bytree': 0.92, 'subsample': 0.76},\n",
       "  {'colsample_bytree': 0.92, 'subsample': 0.77},\n",
       "  {'colsample_bytree': 0.92, 'subsample': 0.78},\n",
       "  {'colsample_bytree': 0.92, 'subsample': 0.79},\n",
       "  {'colsample_bytree': 0.92, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.92, 'subsample': 0.81},\n",
       "  {'colsample_bytree': 0.92, 'subsample': 0.82},\n",
       "  {'colsample_bytree': 0.92, 'subsample': 0.83},\n",
       "  {'colsample_bytree': 0.92, 'subsample': 0.84},\n",
       "  {'colsample_bytree': 0.93, 'subsample': 0.75},\n",
       "  {'colsample_bytree': 0.93, 'subsample': 0.76},\n",
       "  {'colsample_bytree': 0.93, 'subsample': 0.77},\n",
       "  {'colsample_bytree': 0.93, 'subsample': 0.78},\n",
       "  {'colsample_bytree': 0.93, 'subsample': 0.79},\n",
       "  {'colsample_bytree': 0.93, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.93, 'subsample': 0.81},\n",
       "  {'colsample_bytree': 0.93, 'subsample': 0.82},\n",
       "  {'colsample_bytree': 0.93, 'subsample': 0.83},\n",
       "  {'colsample_bytree': 0.93, 'subsample': 0.84},\n",
       "  {'colsample_bytree': 0.94, 'subsample': 0.75},\n",
       "  {'colsample_bytree': 0.94, 'subsample': 0.76},\n",
       "  {'colsample_bytree': 0.94, 'subsample': 0.77},\n",
       "  {'colsample_bytree': 0.94, 'subsample': 0.78},\n",
       "  {'colsample_bytree': 0.94, 'subsample': 0.79},\n",
       "  {'colsample_bytree': 0.94, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.94, 'subsample': 0.81},\n",
       "  {'colsample_bytree': 0.94, 'subsample': 0.82},\n",
       "  {'colsample_bytree': 0.94, 'subsample': 0.83},\n",
       "  {'colsample_bytree': 0.94, 'subsample': 0.84},\n",
       "  {'colsample_bytree': 0.95, 'subsample': 0.75},\n",
       "  {'colsample_bytree': 0.95, 'subsample': 0.76},\n",
       "  {'colsample_bytree': 0.95, 'subsample': 0.77},\n",
       "  {'colsample_bytree': 0.95, 'subsample': 0.78},\n",
       "  {'colsample_bytree': 0.95, 'subsample': 0.79},\n",
       "  {'colsample_bytree': 0.95, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.95, 'subsample': 0.81},\n",
       "  {'colsample_bytree': 0.95, 'subsample': 0.82},\n",
       "  {'colsample_bytree': 0.95, 'subsample': 0.83},\n",
       "  {'colsample_bytree': 0.95, 'subsample': 0.84},\n",
       "  {'colsample_bytree': 0.96, 'subsample': 0.75},\n",
       "  {'colsample_bytree': 0.96, 'subsample': 0.76},\n",
       "  {'colsample_bytree': 0.96, 'subsample': 0.77},\n",
       "  {'colsample_bytree': 0.96, 'subsample': 0.78},\n",
       "  {'colsample_bytree': 0.96, 'subsample': 0.79},\n",
       "  {'colsample_bytree': 0.96, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.96, 'subsample': 0.81},\n",
       "  {'colsample_bytree': 0.96, 'subsample': 0.82},\n",
       "  {'colsample_bytree': 0.96, 'subsample': 0.83},\n",
       "  {'colsample_bytree': 0.96, 'subsample': 0.84},\n",
       "  {'colsample_bytree': 0.97, 'subsample': 0.75},\n",
       "  {'colsample_bytree': 0.97, 'subsample': 0.76},\n",
       "  {'colsample_bytree': 0.97, 'subsample': 0.77},\n",
       "  {'colsample_bytree': 0.97, 'subsample': 0.78},\n",
       "  {'colsample_bytree': 0.97, 'subsample': 0.79},\n",
       "  {'colsample_bytree': 0.97, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.97, 'subsample': 0.81},\n",
       "  {'colsample_bytree': 0.97, 'subsample': 0.82},\n",
       "  {'colsample_bytree': 0.97, 'subsample': 0.83},\n",
       "  {'colsample_bytree': 0.97, 'subsample': 0.84},\n",
       "  {'colsample_bytree': 0.98, 'subsample': 0.75},\n",
       "  {'colsample_bytree': 0.98, 'subsample': 0.76},\n",
       "  {'colsample_bytree': 0.98, 'subsample': 0.77},\n",
       "  {'colsample_bytree': 0.98, 'subsample': 0.78},\n",
       "  {'colsample_bytree': 0.98, 'subsample': 0.79},\n",
       "  {'colsample_bytree': 0.98, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.98, 'subsample': 0.81},\n",
       "  {'colsample_bytree': 0.98, 'subsample': 0.82},\n",
       "  {'colsample_bytree': 0.98, 'subsample': 0.83},\n",
       "  {'colsample_bytree': 0.98, 'subsample': 0.84},\n",
       "  {'colsample_bytree': 0.99, 'subsample': 0.75},\n",
       "  {'colsample_bytree': 0.99, 'subsample': 0.76},\n",
       "  {'colsample_bytree': 0.99, 'subsample': 0.77},\n",
       "  {'colsample_bytree': 0.99, 'subsample': 0.78},\n",
       "  {'colsample_bytree': 0.99, 'subsample': 0.79},\n",
       "  {'colsample_bytree': 0.99, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.99, 'subsample': 0.81},\n",
       "  {'colsample_bytree': 0.99, 'subsample': 0.82},\n",
       "  {'colsample_bytree': 0.99, 'subsample': 0.83},\n",
       "  {'colsample_bytree': 0.99, 'subsample': 0.84}],\n",
       " 'split0_test_score': array([0.64608224, 0.64498926, 0.65704971, 0.65135869, 0.66242038,\n",
       "        0.67759017, 0.67589417, 0.66172314, 0.66880865, 0.66196812,\n",
       "        0.64608224, 0.64498926, 0.65704971, 0.65135869, 0.66242038,\n",
       "        0.67759017, 0.67589417, 0.66172314, 0.66880865, 0.66196812,\n",
       "        0.65037877, 0.65642784, 0.65292278, 0.66767799, 0.67760902,\n",
       "        0.66315532, 0.6696755 , 0.68273471, 0.67448084, 0.66219425,\n",
       "        0.65816153, 0.65652207, 0.66145931, 0.65475069, 0.67796706,\n",
       "        0.67431124, 0.66176083, 0.67282252, 0.66958128, 0.66837523,\n",
       "        0.65816153, 0.65652207, 0.66145931, 0.65475069, 0.67796706,\n",
       "        0.67431124, 0.66176083, 0.67282252, 0.66958128, 0.66837523,\n",
       "        0.65639016, 0.6519994 , 0.65147175, 0.67042928, 0.69113934,\n",
       "        0.67076848, 0.65769042, 0.66155354, 0.6688275 , 0.67020314,\n",
       "        0.66008367, 0.65360118, 0.662345  , 0.65294162, 0.67216297,\n",
       "        0.6761203 , 0.6742547 , 0.66860136, 0.67218181, 0.65757736,\n",
       "        0.66008367, 0.65360118, 0.662345  , 0.65294162, 0.67216297,\n",
       "        0.6761203 , 0.6742547 , 0.66860136, 0.67218181, 0.65757736,\n",
       "        0.64564881, 0.65476953, 0.66255229, 0.6698451 , 0.68224475,\n",
       "        0.66709381, 0.66579354, 0.66025327, 0.67257754, 0.66411638,\n",
       "        0.65431727, 0.65397807, 0.66622696, 0.66980741, 0.68495835,\n",
       "        0.65541024, 0.67342555, 0.67133381, 0.67483888, 0.661497  ]),\n",
       " 'split1_test_score': array([0.68962257, 0.68695636, 0.6833825 , 0.68158611, 0.67504349,\n",
       "        0.68701309, 0.68357159, 0.68559489, 0.68130247, 0.68383632,\n",
       "        0.68962257, 0.68695636, 0.6833825 , 0.68158611, 0.67504349,\n",
       "        0.68701309, 0.68357159, 0.68559489, 0.68130247, 0.68383632,\n",
       "        0.6835905 , 0.68691854, 0.69573028, 0.68221012, 0.679941  ,\n",
       "        0.68411996, 0.68472506, 0.68771273, 0.68720218, 0.6864269 ,\n",
       "        0.68307995, 0.68366614, 0.68909311, 0.67003252, 0.6854247 ,\n",
       "        0.68362832, 0.6823803 , 0.68654035, 0.68058392, 0.68022464,\n",
       "        0.68307995, 0.68366614, 0.68909311, 0.67003252, 0.6854247 ,\n",
       "        0.68362832, 0.6823803 , 0.68654035, 0.68058392, 0.68022464,\n",
       "        0.69122986, 0.69538991, 0.67470312, 0.67901445, 0.67903336,\n",
       "        0.67975191, 0.68347704, 0.67347402, 0.68082974, 0.68533016,\n",
       "        0.68888511, 0.69283715, 0.68481961, 0.68137811, 0.68718327,\n",
       "        0.67570532, 0.68243703, 0.67757734, 0.68194539, 0.68084865,\n",
       "        0.68888511, 0.69283715, 0.68481961, 0.68137811, 0.68718327,\n",
       "        0.67570532, 0.68243703, 0.67757734, 0.68194539, 0.68084865,\n",
       "        0.68491415, 0.69247788, 0.68563271, 0.68166175, 0.6902844 ,\n",
       "        0.67092126, 0.68676726, 0.68243703, 0.68228576, 0.69268588,\n",
       "        0.6825694 , 0.69141895, 0.68251267, 0.68309886, 0.67950609,\n",
       "        0.67239619, 0.67665078, 0.68722109, 0.68343923, 0.69669465]),\n",
       " 'split2_test_score': array([0.64225475, 0.63535285, 0.64263293, 0.64185765, 0.62552001,\n",
       "        0.62748657, 0.63295137, 0.62465018, 0.63416156, 0.63697905,\n",
       "        0.64225475, 0.63535285, 0.64263293, 0.64185765, 0.62552001,\n",
       "        0.62748657, 0.63295137, 0.62465018, 0.63416156, 0.63697905,\n",
       "        0.64737917, 0.6435784 , 0.64132819, 0.6360714 , 0.64925119,\n",
       "        0.64263293, 0.61731337, 0.62597383, 0.63030406, 0.64968611,\n",
       "        0.63650632, 0.62968005, 0.65745783, 0.63416156, 0.65095303,\n",
       "        0.62232433, 0.62928296, 0.64287875, 0.6386998 , 0.63372665,\n",
       "        0.63650632, 0.62968005, 0.65745783, 0.63416156, 0.65095303,\n",
       "        0.62232433, 0.62928296, 0.64287875, 0.6386998 , 0.63372665,\n",
       "        0.64340821, 0.62574692, 0.65897058, 0.63399138, 0.63792451,\n",
       "        0.64522351, 0.62837531, 0.63588231, 0.63325391, 0.63461538,\n",
       "        0.64110128, 0.64382422, 0.64675516, 0.63644959, 0.64034491,\n",
       "        0.64119582, 0.63503139, 0.65095303, 0.63601467, 0.63956962,\n",
       "        0.64110128, 0.64382422, 0.64675516, 0.63644959, 0.64034491,\n",
       "        0.64119582, 0.63503139, 0.65095303, 0.63601467, 0.63956962,\n",
       "        0.6452046 , 0.63941835, 0.63544739, 0.63881325, 0.63408592,\n",
       "        0.64858937, 0.62574692, 0.62901823, 0.62799713, 0.64025036,\n",
       "        0.63682777, 0.63656304, 0.64475078, 0.64584752, 0.63866198,\n",
       "        0.63737614, 0.64034491, 0.62884804, 0.63157099, 0.62945314]),\n",
       " 'split3_test_score': array([0.69015203, 0.68595416, 0.68722109, 0.68117011, 0.68062174,\n",
       "        0.68937675, 0.69041676, 0.6886771 , 0.67702897, 0.68741018,\n",
       "        0.69015203, 0.68595416, 0.68722109, 0.68117011, 0.68062174,\n",
       "        0.68937675, 0.69041676, 0.6886771 , 0.67702897, 0.68741018,\n",
       "        0.69514409, 0.68377959, 0.68152939, 0.68168066, 0.6783148 ,\n",
       "        0.68255049, 0.68971712, 0.67806898, 0.68565161, 0.68986839,\n",
       "        0.68913093, 0.67814462, 0.67842826, 0.6738333 , 0.69037894,\n",
       "        0.68773164, 0.68048937, 0.68183193, 0.68221012, 0.68472506,\n",
       "        0.68913093, 0.67814462, 0.67842826, 0.6738333 , 0.69037894,\n",
       "        0.68773164, 0.68048937, 0.68183193, 0.68221012, 0.68472506,\n",
       "        0.69134332, 0.66891687, 0.68421451, 0.68381741, 0.67882535,\n",
       "        0.68498979, 0.67988428, 0.68920657, 0.68731563, 0.68629453,\n",
       "        0.68616217, 0.67670751, 0.70359655, 0.6831745 , 0.68313668,\n",
       "        0.68797746, 0.67748279, 0.69036003, 0.6907004 , 0.68606762,\n",
       "        0.68616217, 0.67670751, 0.70359655, 0.6831745 , 0.68313668,\n",
       "        0.68797746, 0.67748279, 0.69036003, 0.6907004 , 0.68606762,\n",
       "        0.69406626, 0.67579986, 0.69444444, 0.68932002, 0.68899856,\n",
       "        0.69136223, 0.68391196, 0.68098102, 0.68612435, 0.68969821,\n",
       "        0.70306709, 0.67752061, 0.67946827, 0.68986839, 0.68245594,\n",
       "        0.68376068, 0.69370698, 0.68894183, 0.68841237, 0.67950609]),\n",
       " 'split4_test_score': array([0.63573103, 0.64511005, 0.63298918, 0.6344452 , 0.64414568,\n",
       "        0.64210347, 0.64259511, 0.63921035, 0.64493987, 0.64346494,\n",
       "        0.63573103, 0.64511005, 0.63298918, 0.6344452 , 0.64414568,\n",
       "        0.64210347, 0.64259511, 0.63921035, 0.64493987, 0.64346494,\n",
       "        0.64843809, 0.66010514, 0.63072007, 0.63370774, 0.64047727,\n",
       "        0.64490205, 0.63410483, 0.63480448, 0.64250057, 0.64259511,\n",
       "        0.64410786, 0.65938658, 0.63747069, 0.64429695, 0.65989713,\n",
       "        0.6362794 , 0.63711141, 0.6521065 , 0.63062552, 0.64121473,\n",
       "        0.64410786, 0.65938658, 0.63747069, 0.64429695, 0.65989713,\n",
       "        0.6362794 , 0.63711141, 0.6521065 , 0.63062552, 0.64121473,\n",
       "        0.64501551, 0.65165267, 0.64475078, 0.63185463, 0.63045534,\n",
       "        0.62856441, 0.6443915 , 0.64323803, 0.64076091, 0.65212541,\n",
       "        0.63973981, 0.64770063, 0.64386204, 0.62979351, 0.65065048,\n",
       "        0.64314348, 0.64303003, 0.64015581, 0.64548824, 0.64779517,\n",
       "        0.63973981, 0.64770063, 0.64386204, 0.62979351, 0.65065048,\n",
       "        0.64314348, 0.64303003, 0.64015581, 0.64548824, 0.64779517,\n",
       "        0.65174722, 0.64442932, 0.64223584, 0.63699796, 0.64042054,\n",
       "        0.64335149, 0.63329173, 0.64919446, 0.64815445, 0.64335149,\n",
       "        0.64698207, 0.66647757, 0.63716814, 0.63297027, 0.65339233,\n",
       "        0.6301717 , 0.63531503, 0.64437259, 0.64306785, 0.6539407 ]),\n",
       " 'mean_test_score': array([0.66076852, 0.65967254, 0.66065508, 0.65808355, 0.65755026,\n",
       "        0.66471401, 0.6650858 , 0.65997113, 0.66124831, 0.66273172,\n",
       "        0.66076852, 0.65967254, 0.66065508, 0.65808355, 0.65755026,\n",
       "        0.66471401, 0.6650858 , 0.65997113, 0.66124831, 0.66273172,\n",
       "        0.66498612, 0.6661619 , 0.66044614, 0.66026958, 0.66511866,\n",
       "        0.66347215, 0.65910717, 0.66185895, 0.66402785, 0.66615415,\n",
       "        0.66219732, 0.66147989, 0.66478184, 0.655415  , 0.67292417,\n",
       "        0.66085499, 0.65820498, 0.66723601, 0.66034013, 0.66165326,\n",
       "        0.66219732, 0.66147989, 0.66478184, 0.655415  , 0.67292417,\n",
       "        0.66085499, 0.65820498, 0.66723601, 0.66034013, 0.66165326,\n",
       "        0.66547741, 0.65874115, 0.66282215, 0.65982143, 0.66347558,\n",
       "        0.66185962, 0.65876371, 0.66067089, 0.66219754, 0.66571372,\n",
       "        0.66319441, 0.66293414, 0.66827567, 0.65674746, 0.66669566,\n",
       "        0.66482848, 0.66244719, 0.66552952, 0.6652661 , 0.66237168,\n",
       "        0.66319441, 0.66293414, 0.66827567, 0.65674746, 0.66669566,\n",
       "        0.66482848, 0.66244719, 0.66552952, 0.6652661 , 0.66237168,\n",
       "        0.66431621, 0.66137899, 0.66406253, 0.66332762, 0.66720684,\n",
       "        0.66426363, 0.65910228, 0.6603768 , 0.66342785, 0.66602046,\n",
       "        0.66475272, 0.66519165, 0.66202536, 0.66431849, 0.66779494,\n",
       "        0.65582299, 0.66388865, 0.66414347, 0.66426586, 0.66421832]),\n",
       " 'std_test_score': array([0.02400529, 0.0221551 , 0.02156611, 0.01976175, 0.02033541,\n",
       "        0.02517305, 0.0229724 , 0.0251486 , 0.0184825 , 0.02044222,\n",
       "        0.02400529, 0.0221551 , 0.02156611, 0.01976175, 0.02033541,\n",
       "        0.02517305, 0.0229724 , 0.0251486 , 0.0184825 , 0.02044222,\n",
       "        0.02026249, 0.01662932, 0.02447533, 0.02138125, 0.01678585,\n",
       "        0.01771743, 0.02855442, 0.02602563, 0.02330073, 0.0190539 ,\n",
       "        0.02080888, 0.019027  , 0.01782045, 0.01502442, 0.01509171,\n",
       "        0.02649762, 0.02179498, 0.01696518, 0.02156278, 0.02059135,\n",
       "        0.02080888, 0.019027  , 0.01782045, 0.01502442, 0.01509171,\n",
       "        0.02649762, 0.02179498, 0.01696518, 0.02156278, 0.02059135,\n",
       "        0.02154322, 0.02293902, 0.01462211, 0.02238767, 0.02443824,\n",
       "        0.02153991, 0.02091886, 0.01948005, 0.02153739, 0.01990115,\n",
       "        0.02114441, 0.01880558, 0.0228718 , 0.02217233, 0.01828524,\n",
       "        0.01902854, 0.01946141, 0.01804128, 0.02107007, 0.01821148,\n",
       "        0.02114441, 0.01880558, 0.0228718 , 0.02217233, 0.01828524,\n",
       "        0.01902854, 0.01946141, 0.01804128, 0.02107007, 0.01821148,\n",
       "        0.02088562, 0.01994166, 0.0231769 , 0.02167223, 0.02469045,\n",
       "        0.01714449, 0.02531564, 0.0200978 , 0.02210467, 0.02215078,\n",
       "        0.02445372, 0.01890434, 0.01820951, 0.02172333, 0.0184545 ,\n",
       "        0.02026638, 0.02242194, 0.0238155 , 0.02271903, 0.02284767]),\n",
       " 'rank_test_score': array([71, 84, 74, 92, 94, 30, 22, 81, 67, 50, 71, 84, 74, 92, 94, 30, 22,\n",
       "        81, 67, 50, 24, 11, 76, 80, 21, 42, 86, 61, 39, 12, 57, 64, 27, 99,\n",
       "         1, 69, 90,  6, 78, 62, 57, 64, 27, 99,  1, 69, 90,  6, 78, 62, 17,\n",
       "        89, 49, 83, 41, 60, 88, 73, 56, 14, 45, 47,  3, 96,  9, 25, 52, 15,\n",
       "        18, 54, 45, 47,  3, 96,  9, 25, 52, 15, 18, 54, 33, 66, 38, 44,  8,\n",
       "        35, 87, 77, 43, 13, 29, 20, 59, 32,  5, 98, 40, 37, 34, 36])}"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch5.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Accuracy : 0.8\n",
      "AUC Score (Train): 0.777778\n"
     ]
    }
   ],
   "source": [
    "xgb15 = XGBClassifier(\n",
    " learning_rate =learning_rate,\n",
    " n_estimators=n_estimators,\n",
    " max_depth=max_depth,\n",
    " min_child_weight=min_child_weight,\n",
    " gamma=gamma,\n",
    " subsample=subsample,\n",
    " colsample_bytree=colsample_bytree,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=seed)\n",
    "modelfit(xgb15, X_train,y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:32:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'reg_alpha': 1e-05}, 0.6229069509216079)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test6 = {\n",
    " 'reg_alpha':[1e-5, 1e-2, 0.1,0.0, 1, 100]\n",
    "}\n",
    "gsearch6 = GridSearchCV(estimator = XGBClassifier( learning_rate=learning_rate, n_estimators=n_estimators, max_depth=max_depth,\n",
    " min_child_weight=min_child_weight, gamma=gamma, subsample=subsample, colsample_bytree=colsample_bytree,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=seed), \n",
    " param_grid = param_test6, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch6.fit(X,y)\n",
    "gsearch6.best_params_, gsearch6.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:34:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'reg_alpha': 0.0}, 0.6229069509216079)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test7 = {\n",
    " 'reg_alpha':[i/100000.0 for i in range(0,10)]\n",
    "}\n",
    "gsearch7 = GridSearchCV(estimator = XGBClassifier( learning_rate=learning_rate, n_estimators=n_estimators, max_depth=max_depth,\n",
    " min_child_weight=min_child_weight, gamma=gamma, subsample=subsample, colsample_bytree=colsample_bytree,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=seed), \n",
    " param_grid = param_test7, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch7.fit(X,y)\n",
    "gsearch7.best_params_, gsearch7.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_alpha= 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Accuracy : 0.8\n",
      "AUC Score (Train): 0.833333\n"
     ]
    }
   ],
   "source": [
    "xgb3 = XGBClassifier(\n",
    " learning_rate =learning_rate,\n",
    " n_estimators=n_estimators,\n",
    " max_depth=max_depth,\n",
    " min_child_weight=min_child_weight,\n",
    " gamma=gamma,\n",
    " subsample=subsample,\n",
    " colsample_bytree=colsample_bytree,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " reg_alpha= 0.0,\n",
    " reg_lambda=1,\n",
    " scale_pos_weight=1,\n",
    " seed=seed)\n",
    "modelfit(xgb3, X,y, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:39:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'reg_lambda': 1}, 0.6229069509216079)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test8 = {\n",
    " 'reg_lambda':[1e-5, 1e-6,0.0, 0.1, 1,2,3, 100]\n",
    "}\n",
    "gsearch8 = GridSearchCV(estimator = XGBClassifier( learning_rate=learning_rate, n_estimators=n_estimators, max_depth=max_depth,\n",
    " min_child_weight=min_child_weight, gamma=gamma, subsample=subsample, colsample_bytree=colsample_bytree,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=seed),  \n",
    " param_grid = param_test8, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch8.fit(X,y)\n",
    "gsearch8.best_params_, gsearch8.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:44:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'reg_lambda': 1.0}, 0.6229069509216079)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test9 = {\n",
    " 'reg_lambda':[i*0.001 for i in range(995,1005)]\n",
    "}\n",
    "gsearch9 = GridSearchCV(estimator = XGBClassifier( learning_rate=learning_rate, n_estimators=n_estimators, max_depth=max_depth,\n",
    " min_child_weight=min_child_weight, gamma=gamma, subsample=subsample, colsample_bytree=colsample_bytree,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=seed), \n",
    " param_grid = param_test9, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch9.fit(X,y)\n",
    "gsearch9.best_params_, gsearch9.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_lambda= 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test9 = {\n",
    " 'reg_lambda':[i*0.000001 for i in range(0,11)]\n",
    "}\n",
    "gsearch9 = GridSearchCV(estimator = XGBClassifier( learning_rate=learning_rate, n_estimators=n_estimators, max_depth=max_depth,\n",
    " min_child_weight=min_child_weight, gamma=gamma, subsample=subsample, colsample_bytree=colsample_bytree,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=seed), \n",
    " param_grid = param_test9, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch9.fit(X,y)\n",
    "gsearch9.best_params_, gsearch9.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:38:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'learning_rate': 0.001, 'n_estimators': 7000}, 0.6280701754385964)"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test10 = {\n",
    " 'learning_rate':[0.1,0.01,0.001,0.0001],\n",
    " 'n_estimators':[5000,6000,4000,7000],\n",
    "}\n",
    "gsearch10 = GridSearchCV(estimator = XGBClassifier( learning_rate=learning_rate, n_estimators=n_estimators, max_depth=max_depth,\n",
    " min_child_weight=min_child_weight, gamma=gamma, subsample=subsample, colsample_bytree=colsample_bytree,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=seed),  \n",
    " param_grid = param_test10, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch10.fit(X,y)\n",
    "gsearch10.best_params_, gsearch10.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Accuracy : 0.68\n",
      "AUC Score (Train): 0.729167\n"
     ]
    }
   ],
   "source": [
    "xgb4 = XGBClassifier(\n",
    " learning_rate = 0.005557,\n",
    " n_estimators=7000,\n",
    " max_depth=max_depth,\n",
    " min_child_weight=min_child_weight,\n",
    " gamma=gamma,\n",
    " subsample=subsample,\n",
    " colsample_bytree=colsample_bytree,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " reg_alpha= reg_alpha,\n",
    " reg_lambda=reg_lambda,\n",
    " scale_pos_weight=1,\n",
    " seed=seed)\n",
    "modelfit(xgb4, X_train,y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1591\n"
     ]
    }
   ],
   "source": [
    "predicted_y = xgb4.predict(X_Sample_Test)\n",
    "predicted_y = list(predicted_y)\n",
    "w_list = []\n",
    "for j in range(len(predicted_y)):\n",
    "    w_list.append({\"Id\":(j+1), \"Category\":predicted_y[j]})\n",
    "print(len(w_list))\n",
    "with open('predictions'+'.csv', 'w', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=[\"Id\", \"Category\"])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(w_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base')",
   "language": "python",
   "name": "python37664bitbase3d920d87e3644dc8a79788ca4d0afcae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

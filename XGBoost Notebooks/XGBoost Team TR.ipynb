{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set() # if you want to use seaborn themes with matplotlib functions\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('CSE_DSIntro1_TRAIN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_state = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Column_1</th>\n",
       "      <th>Column_2</th>\n",
       "      <th>Column_3</th>\n",
       "      <th>Column_4</th>\n",
       "      <th>Column_5</th>\n",
       "      <th>Column_6</th>\n",
       "      <th>Column_7</th>\n",
       "      <th>Column_8</th>\n",
       "      <th>Column_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Column_69</th>\n",
       "      <th>Column_70</th>\n",
       "      <th>Column_71</th>\n",
       "      <th>Column_72</th>\n",
       "      <th>Column_73</th>\n",
       "      <th>Column_74</th>\n",
       "      <th>Column_75</th>\n",
       "      <th>Column_76</th>\n",
       "      <th>Column_77</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>77041.5</td>\n",
       "      <td>44471.03389</td>\n",
       "      <td>88955.41342</td>\n",
       "      <td>1602.4632</td>\n",
       "      <td>1787.3628</td>\n",
       "      <td>1571.6466</td>\n",
       "      <td>1294.2972</td>\n",
       "      <td>1664.0964</td>\n",
       "      <td>1756.5462</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>77120.0</td>\n",
       "      <td>44516.34682</td>\n",
       "      <td>89046.05288</td>\n",
       "      <td>1573.2480</td>\n",
       "      <td>2128.5120</td>\n",
       "      <td>987.1360</td>\n",
       "      <td>956.2880</td>\n",
       "      <td>1511.5520</td>\n",
       "      <td>1388.1600</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>77120.0</td>\n",
       "      <td>44516.34682</td>\n",
       "      <td>89046.05288</td>\n",
       "      <td>1789.1840</td>\n",
       "      <td>1511.5520</td>\n",
       "      <td>1665.7920</td>\n",
       "      <td>1326.4640</td>\n",
       "      <td>1357.3120</td>\n",
       "      <td>1634.9440</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>77117.5</td>\n",
       "      <td>44514.90373</td>\n",
       "      <td>89043.16628</td>\n",
       "      <td>1511.5030</td>\n",
       "      <td>1789.1260</td>\n",
       "      <td>1233.8800</td>\n",
       "      <td>1881.6670</td>\n",
       "      <td>1418.9620</td>\n",
       "      <td>2159.2900</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>77120.0</td>\n",
       "      <td>44516.34682</td>\n",
       "      <td>89046.05288</td>\n",
       "      <td>1974.2720</td>\n",
       "      <td>1696.6400</td>\n",
       "      <td>832.8960</td>\n",
       "      <td>1820.0320</td>\n",
       "      <td>1758.3360</td>\n",
       "      <td>1727.4880</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>2496</td>\n",
       "      <td>77117.5</td>\n",
       "      <td>44514.90373</td>\n",
       "      <td>89043.16628</td>\n",
       "      <td>1203.0330</td>\n",
       "      <td>2282.6780</td>\n",
       "      <td>1542.3500</td>\n",
       "      <td>1758.2790</td>\n",
       "      <td>1850.8200</td>\n",
       "      <td>1295.5740</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>42</td>\n",
       "      <td>33</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>2497</td>\n",
       "      <td>77120.0</td>\n",
       "      <td>44516.34682</td>\n",
       "      <td>89046.05288</td>\n",
       "      <td>894.5920</td>\n",
       "      <td>1203.0720</td>\n",
       "      <td>1079.6800</td>\n",
       "      <td>1480.7040</td>\n",
       "      <td>1449.8560</td>\n",
       "      <td>1604.0960</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>42</td>\n",
       "      <td>34</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>2498</td>\n",
       "      <td>77117.5</td>\n",
       "      <td>44514.90373</td>\n",
       "      <td>89043.16628</td>\n",
       "      <td>1789.1260</td>\n",
       "      <td>1604.0440</td>\n",
       "      <td>1326.4210</td>\n",
       "      <td>1418.9620</td>\n",
       "      <td>1542.3500</td>\n",
       "      <td>1511.5030</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>42</td>\n",
       "      <td>34</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>2499</td>\n",
       "      <td>77117.5</td>\n",
       "      <td>44514.90373</td>\n",
       "      <td>89043.16628</td>\n",
       "      <td>1789.1260</td>\n",
       "      <td>524.3990</td>\n",
       "      <td>1511.5030</td>\n",
       "      <td>1357.2680</td>\n",
       "      <td>863.7160</td>\n",
       "      <td>616.9400</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>42</td>\n",
       "      <td>35</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>2500</td>\n",
       "      <td>77120.0</td>\n",
       "      <td>44516.34682</td>\n",
       "      <td>89046.05288</td>\n",
       "      <td>1542.4000</td>\n",
       "      <td>1789.1840</td>\n",
       "      <td>1850.8800</td>\n",
       "      <td>1511.5520</td>\n",
       "      <td>1758.3360</td>\n",
       "      <td>1326.4640</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>42</td>\n",
       "      <td>35</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows Ã— 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  Column_1     Column_2     Column_3   Column_4   Column_5  \\\n",
       "0        1   77041.5  44471.03389  88955.41342  1602.4632  1787.3628   \n",
       "1        2   77120.0  44516.34682  89046.05288  1573.2480  2128.5120   \n",
       "2        3   77120.0  44516.34682  89046.05288  1789.1840  1511.5520   \n",
       "3        4   77117.5  44514.90373  89043.16628  1511.5030  1789.1260   \n",
       "4        5   77120.0  44516.34682  89046.05288  1974.2720  1696.6400   \n",
       "...    ...       ...          ...          ...        ...        ...   \n",
       "2495  2496   77117.5  44514.90373  89043.16628  1203.0330  2282.6780   \n",
       "2496  2497   77120.0  44516.34682  89046.05288   894.5920  1203.0720   \n",
       "2497  2498   77117.5  44514.90373  89043.16628  1789.1260  1604.0440   \n",
       "2498  2499   77117.5  44514.90373  89043.16628  1789.1260   524.3990   \n",
       "2499  2500   77120.0  44516.34682  89046.05288  1542.4000  1789.1840   \n",
       "\n",
       "       Column_6   Column_7   Column_8   Column_9  ...  Column_69  Column_70  \\\n",
       "0     1571.6466  1294.2972  1664.0964  1756.5462  ...         22          2   \n",
       "1      987.1360   956.2880  1511.5520  1388.1600  ...         22          2   \n",
       "2     1665.7920  1326.4640  1357.3120  1634.9440  ...         22          2   \n",
       "3     1233.8800  1881.6670  1418.9620  2159.2900  ...         22          2   \n",
       "4      832.8960  1820.0320  1758.3360  1727.4880  ...         22          2   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "2495  1542.3500  1758.2790  1850.8200  1295.5740  ...         22          2   \n",
       "2496  1079.6800  1480.7040  1449.8560  1604.0960  ...         22          2   \n",
       "2497  1326.4210  1418.9620  1542.3500  1511.5030  ...         22          2   \n",
       "2498  1511.5030  1357.2680   863.7160   616.9400  ...         22          2   \n",
       "2499  1850.8800  1511.5520  1758.3360  1326.4640  ...         22          2   \n",
       "\n",
       "      Column_71  Column_72  Column_73  Column_74  Column_75  Column_76  \\\n",
       "0          2021         11         23         15         22          2   \n",
       "1          2021         11         23         15         22          2   \n",
       "2          2021         11         23         15         22          2   \n",
       "3          2021         11         23         16         22          2   \n",
       "4          2021         11         23         16         22          2   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "2495       2021         11         42         33         22          2   \n",
       "2496       2021         11         42         34         22          2   \n",
       "2497       2021         11         42         34         22          2   \n",
       "2498       2021         11         42         35         22          2   \n",
       "2499       2021         11         42         35         22          2   \n",
       "\n",
       "      Column_77  Category  \n",
       "0          2021         0  \n",
       "1          2021         0  \n",
       "2          2021         0  \n",
       "3          2021         0  \n",
       "4          2021         0  \n",
       "...         ...       ...  \n",
       "2495       2021         1  \n",
       "2496       2021         1  \n",
       "2497       2021         1  \n",
       "2498       2021         0  \n",
       "2499       2021         0  \n",
       "\n",
       "[2500 rows x 79 columns]"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id           0.0\n",
       "Column_1     0.0\n",
       "Column_2     0.0\n",
       "Column_3     0.0\n",
       "Column_4     0.0\n",
       "            ... \n",
       "Column_74    0.0\n",
       "Column_75    0.0\n",
       "Column_76    0.0\n",
       "Column_77    0.0\n",
       "Category     0.0\n",
       "Length: 79, dtype: float64"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()/len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(dataset.duplicated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the duplicates:\n",
    "dataset.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 1 Column_55\n",
      "57 1 Column_57\n",
      "66 1 Column_66\n",
      "69 1 Column_69\n",
      "70 1 Column_70\n",
      "71 1 Column_71\n",
      "72 1 Column_72\n",
      "75 1 Column_75\n",
      "76 1 Column_76\n",
      "77 1 Column_77\n"
     ]
    }
   ],
   "source": [
    "unique_values = list(dataset.nunique())\n",
    "for i in range(len(unique_values)):\n",
    "    if unique_values[i] == 1:\n",
    "        print(i, unique_values[i],dataset.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find 55\n",
      "find 57\n",
      "find 66\n",
      "find 69\n",
      "find 70\n",
      "find 71\n",
      "find 72\n",
      "find 75\n",
      "find 76\n",
      "find 77\n",
      "        Id  Column_1     Column_2     Column_3   Column_4   Column_5  \\\n",
      "0        1   77041.5  44471.03389  88955.41342  1602.4632  1787.3628   \n",
      "1        2   77120.0  44516.34682  89046.05288  1573.2480  2128.5120   \n",
      "2        3   77120.0  44516.34682  89046.05288  1789.1840  1511.5520   \n",
      "3        4   77117.5  44514.90373  89043.16628  1511.5030  1789.1260   \n",
      "4        5   77120.0  44516.34682  89046.05288  1974.2720  1696.6400   \n",
      "...    ...       ...          ...          ...        ...        ...   \n",
      "2495  2496   77117.5  44514.90373  89043.16628  1203.0330  2282.6780   \n",
      "2496  2497   77120.0  44516.34682  89046.05288   894.5920  1203.0720   \n",
      "2497  2498   77117.5  44514.90373  89043.16628  1789.1260  1604.0440   \n",
      "2498  2499   77117.5  44514.90373  89043.16628  1789.1260   524.3990   \n",
      "2499  2500   77120.0  44516.34682  89046.05288  1542.4000  1789.1840   \n",
      "\n",
      "       Column_6   Column_7   Column_8   Column_9  ...  Column_61    Column_62  \\\n",
      "0     1571.6466  1294.2972  1664.0964  1756.5462  ...   1.511108  63642.86256   \n",
      "1      987.1360   956.2880  1511.5520  1388.1600  ...   1.511097  63649.22304   \n",
      "2     1665.7920  1326.4640  1357.3120  1634.9440  ...   1.511247  63658.20567   \n",
      "3     1233.8800  1881.6670  1418.9620  2159.2900  ...   1.511245  63655.53620   \n",
      "4      832.8960  1820.0320  1758.3360  1727.4880  ...   1.511409  63637.01387   \n",
      "...         ...        ...        ...        ...  ...        ...          ...   \n",
      "2495  1542.3500  1758.2790  1850.8200  1295.5740  ...   1.511090  63689.52068   \n",
      "2496  1079.6800  1480.7040  1449.8560  1604.0960  ...   1.511129  63696.82226   \n",
      "2497  1326.4210  1418.9620  1542.3500  1511.5030  ...   1.511286  63695.04189   \n",
      "2498  1511.5030  1357.2680   863.7160   616.9400  ...   1.511245  63683.13411   \n",
      "2499  1850.8800  1511.5520  1758.3360  1326.4640  ...   1.511552  63697.79604   \n",
      "\n",
      "      Column_63  Column_64  Column_65  Column_67  Column_68  Column_73  \\\n",
      "0      1.527652   0.073507   1.511320         23         15         23   \n",
      "1      1.527373   0.073794   1.511169         23         15         23   \n",
      "2      1.527631   0.073571   1.511256         23         15         23   \n",
      "3      1.527550   0.073430   1.511489         23         16         23   \n",
      "4      1.527490   0.073543   1.511393         23         16         23   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "2495   1.527730   0.073834   1.510860         42         33         42   \n",
      "2496   1.527971   0.073253   1.511402         42         34         42   \n",
      "2497   1.527891   0.073301   1.511400         42         34         42   \n",
      "2498   1.527758   0.073542   1.511201         42         35         42   \n",
      "2499   1.527767   0.073461   1.511293         42         35         42   \n",
      "\n",
      "      Column_74  Category  \n",
      "0            15         0  \n",
      "1            15         0  \n",
      "2            15         0  \n",
      "3            16         0  \n",
      "4            16         0  \n",
      "...         ...       ...  \n",
      "2495         33         1  \n",
      "2496         34         1  \n",
      "2497         34         1  \n",
      "2498         35         0  \n",
      "2499         35         0  \n",
      "\n",
      "[2500 rows x 69 columns]\n"
     ]
    }
   ],
   "source": [
    "unique_values = list(dataset.nunique())\n",
    "k=0\n",
    "for i in range(len(unique_values)):\n",
    "    if unique_values[i] == 1:\n",
    "        print('find', i)\n",
    "        dataset.drop(dataset.columns[i-k], axis=1 ,inplace=True)\n",
    "        k+=1\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'Column_1', 'Column_2', 'Column_3', 'Column_4', 'Column_5',\n",
       "       'Column_6', 'Column_7', 'Column_8', 'Column_9', 'Column_10',\n",
       "       'Column_11', 'Column_12', 'Column_13', 'Column_14', 'Column_15',\n",
       "       'Column_16', 'Column_17', 'Column_18', 'Column_19', 'Column_20',\n",
       "       'Column_21', 'Column_22', 'Column_23', 'Column_24', 'Column_25',\n",
       "       'Column_26', 'Column_27', 'Column_28', 'Column_29', 'Column_30',\n",
       "       'Column_31', 'Column_32', 'Column_33', 'Column_34', 'Column_35',\n",
       "       'Column_36', 'Column_37', 'Column_38', 'Column_39', 'Column_40',\n",
       "       'Column_41', 'Column_42', 'Column_43', 'Column_44', 'Column_45',\n",
       "       'Column_46', 'Column_47', 'Column_48', 'Column_49', 'Column_50',\n",
       "       'Column_51', 'Column_52', 'Column_53', 'Column_54', 'Column_56',\n",
       "       'Column_58', 'Column_59', 'Column_60', 'Column_61', 'Column_62',\n",
       "       'Column_63', 'Column_64', 'Column_65', 'Column_67', 'Column_68',\n",
       "       'Column_73', 'Column_74', 'Category'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('CSE_DSIntro1_TEST.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 1 Column_55\n",
      "57 1 Column_57\n",
      "66 1 Column_66\n",
      "69 1 Column_69\n",
      "70 1 Column_70\n",
      "71 1 Column_71\n",
      "72 1 Column_72\n",
      "75 1 Column_75\n",
      "76 1 Column_76\n",
      "77 1 Column_77\n"
     ]
    }
   ],
   "source": [
    "unique_values_test = list(test_data.nunique())\n",
    "for i in range(len(unique_values_test)):\n",
    "    if unique_values_test[i] == 1:\n",
    "        print(i, unique_values_test[i],test_data.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find 55\n",
      "find 57\n",
      "find 66\n",
      "find 69\n",
      "find 70\n",
      "find 71\n",
      "find 72\n",
      "find 75\n",
      "find 76\n",
      "find 77\n",
      "        Id  Column_1     Column_2     Column_3   Column_4   Column_5  \\\n",
      "0        1  77117.50  44514.90373  89043.16628  1696.5850  1665.7380   \n",
      "1        2  77120.00  44516.34682  89046.05288  1357.3120   339.3280   \n",
      "2        3  77120.00  44516.34682  89046.05288  1758.3360  1974.2720   \n",
      "3        4  77120.00  44516.34682  89046.05288  1110.5280  1264.7680   \n",
      "4        5  77120.00  44516.34682  89046.05288  2652.9280  2005.1200   \n",
      "...    ...       ...          ...          ...        ...        ...   \n",
      "1586  1587  77120.00  44516.34682  89046.05288  1789.1840  1881.7280   \n",
      "1587  1588  77117.50  44514.90373  89043.16628  1696.5850  1357.2680   \n",
      "1588  1589  77122.25  44517.64560  89048.65083  1696.6895  1727.5384   \n",
      "1589  1590  77122.25  44517.64560  89048.65083  1449.8983  1789.2362   \n",
      "1590  1591  77122.25  44517.64560  89048.65083  1449.8983  1326.5027   \n",
      "\n",
      "       Column_6   Column_7   Column_8   Column_9  ...  Column_60  Column_61  \\\n",
      "0     1418.9620  1264.7270  1203.0330  1573.1970  ...   0.073235   1.511481   \n",
      "1     1326.4640  1017.9840  1573.2480  1604.0960  ...   0.073413   1.511241   \n",
      "2     1480.7040  1141.3760  1542.4000  1388.1600  ...   0.073253   1.511402   \n",
      "3     1388.1600  1449.8560  1573.2480  1419.0080  ...   0.073415   1.511293   \n",
      "4     1943.4240   493.5680  1388.1600   740.3520  ...   0.073395   1.511170   \n",
      "...         ...        ...        ...        ...  ...        ...        ...   \n",
      "1586  1449.8560  1573.2480  1419.0080  1542.4000  ...   0.073209   1.511755   \n",
      "1587  1727.4320  1542.3500  1295.5740  1449.8090  ...   0.073503   1.511498   \n",
      "1588  1573.2939  1449.8983   246.7912  1480.7472  ...   0.073398   1.511532   \n",
      "1589  1634.9917  1203.1071  1326.5027  1357.3516  ...   0.073327   1.511689   \n",
      "1590  1388.2005   154.2445  1480.7472  1048.8626  ...   0.073095   1.511757   \n",
      "\n",
      "        Column_62  Column_63  Column_64  Column_65  Column_67  Column_68  \\\n",
      "0     63697.96460   1.527815   0.073497   1.511214         42         36   \n",
      "1     63707.62973   1.527853   0.073633   1.511019         42         36   \n",
      "2     63699.33986   1.527973   0.073148   1.511530         42         36   \n",
      "3     63691.57205   1.527999   0.073202   1.511444         42         37   \n",
      "4     63691.78617   1.527921   0.073248   1.511445         42         37   \n",
      "...           ...        ...        ...        ...        ...        ...   \n",
      "1586  63656.58449   1.527551   0.073225   1.511742         56          0   \n",
      "1587  63655.56354   1.527707   0.073006   1.511899         56          0   \n",
      "1588  63659.57645   1.527553   0.073222   1.511745         56          1   \n",
      "1589  63638.76254   1.527492   0.073274   1.511726         56          1   \n",
      "1590  63657.61274   1.527457   0.073445   1.511539         56          2   \n",
      "\n",
      "      Column_73  Column_74  \n",
      "0            42         36  \n",
      "1            42         36  \n",
      "2            42         37  \n",
      "3            42         37  \n",
      "4            42         37  \n",
      "...         ...        ...  \n",
      "1586         56          0  \n",
      "1587         56          0  \n",
      "1588         56          1  \n",
      "1589         56          1  \n",
      "1590         56          2  \n",
      "\n",
      "[1591 rows x 68 columns]\n"
     ]
    }
   ],
   "source": [
    "k_test=0\n",
    "for i in range(len(unique_values_test)):\n",
    "    if unique_values_test[i] == 1:\n",
    "        print('find', i)\n",
    "        test_data.drop(test_data.columns[i-k_test], axis=1 ,inplace=True)\n",
    "        k_test+=1\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'Column_1', 'Column_2', 'Column_3', 'Column_4', 'Column_5',\n",
       "       'Column_6', 'Column_7', 'Column_8', 'Column_9', 'Column_10',\n",
       "       'Column_11', 'Column_12', 'Column_13', 'Column_14', 'Column_15',\n",
       "       'Column_16', 'Column_17', 'Column_18', 'Column_19', 'Column_20',\n",
       "       'Column_21', 'Column_22', 'Column_23', 'Column_24', 'Column_25',\n",
       "       'Column_26', 'Column_27', 'Column_28', 'Column_29', 'Column_30',\n",
       "       'Column_31', 'Column_32', 'Column_33', 'Column_34', 'Column_35',\n",
       "       'Column_36', 'Column_37', 'Column_38', 'Column_39', 'Column_40',\n",
       "       'Column_41', 'Column_42', 'Column_43', 'Column_44', 'Column_45',\n",
       "       'Column_46', 'Column_47', 'Column_48', 'Column_49', 'Column_50',\n",
       "       'Column_51', 'Column_52', 'Column_53', 'Column_54', 'Column_56',\n",
       "       'Column_58', 'Column_59', 'Column_60', 'Column_61', 'Column_62',\n",
       "       'Column_63', 'Column_64', 'Column_65', 'Column_67', 'Column_68',\n",
       "       'Column_73', 'Column_74'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 1:-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Sample_Test = test_data.values[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.71175000e+04, 4.45149037e+04, 8.90431663e+04, ...,\n",
       "        3.60000000e+01, 4.20000000e+01, 3.60000000e+01],\n",
       "       [7.71200000e+04, 4.45163468e+04, 8.90460529e+04, ...,\n",
       "        3.60000000e+01, 4.20000000e+01, 3.60000000e+01],\n",
       "       [7.71200000e+04, 4.45163468e+04, 8.90460529e+04, ...,\n",
       "        3.60000000e+01, 4.20000000e+01, 3.70000000e+01],\n",
       "       ...,\n",
       "       [7.71222500e+04, 4.45176456e+04, 8.90486508e+04, ...,\n",
       "        1.00000000e+00, 5.60000000e+01, 1.00000000e+00],\n",
       "       [7.71222500e+04, 4.45176456e+04, 8.90486508e+04, ...,\n",
       "        1.00000000e+00, 5.60000000e+01, 1.00000000e+00],\n",
       "       [7.71222500e+04, 4.45176456e+04, 8.90486508e+04, ...,\n",
       "        2.00000000e+00, 5.60000000e+01, 2.00000000e+00]])"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Sample_Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.70415000e+04, 4.44710339e+04, 8.89554134e+04, ...,\n",
       "        1.50000000e+01, 2.30000000e+01, 1.50000000e+01],\n",
       "       [7.71200000e+04, 4.45163468e+04, 8.90460529e+04, ...,\n",
       "        1.50000000e+01, 2.30000000e+01, 1.50000000e+01],\n",
       "       [7.71200000e+04, 4.45163468e+04, 8.90460529e+04, ...,\n",
       "        1.50000000e+01, 2.30000000e+01, 1.50000000e+01],\n",
       "       ...,\n",
       "       [7.71175000e+04, 4.45149037e+04, 8.90431663e+04, ...,\n",
       "        3.40000000e+01, 4.20000000e+01, 3.40000000e+01],\n",
       "       [7.71175000e+04, 4.45149037e+04, 8.90431663e+04, ...,\n",
       "        3.50000000e+01, 4.20000000e+01, 3.50000000e+01],\n",
       "       [7.71200000e+04, 4.45163468e+04, 8.90460529e+04, ...,\n",
       "        3.50000000e+01, 4.20000000e+01, 3.50000000e+01]])"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.01, random_state = rand_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn import  metrics   #Additional scklearn functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelfit(alg, X_train,y_train, X_test, y_test ,useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='auc', early_stopping_rounds=early_stopping_rounds)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(X_train, y_train ,eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(X_test)\n",
    "    dtrain_predprob = alg.predict_proba(X_test)[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"Accuracy : %.4g\" % metrics.accuracy_score(y_test, dtrain_predictions))\n",
    "    print(\"AUC Score (Train): %f\" % metrics.roc_auc_score(y_test, dtrain_predprob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Category'\n",
    "IDcol = 'Id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Accuracy : 0.64\n",
      "AUC Score (Train): 0.715278\n"
     ]
    }
   ],
   "source": [
    "#Choose all predictors except target & IDcols\n",
    "predictors = [x for x in dataset.columns if x not in ['Category', \"Id\"]]\n",
    "xgb1 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb1, X_train,y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:30:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=0.8, gamma=0, gpu_id=None,\n",
       "                                     importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=0.1, max_delta_step=None,\n",
       "                                     max_depth=5, min_child_weight=1,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=1000,...\n",
       "                                     objective='binary:logistic',\n",
       "                                     random_state=None, reg_alpha=None,\n",
       "                                     reg_lambda=None, scale_pos_weight=1,\n",
       "                                     seed=27, subsample=0.8, tree_method=None,\n",
       "                                     use_label_encoder=True,\n",
       "                                     validate_parameters=None, verbosity=None),\n",
       "             iid=False, n_jobs=4,\n",
       "             param_grid={'max_depth': range(1, 10),\n",
       "                         'min_child_weight': range(1, 10)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test1 = {\n",
    " 'max_depth':range(1,10),\n",
    " 'min_child_weight':range(1,10)\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=1000, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_depth': 1, 'min_child_weight': 5}, 0.6523015308926258)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([1.91008239, 1.64763708, 1.78222113, 3.08479815, 2.91430182,\n",
       "        2.73430052, 4.48228693, 4.42098408, 4.24091487, 6.30856457,\n",
       "        5.17404346, 3.91280246]),\n",
       " 'std_fit_time': array([0.1100116 , 0.0100354 , 0.11415692, 0.18550106, 0.13596696,\n",
       "        0.11274504, 0.14470413, 0.62444188, 0.39173578, 0.13305196,\n",
       "        0.18622056, 0.78048816]),\n",
       " 'mean_score_time': array([0.01080251, 0.00848994, 0.00972085, 0.00979843, 0.0102036 ,\n",
       "        0.00780239, 0.0096035 , 0.01032677, 0.01010237, 0.00920444,\n",
       "        0.00900345, 0.01139669]),\n",
       " 'std_score_time': array([0.00205656, 0.00062178, 0.00264379, 0.00172201, 0.00311642,\n",
       "        0.00133597, 0.00326563, 0.00108116, 0.00079073, 0.00115187,\n",
       "        0.00177261, 0.00683335]),\n",
       " 'param_max_depth': masked_array(data=[3, 3, 3, 5, 5, 5, 7, 7, 7, 9, 9, 9],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_child_weight': masked_array(data=[1, 3, 5, 1, 3, 5, 1, 3, 5, 1, 3, 5],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'max_depth': 3, 'min_child_weight': 1},\n",
       "  {'max_depth': 3, 'min_child_weight': 3},\n",
       "  {'max_depth': 3, 'min_child_weight': 5},\n",
       "  {'max_depth': 5, 'min_child_weight': 1},\n",
       "  {'max_depth': 5, 'min_child_weight': 3},\n",
       "  {'max_depth': 5, 'min_child_weight': 5},\n",
       "  {'max_depth': 7, 'min_child_weight': 1},\n",
       "  {'max_depth': 7, 'min_child_weight': 3},\n",
       "  {'max_depth': 7, 'min_child_weight': 5},\n",
       "  {'max_depth': 9, 'min_child_weight': 1},\n",
       "  {'max_depth': 9, 'min_child_weight': 3},\n",
       "  {'max_depth': 9, 'min_child_weight': 5}],\n",
       " 'split0_test_score': array([0.6552218 , 0.6452625 , 0.65051068, 0.64252063, 0.64406588,\n",
       "        0.64022161, 0.62488222, 0.63251423, 0.62995138, 0.65476953,\n",
       "        0.67061772, 0.65092526]),\n",
       " 'split1_test_score': array([0.68451706, 0.68716436, 0.65870585, 0.68576507, 0.68064065,\n",
       "        0.68073519, 0.66451101, 0.6890742 , 0.64701989, 0.68264503,\n",
       "        0.66498374, 0.66006732]),\n",
       " 'split2_test_score': array([0.61888284, 0.62546328, 0.63020952, 0.60855835, 0.60466304,\n",
       "        0.60695106, 0.62669238, 0.63089025, 0.61084638, 0.62667347,\n",
       "        0.60725361, 0.6226647 ]),\n",
       " 'split3_test_score': array([0.67738825, 0.6803381 , 0.68754255, 0.648041  , 0.68084865,\n",
       "        0.66275244, 0.67748279, 0.66401936, 0.67118599, 0.64857046,\n",
       "        0.66407609, 0.66598593]),\n",
       " 'split4_test_score': array([0.62722184, 0.65324106, 0.64410786, 0.62892368, 0.65923531,\n",
       "        0.64953483, 0.6421602 , 0.6177861 , 0.63149535, 0.62909387,\n",
       "        0.60471976, 0.63750851]),\n",
       " 'mean_test_score': array([0.65264636, 0.65829386, 0.65421529, 0.64276175, 0.6538907 ,\n",
       "        0.64803903, 0.64714572, 0.64685683, 0.6380998 , 0.64835047,\n",
       "        0.64233019, 0.64743034]),\n",
       " 'std_test_score': array([0.0261569 , 0.02277125, 0.01909467, 0.02545026, 0.02825153,\n",
       "        0.02464587, 0.02078821, 0.02601003, 0.02013469, 0.02028832,\n",
       "        0.02976966, 0.01567161]),\n",
       " 'rank_test_score': array([ 4,  1,  2, 10,  3,  6,  8,  9, 12,  5, 11,  7])}"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch1.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:31:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'mean_fit_time': array([0.77432899, 0.73982091, 0.72027373, 0.68436933, 0.74101787,\n",
       "         0.85092483, 0.67240162, 0.67718606, 0.66721535, 0.71488829,\n",
       "         1.31029534, 1.19380732, 1.12718658, 1.11800957, 1.34639935,\n",
       "         1.09886146, 1.09666677, 1.1190062 , 1.28576221, 1.08649387,\n",
       "         1.71760678, 1.81514759, 1.61508155, 1.71960182, 1.67911   ,\n",
       "         1.64220839, 1.81813869, 1.52671709, 1.58456283, 1.75550342,\n",
       "         2.46600623, 2.53542051, 2.70915623, 2.3437335 , 2.30833349,\n",
       "         2.08682003, 2.1654099 , 2.05729856, 2.17937374, 2.02977219,\n",
       "         3.18268933, 3.11307573, 2.9136095 , 2.89984655, 2.6700604 ,\n",
       "         2.7324934 , 2.67863793, 2.51667027, 2.67325182, 2.48036709,\n",
       "         3.81958685, 3.58700824, 3.48129034, 3.39592042, 3.09991102,\n",
       "         3.14738412, 3.1210546 , 3.00616174, 2.96646795, 2.91660151,\n",
       "         4.4435195 , 4.19318881, 3.87723312, 3.72583699, 3.6388701 ,\n",
       "         3.53494816, 3.50841932, 3.43162484, 3.28501568, 3.10011044,\n",
       "         5.11113453, 4.60967507, 4.37589984, 4.0928566 , 3.97556853,\n",
       "         3.95043755, 3.7792943 , 3.8293612 , 4.29132586, 3.46772842,\n",
       "         5.67143688, 4.80654864, 4.6567481 , 4.74810543, 4.4963769 ,\n",
       "         4.24963794, 4.07829571, 4.00828238, 3.9671927 , 3.72025275,\n",
       "         5.93852286, 5.32137175, 4.93839612, 5.39796939, 4.59391632,\n",
       "         4.27915883, 4.06692572, 4.28155146, 4.19358749, 3.09293056]),\n",
       "  'std_fit_time': array([0.02946166, 0.02980846, 0.05365378, 0.00739338, 0.11133984,\n",
       "         0.15045329, 0.00438837, 0.00594786, 0.01303383, 0.02579584,\n",
       "         0.15890593, 0.12375134, 0.00270724, 0.00730206, 0.0816817 ,\n",
       "         0.00424987, 0.00720848, 0.04142566, 0.11602116, 0.01522497,\n",
       "         0.12760794, 0.14908264, 0.01803608, 0.14458682, 0.13078295,\n",
       "         0.0489342 , 0.09304414, 0.0149186 , 0.14634343, 0.19597568,\n",
       "         0.25579027, 0.29744959, 0.43206839, 0.36701227, 0.09997073,\n",
       "         0.13167461, 0.14214288, 0.11582725, 0.13568259, 0.12993286,\n",
       "         0.1490559 , 0.20269282, 0.21702762, 0.10952653, 0.12504682,\n",
       "         0.16899763, 0.1406313 , 0.13796721, 0.10848905, 0.11353857,\n",
       "         0.17943147, 0.16031858, 0.09819536, 0.11758204, 0.11946298,\n",
       "         0.15608387, 0.13091509, 0.13802421, 0.15841142, 0.1970798 ,\n",
       "         0.11560878, 0.04323681, 0.16217969, 0.1532173 , 0.13802646,\n",
       "         0.14646184, 0.12051726, 0.10405731, 0.13679329, 0.1745863 ,\n",
       "         0.03667866, 0.05569076, 0.0644205 , 0.12425008, 0.17066669,\n",
       "         0.09741033, 0.174947  , 0.17763901, 0.42896089, 0.06904236,\n",
       "         0.17774978, 0.14112443, 0.03259028, 0.15932025, 0.21517545,\n",
       "         0.12530383, 0.09598401, 0.12733317, 0.21864296, 0.15263883,\n",
       "         0.10746921, 0.03753262, 0.14559507, 0.39684119, 0.08259575,\n",
       "         0.12667212, 0.16413025, 0.12187536, 0.13532674, 0.57051996]),\n",
       "  'mean_score_time': array([0.00857811, 0.00778022, 0.00817857, 0.00738096, 0.00718164,\n",
       "         0.00757961, 0.0071816 , 0.00758033, 0.00757961, 0.00937524,\n",
       "         0.00817895, 0.00777969, 0.00877628, 0.00837851, 0.00877757,\n",
       "         0.00738082, 0.00877733, 0.0095758 , 0.00757952, 0.00758057,\n",
       "         0.00817928, 0.00817752, 0.00857744, 0.00957503, 0.00917597,\n",
       "         0.0089767 , 0.00817847, 0.00778003, 0.00857787, 0.00797906,\n",
       "         0.00917778, 0.00857778, 0.00917549, 0.00877771, 0.00777874,\n",
       "         0.0079793 , 0.008777  , 0.00857787, 0.00877595, 0.0085773 ,\n",
       "         0.0117692 , 0.00857773, 0.00917654, 0.00797906, 0.00837793,\n",
       "         0.00777993, 0.00797939, 0.00877676, 0.008178  , 0.00877872,\n",
       "         0.00857782, 0.00857773, 0.00897593, 0.0085772 , 0.00857797,\n",
       "         0.00877719, 0.00977468, 0.0087769 , 0.00917659, 0.00817871,\n",
       "         0.00957565, 0.00777979, 0.00897679, 0.00797944, 0.00837803,\n",
       "         0.00837851, 0.00877695, 0.00937486, 0.01097121, 0.00817895,\n",
       "         0.0083787 , 0.00817885, 0.00977445, 0.01057262, 0.00937567,\n",
       "         0.00917602, 0.00877724, 0.00937581, 0.00917687, 0.01216784,\n",
       "         0.01077156, 0.00837827, 0.00877728, 0.01196823, 0.00877743,\n",
       "         0.00837774, 0.00937562, 0.00897775, 0.00897632, 0.00897684,\n",
       "         0.00817847, 0.00877724, 0.00877714, 0.0113688 , 0.00937715,\n",
       "         0.01057229, 0.0089767 , 0.00977464, 0.0089767 , 0.00977402]),\n",
       "  'std_score_time': array([1.01756113e-03, 7.45180640e-04, 1.46554474e-03, 4.88616946e-04,\n",
       "         3.99589795e-04, 7.97593819e-04, 3.97825370e-04, 1.35308456e-03,\n",
       "         7.97891681e-04, 1.35373174e-03, 9.77038511e-04, 3.98684475e-04,\n",
       "         1.16198660e-03, 4.88616783e-04, 2.63100601e-03, 4.88538730e-04,\n",
       "         1.93410176e-03, 2.14861491e-03, 1.01640350e-03, 4.89239744e-04,\n",
       "         9.76678880e-04, 4.00073224e-04, 7.97855891e-04, 1.35279617e-03,\n",
       "         1.46601866e-03, 1.66955126e-03, 1.71498578e-03, 7.46531348e-04,\n",
       "         4.88656089e-04, 1.09288466e-03, 1.46781639e-03, 4.89161753e-04,\n",
       "         1.16312105e-03, 1.16268059e-03, 1.16308950e-03, 1.09266695e-03,\n",
       "         7.46315058e-04, 1.01713968e-03, 1.32219779e-03, 4.88675027e-04,\n",
       "         3.85813400e-03, 4.88831087e-04, 3.99208354e-04, 6.30298889e-04,\n",
       "         1.01706496e-03, 3.99041215e-04, 4.76837158e-07, 3.99160456e-04,\n",
       "         7.45843862e-04, 7.46774833e-04, 1.01749499e-03, 4.88246804e-04,\n",
       "         1.89149923e-03, 1.01669097e-03, 7.97760531e-04, 7.46365672e-04,\n",
       "         2.12974103e-03, 7.46289197e-04, 1.71647144e-03, 7.45907147e-04,\n",
       "         4.89044998e-04, 3.99208866e-04, 1.09292811e-03, 6.30600230e-04,\n",
       "         1.01660659e-03, 7.97570067e-04, 7.46556810e-04, 7.99000741e-04,\n",
       "         3.02495990e-03, 3.98755198e-04, 7.97057813e-04, 7.47207183e-04,\n",
       "         1.59633164e-03, 1.62060479e-03, 7.97939372e-04, 1.93336901e-03,\n",
       "         7.46442258e-04, 1.35321109e-03, 1.16427584e-03, 1.16317016e-03,\n",
       "         1.71607246e-03, 1.01730810e-03, 7.46582609e-04, 2.09196448e-03,\n",
       "         9.77048220e-04, 1.01695269e-03, 4.88675120e-04, 1.41094206e-03,\n",
       "         6.31279068e-04, 6.30375271e-04, 7.46225579e-04, 7.46123644e-04,\n",
       "         7.46926376e-04, 2.05337110e-03, 1.01898369e-03, 1.84952456e-03,\n",
       "         6.30826420e-04, 1.16277758e-03, 6.30223479e-04, 1.46582407e-03]),\n",
       "  'param_max_depth': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                     2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4,\n",
       "                     4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6,\n",
       "                     6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8,\n",
       "                     8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                     10, 10, 10, 10, 10, 10, 10, 10, 10, 10],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_min_child_weight': masked_array(data=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8,\n",
       "                     9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6,\n",
       "                     7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4,\n",
       "                     5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2,\n",
       "                     3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10,\n",
       "                     1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'max_depth': 1, 'min_child_weight': 1},\n",
       "   {'max_depth': 1, 'min_child_weight': 2},\n",
       "   {'max_depth': 1, 'min_child_weight': 3},\n",
       "   {'max_depth': 1, 'min_child_weight': 4},\n",
       "   {'max_depth': 1, 'min_child_weight': 5},\n",
       "   {'max_depth': 1, 'min_child_weight': 6},\n",
       "   {'max_depth': 1, 'min_child_weight': 7},\n",
       "   {'max_depth': 1, 'min_child_weight': 8},\n",
       "   {'max_depth': 1, 'min_child_weight': 9},\n",
       "   {'max_depth': 1, 'min_child_weight': 10},\n",
       "   {'max_depth': 2, 'min_child_weight': 1},\n",
       "   {'max_depth': 2, 'min_child_weight': 2},\n",
       "   {'max_depth': 2, 'min_child_weight': 3},\n",
       "   {'max_depth': 2, 'min_child_weight': 4},\n",
       "   {'max_depth': 2, 'min_child_weight': 5},\n",
       "   {'max_depth': 2, 'min_child_weight': 6},\n",
       "   {'max_depth': 2, 'min_child_weight': 7},\n",
       "   {'max_depth': 2, 'min_child_weight': 8},\n",
       "   {'max_depth': 2, 'min_child_weight': 9},\n",
       "   {'max_depth': 2, 'min_child_weight': 10},\n",
       "   {'max_depth': 3, 'min_child_weight': 1},\n",
       "   {'max_depth': 3, 'min_child_weight': 2},\n",
       "   {'max_depth': 3, 'min_child_weight': 3},\n",
       "   {'max_depth': 3, 'min_child_weight': 4},\n",
       "   {'max_depth': 3, 'min_child_weight': 5},\n",
       "   {'max_depth': 3, 'min_child_weight': 6},\n",
       "   {'max_depth': 3, 'min_child_weight': 7},\n",
       "   {'max_depth': 3, 'min_child_weight': 8},\n",
       "   {'max_depth': 3, 'min_child_weight': 9},\n",
       "   {'max_depth': 3, 'min_child_weight': 10},\n",
       "   {'max_depth': 4, 'min_child_weight': 1},\n",
       "   {'max_depth': 4, 'min_child_weight': 2},\n",
       "   {'max_depth': 4, 'min_child_weight': 3},\n",
       "   {'max_depth': 4, 'min_child_weight': 4},\n",
       "   {'max_depth': 4, 'min_child_weight': 5},\n",
       "   {'max_depth': 4, 'min_child_weight': 6},\n",
       "   {'max_depth': 4, 'min_child_weight': 7},\n",
       "   {'max_depth': 4, 'min_child_weight': 8},\n",
       "   {'max_depth': 4, 'min_child_weight': 9},\n",
       "   {'max_depth': 4, 'min_child_weight': 10},\n",
       "   {'max_depth': 5, 'min_child_weight': 1},\n",
       "   {'max_depth': 5, 'min_child_weight': 2},\n",
       "   {'max_depth': 5, 'min_child_weight': 3},\n",
       "   {'max_depth': 5, 'min_child_weight': 4},\n",
       "   {'max_depth': 5, 'min_child_weight': 5},\n",
       "   {'max_depth': 5, 'min_child_weight': 6},\n",
       "   {'max_depth': 5, 'min_child_weight': 7},\n",
       "   {'max_depth': 5, 'min_child_weight': 8},\n",
       "   {'max_depth': 5, 'min_child_weight': 9},\n",
       "   {'max_depth': 5, 'min_child_weight': 10},\n",
       "   {'max_depth': 6, 'min_child_weight': 1},\n",
       "   {'max_depth': 6, 'min_child_weight': 2},\n",
       "   {'max_depth': 6, 'min_child_weight': 3},\n",
       "   {'max_depth': 6, 'min_child_weight': 4},\n",
       "   {'max_depth': 6, 'min_child_weight': 5},\n",
       "   {'max_depth': 6, 'min_child_weight': 6},\n",
       "   {'max_depth': 6, 'min_child_weight': 7},\n",
       "   {'max_depth': 6, 'min_child_weight': 8},\n",
       "   {'max_depth': 6, 'min_child_weight': 9},\n",
       "   {'max_depth': 6, 'min_child_weight': 10},\n",
       "   {'max_depth': 7, 'min_child_weight': 1},\n",
       "   {'max_depth': 7, 'min_child_weight': 2},\n",
       "   {'max_depth': 7, 'min_child_weight': 3},\n",
       "   {'max_depth': 7, 'min_child_weight': 4},\n",
       "   {'max_depth': 7, 'min_child_weight': 5},\n",
       "   {'max_depth': 7, 'min_child_weight': 6},\n",
       "   {'max_depth': 7, 'min_child_weight': 7},\n",
       "   {'max_depth': 7, 'min_child_weight': 8},\n",
       "   {'max_depth': 7, 'min_child_weight': 9},\n",
       "   {'max_depth': 7, 'min_child_weight': 10},\n",
       "   {'max_depth': 8, 'min_child_weight': 1},\n",
       "   {'max_depth': 8, 'min_child_weight': 2},\n",
       "   {'max_depth': 8, 'min_child_weight': 3},\n",
       "   {'max_depth': 8, 'min_child_weight': 4},\n",
       "   {'max_depth': 8, 'min_child_weight': 5},\n",
       "   {'max_depth': 8, 'min_child_weight': 6},\n",
       "   {'max_depth': 8, 'min_child_weight': 7},\n",
       "   {'max_depth': 8, 'min_child_weight': 8},\n",
       "   {'max_depth': 8, 'min_child_weight': 9},\n",
       "   {'max_depth': 8, 'min_child_weight': 10},\n",
       "   {'max_depth': 9, 'min_child_weight': 1},\n",
       "   {'max_depth': 9, 'min_child_weight': 2},\n",
       "   {'max_depth': 9, 'min_child_weight': 3},\n",
       "   {'max_depth': 9, 'min_child_weight': 4},\n",
       "   {'max_depth': 9, 'min_child_weight': 5},\n",
       "   {'max_depth': 9, 'min_child_weight': 6},\n",
       "   {'max_depth': 9, 'min_child_weight': 7},\n",
       "   {'max_depth': 9, 'min_child_weight': 8},\n",
       "   {'max_depth': 9, 'min_child_weight': 9},\n",
       "   {'max_depth': 9, 'min_child_weight': 10},\n",
       "   {'max_depth': 10, 'min_child_weight': 1},\n",
       "   {'max_depth': 10, 'min_child_weight': 2},\n",
       "   {'max_depth': 10, 'min_child_weight': 3},\n",
       "   {'max_depth': 10, 'min_child_weight': 4},\n",
       "   {'max_depth': 10, 'min_child_weight': 5},\n",
       "   {'max_depth': 10, 'min_child_weight': 6},\n",
       "   {'max_depth': 10, 'min_child_weight': 7},\n",
       "   {'max_depth': 10, 'min_child_weight': 8},\n",
       "   {'max_depth': 10, 'min_child_weight': 9},\n",
       "   {'max_depth': 10, 'min_child_weight': 10}],\n",
       "  'split0_test_score': array([0.65612633, 0.65612633, 0.65612633, 0.65620171, 0.6525082 ,\n",
       "         0.65079335, 0.64947424, 0.65222553, 0.6519994 , 0.64798553,\n",
       "         0.66643425, 0.67466928, 0.66703727, 0.68152866, 0.66447443,\n",
       "         0.66059247, 0.65808616, 0.66978857, 0.65846305, 0.66620812,\n",
       "         0.6552218 , 0.66063016, 0.6452625 , 0.6553914 , 0.65051068,\n",
       "         0.66311763, 0.65582482, 0.66108243, 0.64600686, 0.64487619,\n",
       "         0.6601402 , 0.64855086, 0.64985113, 0.64968153, 0.66187389,\n",
       "         0.64174801, 0.64660988, 0.65493913, 0.63300418, 0.64227566,\n",
       "         0.64252063, 0.63194889, 0.64406588, 0.65162251, 0.64022161,\n",
       "         0.65520295, 0.63799796, 0.62303547, 0.62844382, 0.64849433,\n",
       "         0.64353824, 0.64807975, 0.65049184, 0.63812988, 0.63607583,\n",
       "         0.64342517, 0.64304828, 0.61725022, 0.64216259, 0.64691139,\n",
       "         0.62488222, 0.64274677, 0.63251423, 0.63221272, 0.62995138,\n",
       "         0.62522142, 0.63726303, 0.61146497, 0.6426337 , 0.63221272,\n",
       "         0.65265895, 0.63272152, 0.63895903, 0.63409716, 0.63251423,\n",
       "         0.63758339, 0.64287868, 0.64261486, 0.62963103, 0.6518298 ,\n",
       "         0.65476953, 0.63522783, 0.67061772, 0.63673539, 0.65092526,\n",
       "         0.66675461, 0.62126409, 0.63194889, 0.62770889, 0.63323032,\n",
       "         0.62601289, 0.64497041, 0.63503938, 0.64600686, 0.64809859,\n",
       "         0.63865752, 0.64495157, 0.62392115, 0.64344401, 0.63611352]),\n",
       "  'split1_test_score': array([0.66180697, 0.66027532, 0.66103169, 0.66366009, 0.66243098,\n",
       "         0.65885712, 0.65846003, 0.66290371, 0.66708267, 0.66608048,\n",
       "         0.66297935, 0.6693707 , 0.67578095, 0.67460858, 0.67451403,\n",
       "         0.68631344, 0.68005446, 0.67882535, 0.68014901, 0.68137811,\n",
       "         0.68451706, 0.68699418, 0.68716436, 0.68610544, 0.65870585,\n",
       "         0.67555404, 0.6833825 , 0.68495197, 0.67371984, 0.66071023,\n",
       "         0.67307692, 0.68943348, 0.6947659 , 0.68896074, 0.67494894,\n",
       "         0.67508131, 0.67634823, 0.68018682, 0.68360941, 0.67101581,\n",
       "         0.68576507, 0.67680206, 0.68064065, 0.68366614, 0.68073519,\n",
       "         0.68981166, 0.67143181, 0.67375766, 0.68601089, 0.68463051,\n",
       "         0.68052719, 0.68128356, 0.69805612, 0.68429014, 0.68381741,\n",
       "         0.67269874, 0.68099992, 0.66462446, 0.6819643 , 0.67980864,\n",
       "         0.66451101, 0.66004841, 0.6890742 , 0.67179109, 0.64701989,\n",
       "         0.65343015, 0.6527305 , 0.66458664, 0.66555102, 0.69544664,\n",
       "         0.66069132, 0.66509719, 0.65369488, 0.65891385, 0.68732509,\n",
       "         0.66466228, 0.67029725, 0.65017775, 0.67787989, 0.67865517,\n",
       "         0.68264503, 0.66377354, 0.66498374, 0.68394978, 0.66006732,\n",
       "         0.67061871, 0.6630739 , 0.67735043, 0.66375463, 0.66522956,\n",
       "         0.65233341, 0.66515392, 0.68347704, 0.67854171, 0.65592618,\n",
       "         0.66120188, 0.69680811, 0.66944634, 0.66886015, 0.68300431]),\n",
       "  'split2_test_score': array([0.64098782, 0.64098782, 0.64077982, 0.6425573 , 0.64240602,\n",
       "         0.64467514, 0.63996672, 0.63752742, 0.63699796, 0.63817034,\n",
       "         0.62168142, 0.62542546, 0.63187353, 0.62797822, 0.64214129,\n",
       "         0.64397549, 0.63692232, 0.64391877, 0.64229256, 0.63162771,\n",
       "         0.61888284, 0.63068225, 0.62546328, 0.61460933, 0.63020952,\n",
       "         0.6188072 , 0.62746767, 0.62395053, 0.63310264, 0.63334846,\n",
       "         0.61595189, 0.61409878, 0.62587928, 0.62113305, 0.61638681,\n",
       "         0.62750548, 0.62366689, 0.64246275, 0.6182021 , 0.62007412,\n",
       "         0.60855835, 0.62171923, 0.60466304, 0.63289464, 0.60695106,\n",
       "         0.61160275, 0.60903109, 0.61498752, 0.64592315, 0.61782392,\n",
       "         0.62782694, 0.61950685, 0.61909084, 0.62031995, 0.62353453,\n",
       "         0.61740791, 0.59399818, 0.61672718, 0.60869072, 0.61268058,\n",
       "         0.62669238, 0.63510703, 0.63089025, 0.64490205, 0.61084638,\n",
       "         0.5966644 , 0.63813252, 0.62932078, 0.60392557, 0.60284774,\n",
       "         0.62118977, 0.62805385, 0.62323198, 0.62274034, 0.62330762,\n",
       "         0.60290447, 0.5991037 , 0.60197791, 0.60976855, 0.616765  ,\n",
       "         0.62667347, 0.61523334, 0.60725361, 0.62285379, 0.6226647 ,\n",
       "         0.63117389, 0.62546328, 0.61744573, 0.62222979, 0.59534075,\n",
       "         0.62627638, 0.61396642, 0.61704863, 0.61477952, 0.61789955,\n",
       "         0.61177294, 0.5956622 , 0.62803494, 0.6125104 , 0.61805083]),\n",
       "  'split3_test_score': array([0.66381136, 0.66381136, 0.66381136, 0.6582142 , 0.65811966,\n",
       "         0.65486726, 0.65579381, 0.65590727, 0.65571818, 0.65566145,\n",
       "         0.68659708, 0.67778534, 0.6821723 , 0.67786098, 0.67604568,\n",
       "         0.68122684, 0.67549731, 0.67795553, 0.6829854 , 0.67211255,\n",
       "         0.67738825, 0.67349293, 0.6803381 , 0.68657817, 0.68754255,\n",
       "         0.67787989, 0.68599198, 0.68018682, 0.69327207, 0.68674835,\n",
       "         0.67905227, 0.68082974, 0.69255351, 0.69304516, 0.69075713,\n",
       "         0.68118902, 0.68413887, 0.68839346, 0.67935481, 0.68194539,\n",
       "         0.648041  , 0.67561077, 0.68084865, 0.65341124, 0.66275244,\n",
       "         0.66827396, 0.66967325, 0.65632327, 0.6618637 , 0.68342032,\n",
       "         0.68118902, 0.68451706, 0.66577793, 0.65836548, 0.67646169,\n",
       "         0.6809432 , 0.68451706, 0.66458664, 0.65167158, 0.67963845,\n",
       "         0.67748279, 0.67260419, 0.66401936, 0.66712049, 0.67118599,\n",
       "         0.66574011, 0.67003252, 0.66373572, 0.66980561, 0.66390591,\n",
       "         0.68591635, 0.65636109, 0.66812268, 0.65505635, 0.68890402,\n",
       "         0.67562968, 0.65934876, 0.65668255, 0.65594509, 0.66214734,\n",
       "         0.64857046, 0.66350881, 0.66407609, 0.66621284, 0.66598593,\n",
       "         0.68160502, 0.68081083, 0.65348688, 0.64940247, 0.6675554 ,\n",
       "         0.67216928, 0.67564859, 0.6584033 , 0.66108842, 0.67578095,\n",
       "         0.64628243, 0.64959156, 0.6667423 , 0.66229862, 0.66301717]),\n",
       "  'split4_test_score': array([0.63491793, 0.63491793, 0.63482339, 0.63399138, 0.63406701,\n",
       "         0.63026624, 0.62898041, 0.62968005, 0.63306482, 0.6372816 ,\n",
       "         0.63399138, 0.64996975, 0.65233341, 0.63425611, 0.6360714 ,\n",
       "         0.63431284, 0.65220104, 0.65078285, 0.64571515, 0.63703578,\n",
       "         0.62722184, 0.6429733 , 0.65324106, 0.62427199, 0.64410786,\n",
       "         0.64401331, 0.64787081, 0.63639286, 0.65603963, 0.65135012,\n",
       "         0.62262688, 0.64015581, 0.61355041, 0.64596097, 0.63798124,\n",
       "         0.63062552, 0.63348083, 0.64034491, 0.65450798, 0.62926405,\n",
       "         0.62892368, 0.64185765, 0.65923531, 0.63478557, 0.64953483,\n",
       "         0.64261402, 0.65598291, 0.62105741, 0.66122079, 0.6289615 ,\n",
       "         0.64700098, 0.63036079, 0.6131155 , 0.62656002, 0.64119582,\n",
       "         0.62646547, 0.64217911, 0.63436956, 0.63590122, 0.64684971,\n",
       "         0.6421602 , 0.64872173, 0.6177861 , 0.63289464, 0.63149535,\n",
       "         0.63472884, 0.64719008, 0.6208305 , 0.63864307, 0.61602753,\n",
       "         0.61945012, 0.61483625, 0.6208305 , 0.63580667, 0.63102262,\n",
       "         0.64391877, 0.61727555, 0.61222676, 0.64817336, 0.63818924,\n",
       "         0.62909387, 0.63406701, 0.60471976, 0.62005522, 0.63750851,\n",
       "         0.62379926, 0.63189244, 0.64949701, 0.63578776, 0.62198396,\n",
       "         0.62081159, 0.64719008, 0.60462522, 0.60727252, 0.60780198,\n",
       "         0.62483927, 0.62340216, 0.63921035, 0.6500832 , 0.62627638]),\n",
       "  'mean_test_score': array([0.65153008, 0.65122375, 0.65131452, 0.65092493, 0.64990637,\n",
       "         0.64789182, 0.64653504, 0.6476488 , 0.6489726 , 0.64903588,\n",
       "         0.6543367 , 0.6594441 , 0.66183949, 0.65924651, 0.65864937,\n",
       "         0.66128422, 0.66055226, 0.66425421, 0.66192103, 0.65767245,\n",
       "         0.65264636, 0.65895456, 0.65829386, 0.65339127, 0.65421529,\n",
       "         0.65587441, 0.66010756, 0.65731292, 0.66042821, 0.65540667,\n",
       "         0.65016963, 0.65461373, 0.65532005, 0.65975629, 0.6563896 ,\n",
       "         0.65122987, 0.65284894, 0.66126542, 0.6537357 , 0.64891501,\n",
       "         0.64276175, 0.64958772, 0.6538907 , 0.65127602, 0.64803903,\n",
       "         0.65350107, 0.6488234 , 0.63783227, 0.65669247, 0.65266611,\n",
       "         0.65601647, 0.6527496 , 0.64930645, 0.64553309, 0.65221706,\n",
       "         0.6481881 , 0.64894851, 0.63951161, 0.64407808, 0.65317776,\n",
       "         0.64714572, 0.65184562, 0.64685683, 0.6497842 , 0.6380998 ,\n",
       "         0.63515698, 0.64906973, 0.63798772, 0.64411179, 0.64208811,\n",
       "         0.6479813 , 0.63941398, 0.64096781, 0.64132287, 0.65261471,\n",
       "         0.64493972, 0.63778079, 0.63273597, 0.64427958, 0.64951731,\n",
       "         0.64835047, 0.64236211, 0.64233019, 0.6459614 , 0.64743034,\n",
       "         0.6547903 , 0.64450091, 0.64594579, 0.63977671, 0.636668  ,\n",
       "         0.63952071, 0.64938588, 0.63971872, 0.64153781, 0.64110145,\n",
       "         0.63655081, 0.64208312, 0.64547102, 0.64743928, 0.64529244]),\n",
       "  'std_test_score': array([0.01152972, 0.01127003, 0.01146024, 0.01095376, 0.0103753 ,\n",
       "         0.0099832 , 0.01084322, 0.0122244 , 0.0124827 , 0.01087881,\n",
       "         0.02341828, 0.01956413, 0.01801737, 0.02315691, 0.01655616,\n",
       "         0.02025683, 0.0157346 , 0.01432258, 0.01694598, 0.01973592,\n",
       "         0.0261569 , 0.02027371, 0.02277125, 0.03009172, 0.01909467,\n",
       "         0.02208464, 0.02211411, 0.02388321, 0.02111544, 0.0180241 ,\n",
       "         0.02603006, 0.0275207 , 0.03341759, 0.02736646, 0.02643764,\n",
       "         0.02255541, 0.02365129, 0.01962234, 0.02546294, 0.023839  ,\n",
       "         0.02545026, 0.02265107, 0.02825153, 0.01824066, 0.02464587,\n",
       "         0.02612888, 0.02322814, 0.02304246, 0.01908288, 0.02742566,\n",
       "         0.02128881, 0.02627358, 0.03121542, 0.02331209, 0.02362659,\n",
       "         0.02496255, 0.0328408 , 0.02145019, 0.02373109, 0.02501481,\n",
       "         0.02078821, 0.01319797, 0.02601003, 0.01674933, 0.02013469,\n",
       "         0.02387389, 0.01196155, 0.02210613, 0.02352376, 0.03358462,\n",
       "         0.02511695, 0.01857277, 0.01801928, 0.01360883, 0.02915777,\n",
       "         0.02511164, 0.02632439, 0.02164224, 0.02317679, 0.02104718,\n",
       "         0.02028832, 0.01876864, 0.02976966, 0.02507369, 0.01567161,\n",
       "         0.02293858, 0.02334404, 0.02031697, 0.01508002, 0.02722196,\n",
       "         0.01968755, 0.0210581 , 0.02839467, 0.02706143, 0.02497432,\n",
       "         0.01707584, 0.03335658, 0.01915668, 0.01960935, 0.02418396]),\n",
       "  'rank_test_score': array([ 39,  43,  40,  44,  46,  62,  68,  63,  54,  53,  25,  10,   3,\n",
       "          11,  13,   4,   6,   1,   2,  15,  35,  12,  14,  30,  26,  20,\n",
       "           8,  16,   7,  21,  45,  24,  22,   9,  18,  42,  32,   5,  28,\n",
       "          56,  79,  48,  27,  41,  60,  29,  57,  95,  17,  34,  19,  33,\n",
       "          51,  71,  37,  59,  55,  91,  78,  31,  66,  38,  67,  47,  93,\n",
       "          99,  52,  94,  77,  82,  61,  92,  87,  85,  36,  74,  96, 100,\n",
       "          76,  49,  58,  80,  81,  69,  65,  23,  75,  70,  88,  97,  90,\n",
       "          50,  89,  84,  86,  98,  83,  72,  64,  73])},\n",
       " {'max_depth': 2, 'min_child_weight': 8},\n",
       " 0.6642542110322089)"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test2 = {\n",
    " 'max_depth':[1,2,3,4,5,6,7,8,9,10],\n",
    " 'min_child_weight':[1,2,3,4,5,6,7,8,9,10]\n",
    "}\n",
    "gsearch2 = GridSearchCV(estimator = XGBClassifier( learning_rate=0.1, n_estimators=140, max_depth=1,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test2, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch2.fit(X_train,y_train)\n",
    "gsearch2.cv_results_, gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:08:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'mean_fit_time': array([0.02752647, 0.02652993, 0.01755223, 0.02154284, 0.01655469,\n",
       "         1.30231786, 1.21176033, 1.21554928, 1.24626775, 1.193609  ,\n",
       "         1.19021769, 1.45471177, 1.24646535, 1.14094768, 1.15132036,\n",
       "         1.32046943, 1.20198426]),\n",
       "  'std_fit_time': array([0.00391807, 0.00644967, 0.00195361, 0.00223981, 0.00349013,\n",
       "         0.21158408, 0.15812182, 0.16045086, 0.13485001, 0.11012388,\n",
       "         0.1175322 , 0.2343767 , 0.20784411, 0.00769736, 0.02324871,\n",
       "         0.12746676, 0.1186225 ]),\n",
       "  'mean_score_time': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.00837836, 0.00957456, 0.01017389, 0.00857739, 0.00857673,\n",
       "         0.00837846, 0.0097733 , 0.00857782, 0.0095746 , 0.01017342,\n",
       "         0.01057267, 0.00917554]),\n",
       "  'std_score_time': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.00149204, 0.00223921, 0.0023932 , 0.00135319, 0.00119789,\n",
       "         0.00149304, 0.00132199, 0.00079781, 0.00162028, 0.00239377,\n",
       "         0.00271998, 0.00116266]),\n",
       "  'param_gamma': masked_array(data=[-0.005, -0.004, -0.003, -0.002, -0.001, 0.0, 0.001,\n",
       "                     0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008,\n",
       "                     0.009000000000000001, 0.01, 0.011],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'gamma': -0.005},\n",
       "   {'gamma': -0.004},\n",
       "   {'gamma': -0.003},\n",
       "   {'gamma': -0.002},\n",
       "   {'gamma': -0.001},\n",
       "   {'gamma': 0.0},\n",
       "   {'gamma': 0.001},\n",
       "   {'gamma': 0.002},\n",
       "   {'gamma': 0.003},\n",
       "   {'gamma': 0.004},\n",
       "   {'gamma': 0.005},\n",
       "   {'gamma': 0.006},\n",
       "   {'gamma': 0.007},\n",
       "   {'gamma': 0.008},\n",
       "   {'gamma': 0.009000000000000001},\n",
       "   {'gamma': 0.01},\n",
       "   {'gamma': 0.011}],\n",
       "  'split0_test_score': array([       nan,        nan,        nan,        nan,        nan,\n",
       "         0.68356386, 0.68356386, 0.68356386, 0.68356386, 0.68356386,\n",
       "         0.68356386, 0.68356386, 0.68356386, 0.68356386, 0.68356386,\n",
       "         0.68356386, 0.68356386]),\n",
       "  'split1_test_score': array([       nan,        nan,        nan,        nan,        nan,\n",
       "         0.68472506, 0.68472506, 0.68472506, 0.68472506, 0.68472506,\n",
       "         0.68472506, 0.68472506, 0.68472506, 0.68472506, 0.68472506,\n",
       "         0.68472506, 0.68472506]),\n",
       "  'split2_test_score': array([       nan,        nan,        nan,        nan,        nan,\n",
       "         0.64244384, 0.64244384, 0.64244384, 0.64244384, 0.64244384,\n",
       "         0.64244384, 0.64244384, 0.64244384, 0.64244384, 0.64244384,\n",
       "         0.64244384, 0.64244384]),\n",
       "  'split3_test_score': array([       nan,        nan,        nan,        nan,        nan,\n",
       "         0.69480372, 0.69480372, 0.69480372, 0.69480372, 0.69480372,\n",
       "         0.69480372, 0.69480372, 0.69480372, 0.69480372, 0.69480372,\n",
       "         0.69480372, 0.69480372]),\n",
       "  'split4_test_score': array([       nan,        nan,        nan,        nan,        nan,\n",
       "         0.64560169, 0.64560169, 0.64560169, 0.64560169, 0.64560169,\n",
       "         0.64560169, 0.64560169, 0.64560169, 0.64560169, 0.64560169,\n",
       "         0.64560169, 0.64560169]),\n",
       "  'mean_test_score': array([       nan,        nan,        nan,        nan,        nan,\n",
       "         0.67022764, 0.67022764, 0.67022764, 0.67022764, 0.67022764,\n",
       "         0.67022764, 0.67022764, 0.67022764, 0.67022764, 0.67022764,\n",
       "         0.67022764, 0.67022764]),\n",
       "  'std_test_score': array([       nan,        nan,        nan,        nan,        nan,\n",
       "         0.02177333, 0.02177333, 0.02177333, 0.02177333, 0.02177333,\n",
       "         0.02177333, 0.02177333, 0.02177333, 0.02177333, 0.02177333,\n",
       "         0.02177333, 0.02177333]),\n",
       "  'rank_test_score': array([17, 16, 15, 14, 13,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1])},\n",
       " {'gamma': 0.0},\n",
       " 0.6702276354919299)"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test3 = {\n",
    " 'gamma':[i*0.001 for i in range(-5,12)]\n",
    "}\n",
    "gsearch3 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=2,\n",
    " min_child_weight=8, gamma=0, subsample=0.79, colsample_bytree=0.93, reg_alpha=0.1086,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test3, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch3.fit(X_train,y_train)\n",
    "gsearch3.cv_results_, gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Accuracy : 0.64\n",
      "AUC Score (Train): 0.715278\n"
     ]
    }
   ],
   "source": [
    "xgb10 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=2,\n",
    " min_child_weight=8,\n",
    " gamma=0.0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb10, X_train,y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:09:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'mean_fit_time': array([1.11501665, 1.08709331, 1.05936732, 1.3112937 , 1.14354305,\n",
       "         1.15531001, 1.352982  , 1.22951193, 1.24686642, 1.38449807,\n",
       "         1.40683751, 1.3276495 , 1.41561451, 1.54905643, 1.38130674,\n",
       "         1.39407253]),\n",
       "  'std_fit_time': array([0.01335075, 0.02840615, 0.00840177, 0.1237936 , 0.01031644,\n",
       "         0.00806785, 0.14888895, 0.1183429 , 0.00647557, 0.16484438,\n",
       "         0.13905395, 0.03024716, 0.12323501, 0.13644872, 0.0098734 ,\n",
       "         0.0116026 ]),\n",
       "  'mean_score_time': array([0.01735616, 0.01097264, 0.00957484, 0.01017394, 0.01037092,\n",
       "         0.01137061, 0.00977478, 0.0097753 , 0.00977526, 0.00897727,\n",
       "         0.00937591, 0.00957417, 0.01077185, 0.00897713, 0.00937653,\n",
       "         0.00817823]),\n",
       "  'std_score_time': array([0.01254865, 0.00308928, 0.0016211 , 0.00317902, 0.00240648,\n",
       "         0.0024099 , 0.00116243, 0.00203414, 0.00171616, 0.00109306,\n",
       "         0.00232692, 0.00257007, 0.00222091, 0.0015448 , 0.00135465,\n",
       "         0.00146566]),\n",
       "  'param_colsample_bytree': masked_array(data=[0.6, 0.6, 0.6, 0.6, 0.7, 0.7, 0.7, 0.7, 0.8, 0.8, 0.8,\n",
       "                     0.8, 0.9, 0.9, 0.9, 0.9],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_subsample': masked_array(data=[0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8,\n",
       "                     0.9, 0.6, 0.7, 0.8, 0.9],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'colsample_bytree': 0.6, 'subsample': 0.6},\n",
       "   {'colsample_bytree': 0.6, 'subsample': 0.7},\n",
       "   {'colsample_bytree': 0.6, 'subsample': 0.8},\n",
       "   {'colsample_bytree': 0.6, 'subsample': 0.9},\n",
       "   {'colsample_bytree': 0.7, 'subsample': 0.6},\n",
       "   {'colsample_bytree': 0.7, 'subsample': 0.7},\n",
       "   {'colsample_bytree': 0.7, 'subsample': 0.8},\n",
       "   {'colsample_bytree': 0.7, 'subsample': 0.9},\n",
       "   {'colsample_bytree': 0.8, 'subsample': 0.6},\n",
       "   {'colsample_bytree': 0.8, 'subsample': 0.7},\n",
       "   {'colsample_bytree': 0.8, 'subsample': 0.8},\n",
       "   {'colsample_bytree': 0.8, 'subsample': 0.9},\n",
       "   {'colsample_bytree': 0.9, 'subsample': 0.6},\n",
       "   {'colsample_bytree': 0.9, 'subsample': 0.7},\n",
       "   {'colsample_bytree': 0.9, 'subsample': 0.8},\n",
       "   {'colsample_bytree': 0.9, 'subsample': 0.9}],\n",
       "  'split0_test_score': array([0.64304828, 0.67826857, 0.66125203, 0.66311763, 0.62995138,\n",
       "         0.66356989, 0.6698451 , 0.64836242, 0.63818641, 0.66272189,\n",
       "         0.67074963, 0.66130856, 0.6434817 , 0.65601327, 0.67759017,\n",
       "         0.661497  ]),\n",
       "  'split1_test_score': array([0.67319038, 0.68950911, 0.68273958, 0.6825694 , 0.68249376,\n",
       "         0.68737236, 0.67137509, 0.68128356, 0.69694047, 0.68232358,\n",
       "         0.67905227, 0.68160502, 0.67458967, 0.68585962, 0.68701309,\n",
       "         0.68498979]),\n",
       "  'split2_test_score': array([0.62393162, 0.62130323, 0.62788367, 0.63905907, 0.62555782,\n",
       "         0.61742682, 0.61897738, 0.64836245, 0.62487709, 0.62084941,\n",
       "         0.63463429, 0.65310869, 0.62979351, 0.6368845 , 0.62748657,\n",
       "         0.63888889]),\n",
       "  'split3_test_score': array([0.67249073, 0.67939263, 0.67651842, 0.67468421, 0.67347402,\n",
       "         0.68404432, 0.67277437, 0.67126163, 0.67799334, 0.68173739,\n",
       "         0.67406021, 0.67226382, 0.67016489, 0.67368202, 0.68937675,\n",
       "         0.68803419]),\n",
       "  'split4_test_score': array([0.64034491, 0.64234929, 0.64119582, 0.63994781, 0.63622268,\n",
       "         0.64807881, 0.64140383, 0.64202783, 0.63979654, 0.63701687,\n",
       "         0.6423682 , 0.65165267, 0.63779215, 0.64715226, 0.64210347,\n",
       "         0.64112019]),\n",
       "  'mean_test_score': array([0.65060118, 0.66216457, 0.6579179 , 0.65987562, 0.64953993,\n",
       "         0.66009844, 0.65487515, 0.65825958, 0.65555877, 0.65692983,\n",
       "         0.66017292, 0.66398775, 0.65116438, 0.65991833, 0.66471401,\n",
       "         0.66290601]),\n",
       "  'std_test_score': array([0.01930247, 0.02594673, 0.02076003, 0.0177497 , 0.02364317,\n",
       "         0.02566968, 0.02138624, 0.01522192, 0.02723001, 0.02446274,\n",
       "         0.01805759, 0.01145904, 0.01791266, 0.01772664, 0.02517305,\n",
       "         0.02084489]),\n",
       "  'rank_test_score': array([15,  4, 10,  8, 16,  6, 13,  9, 12, 11,  5,  2, 14,  7,  1,  3])},\n",
       " {'colsample_bytree': 0.9, 'subsample': 0.8},\n",
       " 0.6647140102447886)"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test4 = {\n",
    " 'subsample':[i/10.0 for i in range(6,10)],\n",
    " 'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
    "}\n",
    "gsearch4 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=177, max_depth=2,\n",
    " min_child_weight=8, gamma=0.00, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test4, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch4.fit(X_train,y_train)\n",
    "gsearch4.cv_results_, gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:24:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'colsample_bytree': 0.926, 'subsample': 0.79}, 0.6729241736445823)"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test5 = {\n",
    " 'subsample':[i/1000.0 for i in range(785,795)],\n",
    " 'colsample_bytree':[i/1000.0 for i in range(925,935)]\n",
    "}\n",
    "gsearch5 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=177, max_depth=2,\n",
    " min_child_weight=8, gamma=0.0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test5, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch5.fit(X_train,y_train)\n",
    "gsearch5.best_params_, gsearch5.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([1.82865977, 1.49363742, 1.66804447, 1.57808161, 1.58201437,\n",
       "        1.73275294, 1.62233663, 1.570892  , 1.82465005, 1.55816913,\n",
       "        1.7656239 , 1.56898975, 1.51744294, 1.72106924, 1.61919842,\n",
       "        1.57737684, 2.18282266, 1.69979773, 1.9504178 , 1.72833738,\n",
       "        1.82021217, 1.88311977, 1.58461781, 1.84187007, 1.74422131,\n",
       "        1.95648756, 1.6419631 , 1.4882071 , 1.72617159, 1.48952947,\n",
       "        1.48432364, 1.76736059, 1.56793079, 1.838696  , 2.00181489,\n",
       "        1.6578845 , 2.04253788, 1.64081101, 1.99606318, 1.73675537,\n",
       "        1.56740899, 1.78422914, 1.6465971 , 2.05291066, 1.6092967 ,\n",
       "        1.8819694 , 1.93682094, 3.86746192, 2.29107332, 1.6336318 ,\n",
       "        1.63123598, 1.61627817, 1.84227605, 1.64997296, 2.37545409,\n",
       "        3.48498263, 2.14586172, 1.71282125, 2.1360877 , 1.91168842,\n",
       "        2.03934755, 2.43488884, 2.20270877, 2.03356295, 2.21288095,\n",
       "        3.74099779, 3.42404604, 2.29805322, 1.60450969, 1.61149073,\n",
       "        1.84905577, 1.58436332, 1.64779291, 1.69646311, 1.66933608,\n",
       "        4.10981193, 2.57112427, 2.09380312, 1.59054685, 1.76787233,\n",
       "        1.57259483, 1.63403053, 1.65457578, 1.58057246, 1.77345781,\n",
       "        1.70364375, 1.74593177, 1.92904153, 1.7086309 , 1.6854928 ,\n",
       "        1.70962939, 1.57977576, 1.82771244, 1.62186279, 2.49971628,\n",
       "        1.99958105, 1.69253635, 1.82082553, 1.6512073 , 1.83380308]),\n",
       " 'std_fit_time': array([0.16138451, 0.01071457, 0.15124946, 0.10711063, 0.06509946,\n",
       "        0.05634005, 0.0426248 , 0.03377823, 0.14306106, 0.03066638,\n",
       "        0.11902989, 0.15314951, 0.00670067, 0.14649867, 0.09506897,\n",
       "        0.01479888, 0.17578046, 0.10135398, 0.31000415, 0.2595692 ,\n",
       "        0.11399931, 0.22169865, 0.00739677, 0.12712339, 0.1993256 ,\n",
       "        0.12690204, 0.17788681, 0.01019794, 0.11932759, 0.01141525,\n",
       "        0.0187935 , 0.14526601, 0.06207235, 0.14180082, 0.02156028,\n",
       "        0.15728417, 0.20919929, 0.00959466, 0.2672592 , 0.24071502,\n",
       "        0.2020977 , 0.22240816, 0.09072349, 0.18198166, 0.03386008,\n",
       "        0.30259146, 0.24693886, 1.05775572, 0.40891045, 0.16915779,\n",
       "        0.17588494, 0.05517877, 0.10029262, 0.16079949, 0.36626887,\n",
       "        0.4549862 , 0.27557985, 0.17491406, 0.15527274, 0.17269526,\n",
       "        0.39304215, 0.36906071, 0.26730631, 0.18628898, 0.6446404 ,\n",
       "        0.09671904, 0.34418362, 0.42838152, 0.04094395, 0.11703846,\n",
       "        0.13558393, 0.03707427, 0.1167241 , 0.16106359, 0.14155475,\n",
       "        1.20613356, 0.36697785, 0.26428097, 0.02859698, 0.10127854,\n",
       "        0.03785342, 0.16365341, 0.16513968, 0.0471994 , 0.15075653,\n",
       "        0.09541622, 0.01738449, 0.06894546, 0.10199261, 0.16804654,\n",
       "        0.13558088, 0.0187649 , 0.14273313, 0.11168071, 0.59320306,\n",
       "        0.50529909, 0.09660045, 0.08981422, 0.03389309, 0.11251968]),\n",
       " 'mean_score_time': array([0.00922856, 0.01100192, 0.01061401, 0.01360497, 0.00960717,\n",
       "        0.01360273, 0.00880446, 0.00879717, 0.00970383, 0.00959344,\n",
       "        0.00861135, 0.00849118, 0.01059508, 0.01241193, 0.00889983,\n",
       "        0.00781851, 0.01009078, 0.00870094, 0.00960002, 0.00969996,\n",
       "        0.0120038 , 0.00987463, 0.00900683, 0.00832543, 0.00910196,\n",
       "        0.00920782, 0.00890408, 0.00859632, 0.00839272, 0.00799513,\n",
       "        0.00781183, 0.01057677, 0.00979352, 0.00959277, 0.01198716,\n",
       "        0.00937567, 0.00897665, 0.00857782, 0.00857706, 0.00897679,\n",
       "        0.00837932, 0.00937586, 0.00857778, 0.01037521, 0.00857739,\n",
       "        0.01117001, 0.00957508, 0.01815057, 0.00837908, 0.01097131,\n",
       "        0.00897684, 0.00817847, 0.01057024, 0.00959044, 0.00940237,\n",
       "        0.01017799, 0.00837898, 0.01077023, 0.01077166, 0.01017632,\n",
       "        0.01356115, 0.01017456, 0.0103724 , 0.01076999, 0.01356306,\n",
       "        0.01416178, 0.01256628, 0.00957541, 0.00877719, 0.01017509,\n",
       "        0.0095746 , 0.00937591, 0.01097131, 0.00897651, 0.00877724,\n",
       "        0.01196856, 0.01316538, 0.01076913, 0.00837774, 0.00937676,\n",
       "        0.00817924, 0.00837784, 0.00837817, 0.00937557, 0.01216803,\n",
       "        0.00937538, 0.00877647, 0.00997376, 0.00897684, 0.00797963,\n",
       "        0.00877571, 0.0095747 , 0.00897837, 0.00897655, 0.00797858,\n",
       "        0.01039085, 0.00899453, 0.00861216, 0.00860734, 0.00857735]),\n",
       " 'std_score_time': array([0.00040131, 0.00242575, 0.00144645, 0.00215041, 0.00279878,\n",
       "        0.00407851, 0.0009758 , 0.00111712, 0.00087716, 0.0010213 ,\n",
       "        0.00079943, 0.00063401, 0.00340093, 0.00340328, 0.00110494,\n",
       "        0.00073547, 0.00189974, 0.00097694, 0.00149215, 0.0013405 ,\n",
       "        0.00274374, 0.00420178, 0.00062113, 0.00116754, 0.00112704,\n",
       "        0.0007436 , 0.00168088, 0.00101875, 0.00102592, 0.0006306 ,\n",
       "        0.0007479 , 0.00135156, 0.00147212, 0.00241295, 0.00518196,\n",
       "        0.00048951, 0.0008917 , 0.00135279, 0.00135292, 0.00141003,\n",
       "        0.00135209, 0.0014932 , 0.00048858, 0.00101743, 0.00135337,\n",
       "        0.00390913, 0.00149199, 0.01316032, 0.0004902 , 0.00454902,\n",
       "        0.00063007, 0.00039852, 0.00376155, 0.00101628, 0.00186102,\n",
       "        0.00270318, 0.00101675, 0.00239332, 0.00330226, 0.00146901,\n",
       "        0.00499072, 0.00132381, 0.00149255, 0.00193462, 0.00506805,\n",
       "        0.00353668, 0.00249048, 0.00119731, 0.00074592, 0.00255554,\n",
       "        0.00048906, 0.000798  , 0.00274895, 0.00089218, 0.00132358,\n",
       "        0.0026008 , 0.0093854 , 0.00311719, 0.00079789, 0.00331598,\n",
       "        0.00116331, 0.00048877, 0.00101725, 0.00101726, 0.00347805,\n",
       "        0.00184883, 0.00039842, 0.00236058, 0.00089244, 0.00063128,\n",
       "        0.00116095, 0.00079688, 0.00166901, 0.00063052, 0.00089282,\n",
       "        0.00173629, 0.00109734, 0.00048956, 0.00079653, 0.00048862]),\n",
       " 'param_colsample_bytree': masked_array(data=[0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.91,\n",
       "                    0.91, 0.91, 0.91, 0.91, 0.91, 0.91, 0.91, 0.91, 0.91,\n",
       "                    0.92, 0.92, 0.92, 0.92, 0.92, 0.92, 0.92, 0.92, 0.92,\n",
       "                    0.92, 0.93, 0.93, 0.93, 0.93, 0.93, 0.93, 0.93, 0.93,\n",
       "                    0.93, 0.93, 0.94, 0.94, 0.94, 0.94, 0.94, 0.94, 0.94,\n",
       "                    0.94, 0.94, 0.94, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95,\n",
       "                    0.95, 0.95, 0.95, 0.95, 0.96, 0.96, 0.96, 0.96, 0.96,\n",
       "                    0.96, 0.96, 0.96, 0.96, 0.96, 0.97, 0.97, 0.97, 0.97,\n",
       "                    0.97, 0.97, 0.97, 0.97, 0.97, 0.97, 0.98, 0.98, 0.98,\n",
       "                    0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.99, 0.99,\n",
       "                    0.99, 0.99, 0.99, 0.99, 0.99, 0.99, 0.99, 0.99],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_subsample': masked_array(data=[0.75, 0.76, 0.77, 0.78, 0.79, 0.8, 0.81, 0.82, 0.83,\n",
       "                    0.84, 0.75, 0.76, 0.77, 0.78, 0.79, 0.8, 0.81, 0.82,\n",
       "                    0.83, 0.84, 0.75, 0.76, 0.77, 0.78, 0.79, 0.8, 0.81,\n",
       "                    0.82, 0.83, 0.84, 0.75, 0.76, 0.77, 0.78, 0.79, 0.8,\n",
       "                    0.81, 0.82, 0.83, 0.84, 0.75, 0.76, 0.77, 0.78, 0.79,\n",
       "                    0.8, 0.81, 0.82, 0.83, 0.84, 0.75, 0.76, 0.77, 0.78,\n",
       "                    0.79, 0.8, 0.81, 0.82, 0.83, 0.84, 0.75, 0.76, 0.77,\n",
       "                    0.78, 0.79, 0.8, 0.81, 0.82, 0.83, 0.84, 0.75, 0.76,\n",
       "                    0.77, 0.78, 0.79, 0.8, 0.81, 0.82, 0.83, 0.84, 0.75,\n",
       "                    0.76, 0.77, 0.78, 0.79, 0.8, 0.81, 0.82, 0.83, 0.84,\n",
       "                    0.75, 0.76, 0.77, 0.78, 0.79, 0.8, 0.81, 0.82, 0.83,\n",
       "                    0.84],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'colsample_bytree': 0.9, 'subsample': 0.75},\n",
       "  {'colsample_bytree': 0.9, 'subsample': 0.76},\n",
       "  {'colsample_bytree': 0.9, 'subsample': 0.77},\n",
       "  {'colsample_bytree': 0.9, 'subsample': 0.78},\n",
       "  {'colsample_bytree': 0.9, 'subsample': 0.79},\n",
       "  {'colsample_bytree': 0.9, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.9, 'subsample': 0.81},\n",
       "  {'colsample_bytree': 0.9, 'subsample': 0.82},\n",
       "  {'colsample_bytree': 0.9, 'subsample': 0.83},\n",
       "  {'colsample_bytree': 0.9, 'subsample': 0.84},\n",
       "  {'colsample_bytree': 0.91, 'subsample': 0.75},\n",
       "  {'colsample_bytree': 0.91, 'subsample': 0.76},\n",
       "  {'colsample_bytree': 0.91, 'subsample': 0.77},\n",
       "  {'colsample_bytree': 0.91, 'subsample': 0.78},\n",
       "  {'colsample_bytree': 0.91, 'subsample': 0.79},\n",
       "  {'colsample_bytree': 0.91, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.91, 'subsample': 0.81},\n",
       "  {'colsample_bytree': 0.91, 'subsample': 0.82},\n",
       "  {'colsample_bytree': 0.91, 'subsample': 0.83},\n",
       "  {'colsample_bytree': 0.91, 'subsample': 0.84},\n",
       "  {'colsample_bytree': 0.92, 'subsample': 0.75},\n",
       "  {'colsample_bytree': 0.92, 'subsample': 0.76},\n",
       "  {'colsample_bytree': 0.92, 'subsample': 0.77},\n",
       "  {'colsample_bytree': 0.92, 'subsample': 0.78},\n",
       "  {'colsample_bytree': 0.92, 'subsample': 0.79},\n",
       "  {'colsample_bytree': 0.92, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.92, 'subsample': 0.81},\n",
       "  {'colsample_bytree': 0.92, 'subsample': 0.82},\n",
       "  {'colsample_bytree': 0.92, 'subsample': 0.83},\n",
       "  {'colsample_bytree': 0.92, 'subsample': 0.84},\n",
       "  {'colsample_bytree': 0.93, 'subsample': 0.75},\n",
       "  {'colsample_bytree': 0.93, 'subsample': 0.76},\n",
       "  {'colsample_bytree': 0.93, 'subsample': 0.77},\n",
       "  {'colsample_bytree': 0.93, 'subsample': 0.78},\n",
       "  {'colsample_bytree': 0.93, 'subsample': 0.79},\n",
       "  {'colsample_bytree': 0.93, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.93, 'subsample': 0.81},\n",
       "  {'colsample_bytree': 0.93, 'subsample': 0.82},\n",
       "  {'colsample_bytree': 0.93, 'subsample': 0.83},\n",
       "  {'colsample_bytree': 0.93, 'subsample': 0.84},\n",
       "  {'colsample_bytree': 0.94, 'subsample': 0.75},\n",
       "  {'colsample_bytree': 0.94, 'subsample': 0.76},\n",
       "  {'colsample_bytree': 0.94, 'subsample': 0.77},\n",
       "  {'colsample_bytree': 0.94, 'subsample': 0.78},\n",
       "  {'colsample_bytree': 0.94, 'subsample': 0.79},\n",
       "  {'colsample_bytree': 0.94, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.94, 'subsample': 0.81},\n",
       "  {'colsample_bytree': 0.94, 'subsample': 0.82},\n",
       "  {'colsample_bytree': 0.94, 'subsample': 0.83},\n",
       "  {'colsample_bytree': 0.94, 'subsample': 0.84},\n",
       "  {'colsample_bytree': 0.95, 'subsample': 0.75},\n",
       "  {'colsample_bytree': 0.95, 'subsample': 0.76},\n",
       "  {'colsample_bytree': 0.95, 'subsample': 0.77},\n",
       "  {'colsample_bytree': 0.95, 'subsample': 0.78},\n",
       "  {'colsample_bytree': 0.95, 'subsample': 0.79},\n",
       "  {'colsample_bytree': 0.95, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.95, 'subsample': 0.81},\n",
       "  {'colsample_bytree': 0.95, 'subsample': 0.82},\n",
       "  {'colsample_bytree': 0.95, 'subsample': 0.83},\n",
       "  {'colsample_bytree': 0.95, 'subsample': 0.84},\n",
       "  {'colsample_bytree': 0.96, 'subsample': 0.75},\n",
       "  {'colsample_bytree': 0.96, 'subsample': 0.76},\n",
       "  {'colsample_bytree': 0.96, 'subsample': 0.77},\n",
       "  {'colsample_bytree': 0.96, 'subsample': 0.78},\n",
       "  {'colsample_bytree': 0.96, 'subsample': 0.79},\n",
       "  {'colsample_bytree': 0.96, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.96, 'subsample': 0.81},\n",
       "  {'colsample_bytree': 0.96, 'subsample': 0.82},\n",
       "  {'colsample_bytree': 0.96, 'subsample': 0.83},\n",
       "  {'colsample_bytree': 0.96, 'subsample': 0.84},\n",
       "  {'colsample_bytree': 0.97, 'subsample': 0.75},\n",
       "  {'colsample_bytree': 0.97, 'subsample': 0.76},\n",
       "  {'colsample_bytree': 0.97, 'subsample': 0.77},\n",
       "  {'colsample_bytree': 0.97, 'subsample': 0.78},\n",
       "  {'colsample_bytree': 0.97, 'subsample': 0.79},\n",
       "  {'colsample_bytree': 0.97, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.97, 'subsample': 0.81},\n",
       "  {'colsample_bytree': 0.97, 'subsample': 0.82},\n",
       "  {'colsample_bytree': 0.97, 'subsample': 0.83},\n",
       "  {'colsample_bytree': 0.97, 'subsample': 0.84},\n",
       "  {'colsample_bytree': 0.98, 'subsample': 0.75},\n",
       "  {'colsample_bytree': 0.98, 'subsample': 0.76},\n",
       "  {'colsample_bytree': 0.98, 'subsample': 0.77},\n",
       "  {'colsample_bytree': 0.98, 'subsample': 0.78},\n",
       "  {'colsample_bytree': 0.98, 'subsample': 0.79},\n",
       "  {'colsample_bytree': 0.98, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.98, 'subsample': 0.81},\n",
       "  {'colsample_bytree': 0.98, 'subsample': 0.82},\n",
       "  {'colsample_bytree': 0.98, 'subsample': 0.83},\n",
       "  {'colsample_bytree': 0.98, 'subsample': 0.84},\n",
       "  {'colsample_bytree': 0.99, 'subsample': 0.75},\n",
       "  {'colsample_bytree': 0.99, 'subsample': 0.76},\n",
       "  {'colsample_bytree': 0.99, 'subsample': 0.77},\n",
       "  {'colsample_bytree': 0.99, 'subsample': 0.78},\n",
       "  {'colsample_bytree': 0.99, 'subsample': 0.79},\n",
       "  {'colsample_bytree': 0.99, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.99, 'subsample': 0.81},\n",
       "  {'colsample_bytree': 0.99, 'subsample': 0.82},\n",
       "  {'colsample_bytree': 0.99, 'subsample': 0.83},\n",
       "  {'colsample_bytree': 0.99, 'subsample': 0.84}],\n",
       " 'split0_test_score': array([0.64608224, 0.64498926, 0.65704971, 0.65135869, 0.66242038,\n",
       "        0.67759017, 0.67589417, 0.66172314, 0.66880865, 0.66196812,\n",
       "        0.64608224, 0.64498926, 0.65704971, 0.65135869, 0.66242038,\n",
       "        0.67759017, 0.67589417, 0.66172314, 0.66880865, 0.66196812,\n",
       "        0.65037877, 0.65642784, 0.65292278, 0.66767799, 0.67760902,\n",
       "        0.66315532, 0.6696755 , 0.68273471, 0.67448084, 0.66219425,\n",
       "        0.65816153, 0.65652207, 0.66145931, 0.65475069, 0.67796706,\n",
       "        0.67431124, 0.66176083, 0.67282252, 0.66958128, 0.66837523,\n",
       "        0.65816153, 0.65652207, 0.66145931, 0.65475069, 0.67796706,\n",
       "        0.67431124, 0.66176083, 0.67282252, 0.66958128, 0.66837523,\n",
       "        0.65639016, 0.6519994 , 0.65147175, 0.67042928, 0.69113934,\n",
       "        0.67076848, 0.65769042, 0.66155354, 0.6688275 , 0.67020314,\n",
       "        0.66008367, 0.65360118, 0.662345  , 0.65294162, 0.67216297,\n",
       "        0.6761203 , 0.6742547 , 0.66860136, 0.67218181, 0.65757736,\n",
       "        0.66008367, 0.65360118, 0.662345  , 0.65294162, 0.67216297,\n",
       "        0.6761203 , 0.6742547 , 0.66860136, 0.67218181, 0.65757736,\n",
       "        0.64564881, 0.65476953, 0.66255229, 0.6698451 , 0.68224475,\n",
       "        0.66709381, 0.66579354, 0.66025327, 0.67257754, 0.66411638,\n",
       "        0.65431727, 0.65397807, 0.66622696, 0.66980741, 0.68495835,\n",
       "        0.65541024, 0.67342555, 0.67133381, 0.67483888, 0.661497  ]),\n",
       " 'split1_test_score': array([0.68962257, 0.68695636, 0.6833825 , 0.68158611, 0.67504349,\n",
       "        0.68701309, 0.68357159, 0.68559489, 0.68130247, 0.68383632,\n",
       "        0.68962257, 0.68695636, 0.6833825 , 0.68158611, 0.67504349,\n",
       "        0.68701309, 0.68357159, 0.68559489, 0.68130247, 0.68383632,\n",
       "        0.6835905 , 0.68691854, 0.69573028, 0.68221012, 0.679941  ,\n",
       "        0.68411996, 0.68472506, 0.68771273, 0.68720218, 0.6864269 ,\n",
       "        0.68307995, 0.68366614, 0.68909311, 0.67003252, 0.6854247 ,\n",
       "        0.68362832, 0.6823803 , 0.68654035, 0.68058392, 0.68022464,\n",
       "        0.68307995, 0.68366614, 0.68909311, 0.67003252, 0.6854247 ,\n",
       "        0.68362832, 0.6823803 , 0.68654035, 0.68058392, 0.68022464,\n",
       "        0.69122986, 0.69538991, 0.67470312, 0.67901445, 0.67903336,\n",
       "        0.67975191, 0.68347704, 0.67347402, 0.68082974, 0.68533016,\n",
       "        0.68888511, 0.69283715, 0.68481961, 0.68137811, 0.68718327,\n",
       "        0.67570532, 0.68243703, 0.67757734, 0.68194539, 0.68084865,\n",
       "        0.68888511, 0.69283715, 0.68481961, 0.68137811, 0.68718327,\n",
       "        0.67570532, 0.68243703, 0.67757734, 0.68194539, 0.68084865,\n",
       "        0.68491415, 0.69247788, 0.68563271, 0.68166175, 0.6902844 ,\n",
       "        0.67092126, 0.68676726, 0.68243703, 0.68228576, 0.69268588,\n",
       "        0.6825694 , 0.69141895, 0.68251267, 0.68309886, 0.67950609,\n",
       "        0.67239619, 0.67665078, 0.68722109, 0.68343923, 0.69669465]),\n",
       " 'split2_test_score': array([0.64225475, 0.63535285, 0.64263293, 0.64185765, 0.62552001,\n",
       "        0.62748657, 0.63295137, 0.62465018, 0.63416156, 0.63697905,\n",
       "        0.64225475, 0.63535285, 0.64263293, 0.64185765, 0.62552001,\n",
       "        0.62748657, 0.63295137, 0.62465018, 0.63416156, 0.63697905,\n",
       "        0.64737917, 0.6435784 , 0.64132819, 0.6360714 , 0.64925119,\n",
       "        0.64263293, 0.61731337, 0.62597383, 0.63030406, 0.64968611,\n",
       "        0.63650632, 0.62968005, 0.65745783, 0.63416156, 0.65095303,\n",
       "        0.62232433, 0.62928296, 0.64287875, 0.6386998 , 0.63372665,\n",
       "        0.63650632, 0.62968005, 0.65745783, 0.63416156, 0.65095303,\n",
       "        0.62232433, 0.62928296, 0.64287875, 0.6386998 , 0.63372665,\n",
       "        0.64340821, 0.62574692, 0.65897058, 0.63399138, 0.63792451,\n",
       "        0.64522351, 0.62837531, 0.63588231, 0.63325391, 0.63461538,\n",
       "        0.64110128, 0.64382422, 0.64675516, 0.63644959, 0.64034491,\n",
       "        0.64119582, 0.63503139, 0.65095303, 0.63601467, 0.63956962,\n",
       "        0.64110128, 0.64382422, 0.64675516, 0.63644959, 0.64034491,\n",
       "        0.64119582, 0.63503139, 0.65095303, 0.63601467, 0.63956962,\n",
       "        0.6452046 , 0.63941835, 0.63544739, 0.63881325, 0.63408592,\n",
       "        0.64858937, 0.62574692, 0.62901823, 0.62799713, 0.64025036,\n",
       "        0.63682777, 0.63656304, 0.64475078, 0.64584752, 0.63866198,\n",
       "        0.63737614, 0.64034491, 0.62884804, 0.63157099, 0.62945314]),\n",
       " 'split3_test_score': array([0.69015203, 0.68595416, 0.68722109, 0.68117011, 0.68062174,\n",
       "        0.68937675, 0.69041676, 0.6886771 , 0.67702897, 0.68741018,\n",
       "        0.69015203, 0.68595416, 0.68722109, 0.68117011, 0.68062174,\n",
       "        0.68937675, 0.69041676, 0.6886771 , 0.67702897, 0.68741018,\n",
       "        0.69514409, 0.68377959, 0.68152939, 0.68168066, 0.6783148 ,\n",
       "        0.68255049, 0.68971712, 0.67806898, 0.68565161, 0.68986839,\n",
       "        0.68913093, 0.67814462, 0.67842826, 0.6738333 , 0.69037894,\n",
       "        0.68773164, 0.68048937, 0.68183193, 0.68221012, 0.68472506,\n",
       "        0.68913093, 0.67814462, 0.67842826, 0.6738333 , 0.69037894,\n",
       "        0.68773164, 0.68048937, 0.68183193, 0.68221012, 0.68472506,\n",
       "        0.69134332, 0.66891687, 0.68421451, 0.68381741, 0.67882535,\n",
       "        0.68498979, 0.67988428, 0.68920657, 0.68731563, 0.68629453,\n",
       "        0.68616217, 0.67670751, 0.70359655, 0.6831745 , 0.68313668,\n",
       "        0.68797746, 0.67748279, 0.69036003, 0.6907004 , 0.68606762,\n",
       "        0.68616217, 0.67670751, 0.70359655, 0.6831745 , 0.68313668,\n",
       "        0.68797746, 0.67748279, 0.69036003, 0.6907004 , 0.68606762,\n",
       "        0.69406626, 0.67579986, 0.69444444, 0.68932002, 0.68899856,\n",
       "        0.69136223, 0.68391196, 0.68098102, 0.68612435, 0.68969821,\n",
       "        0.70306709, 0.67752061, 0.67946827, 0.68986839, 0.68245594,\n",
       "        0.68376068, 0.69370698, 0.68894183, 0.68841237, 0.67950609]),\n",
       " 'split4_test_score': array([0.63573103, 0.64511005, 0.63298918, 0.6344452 , 0.64414568,\n",
       "        0.64210347, 0.64259511, 0.63921035, 0.64493987, 0.64346494,\n",
       "        0.63573103, 0.64511005, 0.63298918, 0.6344452 , 0.64414568,\n",
       "        0.64210347, 0.64259511, 0.63921035, 0.64493987, 0.64346494,\n",
       "        0.64843809, 0.66010514, 0.63072007, 0.63370774, 0.64047727,\n",
       "        0.64490205, 0.63410483, 0.63480448, 0.64250057, 0.64259511,\n",
       "        0.64410786, 0.65938658, 0.63747069, 0.64429695, 0.65989713,\n",
       "        0.6362794 , 0.63711141, 0.6521065 , 0.63062552, 0.64121473,\n",
       "        0.64410786, 0.65938658, 0.63747069, 0.64429695, 0.65989713,\n",
       "        0.6362794 , 0.63711141, 0.6521065 , 0.63062552, 0.64121473,\n",
       "        0.64501551, 0.65165267, 0.64475078, 0.63185463, 0.63045534,\n",
       "        0.62856441, 0.6443915 , 0.64323803, 0.64076091, 0.65212541,\n",
       "        0.63973981, 0.64770063, 0.64386204, 0.62979351, 0.65065048,\n",
       "        0.64314348, 0.64303003, 0.64015581, 0.64548824, 0.64779517,\n",
       "        0.63973981, 0.64770063, 0.64386204, 0.62979351, 0.65065048,\n",
       "        0.64314348, 0.64303003, 0.64015581, 0.64548824, 0.64779517,\n",
       "        0.65174722, 0.64442932, 0.64223584, 0.63699796, 0.64042054,\n",
       "        0.64335149, 0.63329173, 0.64919446, 0.64815445, 0.64335149,\n",
       "        0.64698207, 0.66647757, 0.63716814, 0.63297027, 0.65339233,\n",
       "        0.6301717 , 0.63531503, 0.64437259, 0.64306785, 0.6539407 ]),\n",
       " 'mean_test_score': array([0.66076852, 0.65967254, 0.66065508, 0.65808355, 0.65755026,\n",
       "        0.66471401, 0.6650858 , 0.65997113, 0.66124831, 0.66273172,\n",
       "        0.66076852, 0.65967254, 0.66065508, 0.65808355, 0.65755026,\n",
       "        0.66471401, 0.6650858 , 0.65997113, 0.66124831, 0.66273172,\n",
       "        0.66498612, 0.6661619 , 0.66044614, 0.66026958, 0.66511866,\n",
       "        0.66347215, 0.65910717, 0.66185895, 0.66402785, 0.66615415,\n",
       "        0.66219732, 0.66147989, 0.66478184, 0.655415  , 0.67292417,\n",
       "        0.66085499, 0.65820498, 0.66723601, 0.66034013, 0.66165326,\n",
       "        0.66219732, 0.66147989, 0.66478184, 0.655415  , 0.67292417,\n",
       "        0.66085499, 0.65820498, 0.66723601, 0.66034013, 0.66165326,\n",
       "        0.66547741, 0.65874115, 0.66282215, 0.65982143, 0.66347558,\n",
       "        0.66185962, 0.65876371, 0.66067089, 0.66219754, 0.66571372,\n",
       "        0.66319441, 0.66293414, 0.66827567, 0.65674746, 0.66669566,\n",
       "        0.66482848, 0.66244719, 0.66552952, 0.6652661 , 0.66237168,\n",
       "        0.66319441, 0.66293414, 0.66827567, 0.65674746, 0.66669566,\n",
       "        0.66482848, 0.66244719, 0.66552952, 0.6652661 , 0.66237168,\n",
       "        0.66431621, 0.66137899, 0.66406253, 0.66332762, 0.66720684,\n",
       "        0.66426363, 0.65910228, 0.6603768 , 0.66342785, 0.66602046,\n",
       "        0.66475272, 0.66519165, 0.66202536, 0.66431849, 0.66779494,\n",
       "        0.65582299, 0.66388865, 0.66414347, 0.66426586, 0.66421832]),\n",
       " 'std_test_score': array([0.02400529, 0.0221551 , 0.02156611, 0.01976175, 0.02033541,\n",
       "        0.02517305, 0.0229724 , 0.0251486 , 0.0184825 , 0.02044222,\n",
       "        0.02400529, 0.0221551 , 0.02156611, 0.01976175, 0.02033541,\n",
       "        0.02517305, 0.0229724 , 0.0251486 , 0.0184825 , 0.02044222,\n",
       "        0.02026249, 0.01662932, 0.02447533, 0.02138125, 0.01678585,\n",
       "        0.01771743, 0.02855442, 0.02602563, 0.02330073, 0.0190539 ,\n",
       "        0.02080888, 0.019027  , 0.01782045, 0.01502442, 0.01509171,\n",
       "        0.02649762, 0.02179498, 0.01696518, 0.02156278, 0.02059135,\n",
       "        0.02080888, 0.019027  , 0.01782045, 0.01502442, 0.01509171,\n",
       "        0.02649762, 0.02179498, 0.01696518, 0.02156278, 0.02059135,\n",
       "        0.02154322, 0.02293902, 0.01462211, 0.02238767, 0.02443824,\n",
       "        0.02153991, 0.02091886, 0.01948005, 0.02153739, 0.01990115,\n",
       "        0.02114441, 0.01880558, 0.0228718 , 0.02217233, 0.01828524,\n",
       "        0.01902854, 0.01946141, 0.01804128, 0.02107007, 0.01821148,\n",
       "        0.02114441, 0.01880558, 0.0228718 , 0.02217233, 0.01828524,\n",
       "        0.01902854, 0.01946141, 0.01804128, 0.02107007, 0.01821148,\n",
       "        0.02088562, 0.01994166, 0.0231769 , 0.02167223, 0.02469045,\n",
       "        0.01714449, 0.02531564, 0.0200978 , 0.02210467, 0.02215078,\n",
       "        0.02445372, 0.01890434, 0.01820951, 0.02172333, 0.0184545 ,\n",
       "        0.02026638, 0.02242194, 0.0238155 , 0.02271903, 0.02284767]),\n",
       " 'rank_test_score': array([71, 84, 74, 92, 94, 30, 22, 81, 67, 50, 71, 84, 74, 92, 94, 30, 22,\n",
       "        81, 67, 50, 24, 11, 76, 80, 21, 42, 86, 61, 39, 12, 57, 64, 27, 99,\n",
       "         1, 69, 90,  6, 78, 62, 57, 64, 27, 99,  1, 69, 90,  6, 78, 62, 17,\n",
       "        89, 49, 83, 41, 60, 88, 73, 56, 14, 45, 47,  3, 96,  9, 25, 52, 15,\n",
       "        18, 54, 45, 47,  3, 96,  9, 25, 52, 15, 18, 54, 33, 66, 38, 44,  8,\n",
       "        35, 87, 77, 43, 13, 29, 20, 59, 32,  5, 98, 40, 37, 34, 36])}"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch5.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Accuracy : 0.72\n",
      "AUC Score (Train): 0.729167\n"
     ]
    }
   ],
   "source": [
    "xgb15 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=177,\n",
    " max_depth=2,\n",
    " min_child_weight=8,\n",
    " gamma=0.02,\n",
    " subsample=0.79,\n",
    " colsample_bytree=0.926,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb15, X_train,y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:25:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'reg_alpha': 0.1}, 0.6642611262255892)"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test6 = {\n",
    " 'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]\n",
    "}\n",
    "gsearch6 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=177, max_depth=2,\n",
    " min_child_weight=8, gamma=0.02, subsample=0.93, colsample_bytree=0.79,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test6, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch6.fit(X_train,y_train)\n",
    "gsearch6.best_params_, gsearch6.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:26:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'reg_alpha': 0.1086}, 0.6690715474590723)"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test7 = {\n",
    " 'reg_alpha':[i/10000.0 for i in range(1070,1090)]\n",
    "}\n",
    "gsearch7 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=177, max_depth=2,\n",
    " min_child_weight=8, gamma=0.02, subsample=0.79, colsample_bytree=0.93,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test7, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch7.fit(X_train,y_train)\n",
    "gsearch7.best_params_, gsearch7.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Accuracy : 0.72\n",
      "AUC Score (Train): 0.729167\n"
     ]
    }
   ],
   "source": [
    "xgb3 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=2,\n",
    " min_child_weight=8,\n",
    " gamma=0.02,\n",
    " subsample=0.79,\n",
    " colsample_bytree=0.926,\n",
    " reg_alpha=0.1086,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb3, X_train,y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Accuracy : 0.76\n",
      "AUC Score (Train): 0.826389\n"
     ]
    }
   ],
   "source": [
    "xgb4 = XGBClassifier(\n",
    " learning_rate =0.01,\n",
    " n_estimators=5000,\n",
    " max_depth=2,\n",
    " min_child_weight=8,\n",
    " gamma=0.02,\n",
    " subsample=0.79,\n",
    " colsample_bytree=0.926,\n",
    " reg_alpha=0.1086,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb4, X,y, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1591\n"
     ]
    }
   ],
   "source": [
    "predicted_y = xgb4.predict(X_Sample_Test)\n",
    "predicted_y = list(predicted_y)\n",
    "w_list = []\n",
    "for j in range(len(predicted_y)):\n",
    "    w_list.append({\"Id\":(j+1), \"Category\":predicted_y[j]})\n",
    "print(len(w_list))\n",
    "with open('predictions'+'.csv', 'w', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=[\"Id\", \"Category\"])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(w_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base')",
   "language": "python",
   "name": "python37664bitbase3d920d87e3644dc8a79788ca4d0afcae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

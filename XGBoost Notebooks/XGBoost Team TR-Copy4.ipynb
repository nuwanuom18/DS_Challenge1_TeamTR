{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set() # if you want to use seaborn themes with matplotlib functions\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('CSE_DSIntro1_TRAIN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_state = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Column_1</th>\n",
       "      <th>Column_2</th>\n",
       "      <th>Column_3</th>\n",
       "      <th>Column_4</th>\n",
       "      <th>Column_5</th>\n",
       "      <th>Column_6</th>\n",
       "      <th>Column_7</th>\n",
       "      <th>Column_8</th>\n",
       "      <th>Column_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Column_69</th>\n",
       "      <th>Column_70</th>\n",
       "      <th>Column_71</th>\n",
       "      <th>Column_72</th>\n",
       "      <th>Column_73</th>\n",
       "      <th>Column_74</th>\n",
       "      <th>Column_75</th>\n",
       "      <th>Column_76</th>\n",
       "      <th>Column_77</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>77041.5</td>\n",
       "      <td>44471.03389</td>\n",
       "      <td>88955.41342</td>\n",
       "      <td>1602.4632</td>\n",
       "      <td>1787.3628</td>\n",
       "      <td>1571.6466</td>\n",
       "      <td>1294.2972</td>\n",
       "      <td>1664.0964</td>\n",
       "      <td>1756.5462</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>77120.0</td>\n",
       "      <td>44516.34682</td>\n",
       "      <td>89046.05288</td>\n",
       "      <td>1573.2480</td>\n",
       "      <td>2128.5120</td>\n",
       "      <td>987.1360</td>\n",
       "      <td>956.2880</td>\n",
       "      <td>1511.5520</td>\n",
       "      <td>1388.1600</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>77120.0</td>\n",
       "      <td>44516.34682</td>\n",
       "      <td>89046.05288</td>\n",
       "      <td>1789.1840</td>\n",
       "      <td>1511.5520</td>\n",
       "      <td>1665.7920</td>\n",
       "      <td>1326.4640</td>\n",
       "      <td>1357.3120</td>\n",
       "      <td>1634.9440</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>77117.5</td>\n",
       "      <td>44514.90373</td>\n",
       "      <td>89043.16628</td>\n",
       "      <td>1511.5030</td>\n",
       "      <td>1789.1260</td>\n",
       "      <td>1233.8800</td>\n",
       "      <td>1881.6670</td>\n",
       "      <td>1418.9620</td>\n",
       "      <td>2159.2900</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>77120.0</td>\n",
       "      <td>44516.34682</td>\n",
       "      <td>89046.05288</td>\n",
       "      <td>1974.2720</td>\n",
       "      <td>1696.6400</td>\n",
       "      <td>832.8960</td>\n",
       "      <td>1820.0320</td>\n",
       "      <td>1758.3360</td>\n",
       "      <td>1727.4880</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>2496</td>\n",
       "      <td>77117.5</td>\n",
       "      <td>44514.90373</td>\n",
       "      <td>89043.16628</td>\n",
       "      <td>1203.0330</td>\n",
       "      <td>2282.6780</td>\n",
       "      <td>1542.3500</td>\n",
       "      <td>1758.2790</td>\n",
       "      <td>1850.8200</td>\n",
       "      <td>1295.5740</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>42</td>\n",
       "      <td>33</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>2497</td>\n",
       "      <td>77120.0</td>\n",
       "      <td>44516.34682</td>\n",
       "      <td>89046.05288</td>\n",
       "      <td>894.5920</td>\n",
       "      <td>1203.0720</td>\n",
       "      <td>1079.6800</td>\n",
       "      <td>1480.7040</td>\n",
       "      <td>1449.8560</td>\n",
       "      <td>1604.0960</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>42</td>\n",
       "      <td>34</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>2498</td>\n",
       "      <td>77117.5</td>\n",
       "      <td>44514.90373</td>\n",
       "      <td>89043.16628</td>\n",
       "      <td>1789.1260</td>\n",
       "      <td>1604.0440</td>\n",
       "      <td>1326.4210</td>\n",
       "      <td>1418.9620</td>\n",
       "      <td>1542.3500</td>\n",
       "      <td>1511.5030</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>42</td>\n",
       "      <td>34</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>2499</td>\n",
       "      <td>77117.5</td>\n",
       "      <td>44514.90373</td>\n",
       "      <td>89043.16628</td>\n",
       "      <td>1789.1260</td>\n",
       "      <td>524.3990</td>\n",
       "      <td>1511.5030</td>\n",
       "      <td>1357.2680</td>\n",
       "      <td>863.7160</td>\n",
       "      <td>616.9400</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>42</td>\n",
       "      <td>35</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>2500</td>\n",
       "      <td>77120.0</td>\n",
       "      <td>44516.34682</td>\n",
       "      <td>89046.05288</td>\n",
       "      <td>1542.4000</td>\n",
       "      <td>1789.1840</td>\n",
       "      <td>1850.8800</td>\n",
       "      <td>1511.5520</td>\n",
       "      <td>1758.3360</td>\n",
       "      <td>1326.4640</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>42</td>\n",
       "      <td>35</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  Column_1     Column_2     Column_3   Column_4   Column_5  \\\n",
       "0        1   77041.5  44471.03389  88955.41342  1602.4632  1787.3628   \n",
       "1        2   77120.0  44516.34682  89046.05288  1573.2480  2128.5120   \n",
       "2        3   77120.0  44516.34682  89046.05288  1789.1840  1511.5520   \n",
       "3        4   77117.5  44514.90373  89043.16628  1511.5030  1789.1260   \n",
       "4        5   77120.0  44516.34682  89046.05288  1974.2720  1696.6400   \n",
       "...    ...       ...          ...          ...        ...        ...   \n",
       "2495  2496   77117.5  44514.90373  89043.16628  1203.0330  2282.6780   \n",
       "2496  2497   77120.0  44516.34682  89046.05288   894.5920  1203.0720   \n",
       "2497  2498   77117.5  44514.90373  89043.16628  1789.1260  1604.0440   \n",
       "2498  2499   77117.5  44514.90373  89043.16628  1789.1260   524.3990   \n",
       "2499  2500   77120.0  44516.34682  89046.05288  1542.4000  1789.1840   \n",
       "\n",
       "       Column_6   Column_7   Column_8   Column_9  ...  Column_69  Column_70  \\\n",
       "0     1571.6466  1294.2972  1664.0964  1756.5462  ...         22          2   \n",
       "1      987.1360   956.2880  1511.5520  1388.1600  ...         22          2   \n",
       "2     1665.7920  1326.4640  1357.3120  1634.9440  ...         22          2   \n",
       "3     1233.8800  1881.6670  1418.9620  2159.2900  ...         22          2   \n",
       "4      832.8960  1820.0320  1758.3360  1727.4880  ...         22          2   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "2495  1542.3500  1758.2790  1850.8200  1295.5740  ...         22          2   \n",
       "2496  1079.6800  1480.7040  1449.8560  1604.0960  ...         22          2   \n",
       "2497  1326.4210  1418.9620  1542.3500  1511.5030  ...         22          2   \n",
       "2498  1511.5030  1357.2680   863.7160   616.9400  ...         22          2   \n",
       "2499  1850.8800  1511.5520  1758.3360  1326.4640  ...         22          2   \n",
       "\n",
       "      Column_71  Column_72  Column_73  Column_74  Column_75  Column_76  \\\n",
       "0          2021         11         23         15         22          2   \n",
       "1          2021         11         23         15         22          2   \n",
       "2          2021         11         23         15         22          2   \n",
       "3          2021         11         23         16         22          2   \n",
       "4          2021         11         23         16         22          2   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "2495       2021         11         42         33         22          2   \n",
       "2496       2021         11         42         34         22          2   \n",
       "2497       2021         11         42         34         22          2   \n",
       "2498       2021         11         42         35         22          2   \n",
       "2499       2021         11         42         35         22          2   \n",
       "\n",
       "      Column_77  Category  \n",
       "0          2021         0  \n",
       "1          2021         0  \n",
       "2          2021         0  \n",
       "3          2021         0  \n",
       "4          2021         0  \n",
       "...         ...       ...  \n",
       "2495       2021         1  \n",
       "2496       2021         1  \n",
       "2497       2021         1  \n",
       "2498       2021         0  \n",
       "2499       2021         0  \n",
       "\n",
       "[2500 rows x 79 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id           0.0\n",
       "Column_1     0.0\n",
       "Column_2     0.0\n",
       "Column_3     0.0\n",
       "Column_4     0.0\n",
       "            ... \n",
       "Column_74    0.0\n",
       "Column_75    0.0\n",
       "Column_76    0.0\n",
       "Column_77    0.0\n",
       "Category     0.0\n",
       "Length: 79, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()/len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(dataset.duplicated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the duplicates:\n",
    "dataset.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 1 Column_55\n",
      "57 1 Column_57\n",
      "66 1 Column_66\n",
      "69 1 Column_69\n",
      "70 1 Column_70\n",
      "71 1 Column_71\n",
      "72 1 Column_72\n",
      "75 1 Column_75\n",
      "76 1 Column_76\n",
      "77 1 Column_77\n"
     ]
    }
   ],
   "source": [
    "unique_values = list(dataset.nunique())\n",
    "for i in range(len(unique_values)):\n",
    "    if unique_values[i] == 1:\n",
    "        print(i, unique_values[i],dataset.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find 55\n",
      "find 57\n",
      "find 66\n",
      "find 69\n",
      "find 70\n",
      "find 71\n",
      "find 72\n",
      "find 75\n",
      "find 76\n",
      "find 77\n",
      "        Id  Column_1     Column_2     Column_3   Column_4   Column_5  \\\n",
      "0        1   77041.5  44471.03389  88955.41342  1602.4632  1787.3628   \n",
      "1        2   77120.0  44516.34682  89046.05288  1573.2480  2128.5120   \n",
      "2        3   77120.0  44516.34682  89046.05288  1789.1840  1511.5520   \n",
      "3        4   77117.5  44514.90373  89043.16628  1511.5030  1789.1260   \n",
      "4        5   77120.0  44516.34682  89046.05288  1974.2720  1696.6400   \n",
      "...    ...       ...          ...          ...        ...        ...   \n",
      "2495  2496   77117.5  44514.90373  89043.16628  1203.0330  2282.6780   \n",
      "2496  2497   77120.0  44516.34682  89046.05288   894.5920  1203.0720   \n",
      "2497  2498   77117.5  44514.90373  89043.16628  1789.1260  1604.0440   \n",
      "2498  2499   77117.5  44514.90373  89043.16628  1789.1260   524.3990   \n",
      "2499  2500   77120.0  44516.34682  89046.05288  1542.4000  1789.1840   \n",
      "\n",
      "       Column_6   Column_7   Column_8   Column_9  ...  Column_61    Column_62  \\\n",
      "0     1571.6466  1294.2972  1664.0964  1756.5462  ...   1.511108  63642.86256   \n",
      "1      987.1360   956.2880  1511.5520  1388.1600  ...   1.511097  63649.22304   \n",
      "2     1665.7920  1326.4640  1357.3120  1634.9440  ...   1.511247  63658.20567   \n",
      "3     1233.8800  1881.6670  1418.9620  2159.2900  ...   1.511245  63655.53620   \n",
      "4      832.8960  1820.0320  1758.3360  1727.4880  ...   1.511409  63637.01387   \n",
      "...         ...        ...        ...        ...  ...        ...          ...   \n",
      "2495  1542.3500  1758.2790  1850.8200  1295.5740  ...   1.511090  63689.52068   \n",
      "2496  1079.6800  1480.7040  1449.8560  1604.0960  ...   1.511129  63696.82226   \n",
      "2497  1326.4210  1418.9620  1542.3500  1511.5030  ...   1.511286  63695.04189   \n",
      "2498  1511.5030  1357.2680   863.7160   616.9400  ...   1.511245  63683.13411   \n",
      "2499  1850.8800  1511.5520  1758.3360  1326.4640  ...   1.511552  63697.79604   \n",
      "\n",
      "      Column_63  Column_64  Column_65  Column_67  Column_68  Column_73  \\\n",
      "0      1.527652   0.073507   1.511320         23         15         23   \n",
      "1      1.527373   0.073794   1.511169         23         15         23   \n",
      "2      1.527631   0.073571   1.511256         23         15         23   \n",
      "3      1.527550   0.073430   1.511489         23         16         23   \n",
      "4      1.527490   0.073543   1.511393         23         16         23   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "2495   1.527730   0.073834   1.510860         42         33         42   \n",
      "2496   1.527971   0.073253   1.511402         42         34         42   \n",
      "2497   1.527891   0.073301   1.511400         42         34         42   \n",
      "2498   1.527758   0.073542   1.511201         42         35         42   \n",
      "2499   1.527767   0.073461   1.511293         42         35         42   \n",
      "\n",
      "      Column_74  Category  \n",
      "0            15         0  \n",
      "1            15         0  \n",
      "2            15         0  \n",
      "3            16         0  \n",
      "4            16         0  \n",
      "...         ...       ...  \n",
      "2495         33         1  \n",
      "2496         34         1  \n",
      "2497         34         1  \n",
      "2498         35         0  \n",
      "2499         35         0  \n",
      "\n",
      "[2500 rows x 69 columns]\n"
     ]
    }
   ],
   "source": [
    "unique_values = list(dataset.nunique())\n",
    "k=0\n",
    "for i in range(len(unique_values)):\n",
    "    if unique_values[i] == 1:\n",
    "        print('find', i)\n",
    "        dataset.drop(dataset.columns[i-k], axis=1 ,inplace=True)\n",
    "        k+=1\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'Column_1', 'Column_2', 'Column_3', 'Column_4', 'Column_5',\n",
       "       'Column_6', 'Column_7', 'Column_8', 'Column_9', 'Column_10',\n",
       "       'Column_11', 'Column_12', 'Column_13', 'Column_14', 'Column_15',\n",
       "       'Column_16', 'Column_17', 'Column_18', 'Column_19', 'Column_20',\n",
       "       'Column_21', 'Column_22', 'Column_23', 'Column_24', 'Column_25',\n",
       "       'Column_26', 'Column_27', 'Column_28', 'Column_29', 'Column_30',\n",
       "       'Column_31', 'Column_32', 'Column_33', 'Column_34', 'Column_35',\n",
       "       'Column_36', 'Column_37', 'Column_38', 'Column_39', 'Column_40',\n",
       "       'Column_41', 'Column_42', 'Column_43', 'Column_44', 'Column_45',\n",
       "       'Column_46', 'Column_47', 'Column_48', 'Column_49', 'Column_50',\n",
       "       'Column_51', 'Column_52', 'Column_53', 'Column_54', 'Column_56',\n",
       "       'Column_58', 'Column_59', 'Column_60', 'Column_61', 'Column_62',\n",
       "       'Column_63', 'Column_64', 'Column_65', 'Column_67', 'Column_68',\n",
       "       'Column_73', 'Column_74', 'Category'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('CSE_DSIntro1_TEST.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 1 Column_55\n",
      "57 1 Column_57\n",
      "66 1 Column_66\n",
      "69 1 Column_69\n",
      "70 1 Column_70\n",
      "71 1 Column_71\n",
      "72 1 Column_72\n",
      "75 1 Column_75\n",
      "76 1 Column_76\n",
      "77 1 Column_77\n"
     ]
    }
   ],
   "source": [
    "unique_values_test = list(test_data.nunique())\n",
    "for i in range(len(unique_values_test)):\n",
    "    if unique_values_test[i] == 1:\n",
    "        print(i, unique_values_test[i],test_data.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find 55\n",
      "find 57\n",
      "find 66\n",
      "find 69\n",
      "find 70\n",
      "find 71\n",
      "find 72\n",
      "find 75\n",
      "find 76\n",
      "find 77\n",
      "        Id  Column_1     Column_2     Column_3   Column_4   Column_5  \\\n",
      "0        1  77117.50  44514.90373  89043.16628  1696.5850  1665.7380   \n",
      "1        2  77120.00  44516.34682  89046.05288  1357.3120   339.3280   \n",
      "2        3  77120.00  44516.34682  89046.05288  1758.3360  1974.2720   \n",
      "3        4  77120.00  44516.34682  89046.05288  1110.5280  1264.7680   \n",
      "4        5  77120.00  44516.34682  89046.05288  2652.9280  2005.1200   \n",
      "...    ...       ...          ...          ...        ...        ...   \n",
      "1586  1587  77120.00  44516.34682  89046.05288  1789.1840  1881.7280   \n",
      "1587  1588  77117.50  44514.90373  89043.16628  1696.5850  1357.2680   \n",
      "1588  1589  77122.25  44517.64560  89048.65083  1696.6895  1727.5384   \n",
      "1589  1590  77122.25  44517.64560  89048.65083  1449.8983  1789.2362   \n",
      "1590  1591  77122.25  44517.64560  89048.65083  1449.8983  1326.5027   \n",
      "\n",
      "       Column_6   Column_7   Column_8   Column_9  ...  Column_60  Column_61  \\\n",
      "0     1418.9620  1264.7270  1203.0330  1573.1970  ...   0.073235   1.511481   \n",
      "1     1326.4640  1017.9840  1573.2480  1604.0960  ...   0.073413   1.511241   \n",
      "2     1480.7040  1141.3760  1542.4000  1388.1600  ...   0.073253   1.511402   \n",
      "3     1388.1600  1449.8560  1573.2480  1419.0080  ...   0.073415   1.511293   \n",
      "4     1943.4240   493.5680  1388.1600   740.3520  ...   0.073395   1.511170   \n",
      "...         ...        ...        ...        ...  ...        ...        ...   \n",
      "1586  1449.8560  1573.2480  1419.0080  1542.4000  ...   0.073209   1.511755   \n",
      "1587  1727.4320  1542.3500  1295.5740  1449.8090  ...   0.073503   1.511498   \n",
      "1588  1573.2939  1449.8983   246.7912  1480.7472  ...   0.073398   1.511532   \n",
      "1589  1634.9917  1203.1071  1326.5027  1357.3516  ...   0.073327   1.511689   \n",
      "1590  1388.2005   154.2445  1480.7472  1048.8626  ...   0.073095   1.511757   \n",
      "\n",
      "        Column_62  Column_63  Column_64  Column_65  Column_67  Column_68  \\\n",
      "0     63697.96460   1.527815   0.073497   1.511214         42         36   \n",
      "1     63707.62973   1.527853   0.073633   1.511019         42         36   \n",
      "2     63699.33986   1.527973   0.073148   1.511530         42         36   \n",
      "3     63691.57205   1.527999   0.073202   1.511444         42         37   \n",
      "4     63691.78617   1.527921   0.073248   1.511445         42         37   \n",
      "...           ...        ...        ...        ...        ...        ...   \n",
      "1586  63656.58449   1.527551   0.073225   1.511742         56          0   \n",
      "1587  63655.56354   1.527707   0.073006   1.511899         56          0   \n",
      "1588  63659.57645   1.527553   0.073222   1.511745         56          1   \n",
      "1589  63638.76254   1.527492   0.073274   1.511726         56          1   \n",
      "1590  63657.61274   1.527457   0.073445   1.511539         56          2   \n",
      "\n",
      "      Column_73  Column_74  \n",
      "0            42         36  \n",
      "1            42         36  \n",
      "2            42         37  \n",
      "3            42         37  \n",
      "4            42         37  \n",
      "...         ...        ...  \n",
      "1586         56          0  \n",
      "1587         56          0  \n",
      "1588         56          1  \n",
      "1589         56          1  \n",
      "1590         56          2  \n",
      "\n",
      "[1591 rows x 68 columns]\n"
     ]
    }
   ],
   "source": [
    "k_test=0\n",
    "for i in range(len(unique_values_test)):\n",
    "    if unique_values_test[i] == 1:\n",
    "        print('find', i)\n",
    "        test_data.drop(test_data.columns[i-k_test], axis=1 ,inplace=True)\n",
    "        k_test+=1\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'Column_1', 'Column_2', 'Column_3', 'Column_4', 'Column_5',\n",
       "       'Column_6', 'Column_7', 'Column_8', 'Column_9', 'Column_10',\n",
       "       'Column_11', 'Column_12', 'Column_13', 'Column_14', 'Column_15',\n",
       "       'Column_16', 'Column_17', 'Column_18', 'Column_19', 'Column_20',\n",
       "       'Column_21', 'Column_22', 'Column_23', 'Column_24', 'Column_25',\n",
       "       'Column_26', 'Column_27', 'Column_28', 'Column_29', 'Column_30',\n",
       "       'Column_31', 'Column_32', 'Column_33', 'Column_34', 'Column_35',\n",
       "       'Column_36', 'Column_37', 'Column_38', 'Column_39', 'Column_40',\n",
       "       'Column_41', 'Column_42', 'Column_43', 'Column_44', 'Column_45',\n",
       "       'Column_46', 'Column_47', 'Column_48', 'Column_49', 'Column_50',\n",
       "       'Column_51', 'Column_52', 'Column_53', 'Column_54', 'Column_56',\n",
       "       'Column_58', 'Column_59', 'Column_60', 'Column_61', 'Column_62',\n",
       "       'Column_63', 'Column_64', 'Column_65', 'Column_67', 'Column_68',\n",
       "       'Column_73', 'Column_74'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 1:-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Sample_Test = test_data.values[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.71175000e+04, 4.45149037e+04, 8.90431663e+04, ...,\n",
       "        3.60000000e+01, 4.20000000e+01, 3.60000000e+01],\n",
       "       [7.71200000e+04, 4.45163468e+04, 8.90460529e+04, ...,\n",
       "        3.60000000e+01, 4.20000000e+01, 3.60000000e+01],\n",
       "       [7.71200000e+04, 4.45163468e+04, 8.90460529e+04, ...,\n",
       "        3.60000000e+01, 4.20000000e+01, 3.70000000e+01],\n",
       "       ...,\n",
       "       [7.71222500e+04, 4.45176456e+04, 8.90486508e+04, ...,\n",
       "        1.00000000e+00, 5.60000000e+01, 1.00000000e+00],\n",
       "       [7.71222500e+04, 4.45176456e+04, 8.90486508e+04, ...,\n",
       "        1.00000000e+00, 5.60000000e+01, 1.00000000e+00],\n",
       "       [7.71222500e+04, 4.45176456e+04, 8.90486508e+04, ...,\n",
       "        2.00000000e+00, 5.60000000e+01, 2.00000000e+00]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Sample_Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.70415000e+04, 4.44710339e+04, 8.89554134e+04, ...,\n",
       "        1.50000000e+01, 2.30000000e+01, 1.50000000e+01],\n",
       "       [7.71200000e+04, 4.45163468e+04, 8.90460529e+04, ...,\n",
       "        1.50000000e+01, 2.30000000e+01, 1.50000000e+01],\n",
       "       [7.71200000e+04, 4.45163468e+04, 8.90460529e+04, ...,\n",
       "        1.50000000e+01, 2.30000000e+01, 1.50000000e+01],\n",
       "       ...,\n",
       "       [7.71175000e+04, 4.45149037e+04, 8.90431663e+04, ...,\n",
       "        3.40000000e+01, 4.20000000e+01, 3.40000000e+01],\n",
       "       [7.71175000e+04, 4.45149037e+04, 8.90431663e+04, ...,\n",
       "        3.50000000e+01, 4.20000000e+01, 3.50000000e+01],\n",
       "       [7.71200000e+04, 4.45163468e+04, 8.90460529e+04, ...,\n",
       "        3.50000000e+01, 4.20000000e+01, 3.50000000e+01]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.01, random_state = rand_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn import  metrics   #Additional scklearn functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelfit(alg, X_train,y_train, X_test, y_test ,useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='auc', early_stopping_rounds=early_stopping_rounds)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(X_train, y_train ,eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(X_test)\n",
    "    dtrain_predprob = alg.predict_proba(X_test)[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"Accuracy : %.4g\" % metrics.accuracy_score(y_test, dtrain_predictions))\n",
    "    print(\"AUC Score (Train): %f\" % metrics.roc_auc_score(y_test, dtrain_predprob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Category'\n",
    "IDcol = 'Id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Accuracy : 0.64\n",
      "AUC Score (Train): 0.694444\n"
     ]
    }
   ],
   "source": [
    "#Choose all predictors except target & IDcols\n",
    "predictors = [x for x in dataset.columns if x not in ['Category', \"Id\"]]\n",
    "xgb1 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb1, X_train,y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_test1 = {\n",
    " 'max_depth':range(1,10),\n",
    " 'min_child_weight':range(1,10)\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=1000, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_depth': 1, 'min_child_weight': 5}, 0.6523015308926258)"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 5.14646025,  5.09098806,  5.02760334,  4.98404241,  4.8102704 ,\n",
       "         4.99972062,  4.98946576,  5.01885953,  5.04565806,  8.3889359 ,\n",
       "         8.74603558,  8.80695248,  8.70603218,  8.37955923,  8.4356061 ,\n",
       "         8.52354431,  8.25247879,  8.44954486, 12.58162136, 12.42001901,\n",
       "        12.11461592, 12.06438212, 11.91784768, 12.88632994, 11.84580235,\n",
       "        12.56151423, 11.17101879, 15.82269683, 15.15029473, 14.60495224,\n",
       "        14.11506257, 13.94770908, 13.80030432, 13.52783246, 13.39997392,\n",
       "        13.18614588, 18.11476874, 16.86351438, 16.84017677, 16.13486323,\n",
       "        15.46006598, 15.23506818, 15.00229053, 14.83772998, 14.5850059 ,\n",
       "        19.52759185, 17.82494464, 17.31191568, 16.64689298, 16.26631093,\n",
       "        16.01019597, 15.76724553, 15.51731339, 15.15687737, 20.10085826,\n",
       "        18.54103289, 18.00885606, 16.78372784, 16.43146925, 15.85620642,\n",
       "        15.76165967, 15.60308385, 15.1935791 , 19.97539392, 18.41337042,\n",
       "        17.89934468, 17.36008835, 16.70743747, 16.79150639, 16.52182736,\n",
       "        15.75428042, 15.38107738, 20.11981645, 18.51310415, 17.6097188 ,\n",
       "        17.12302041, 17.5590548 , 16.2760849 , 16.14802704, 15.73796401,\n",
       "        13.36090283]),\n",
       " 'std_fit_time': array([0.01578752, 0.04586244, 0.02366192, 0.05989663, 0.09223713,\n",
       "        0.02558021, 0.03905846, 0.02985938, 0.24985459, 0.34366379,\n",
       "        0.11899396, 0.11930959, 0.12815624, 0.08113795, 0.16039186,\n",
       "        0.19311581, 0.10375524, 0.18229775, 0.12548065, 0.21703769,\n",
       "        0.03485924, 0.16889936, 0.25307461, 0.56781273, 0.65614038,\n",
       "        1.00252951, 0.0563105 , 0.07798355, 0.06995638, 0.10229947,\n",
       "        0.08401135, 0.15818597, 0.18594556, 0.09719589, 0.15930357,\n",
       "        0.18234209, 0.15733285, 0.03130182, 0.28550187, 0.01657911,\n",
       "        0.15665577, 0.08421273, 0.15261216, 0.01863347, 0.1601567 ,\n",
       "        0.14226209, 0.14340916, 0.08516878, 0.12259505, 0.07936986,\n",
       "        0.03516523, 0.14622229, 0.04462611, 0.0960727 , 0.08781946,\n",
       "        0.42717048, 0.50465702, 0.09725662, 0.03958088, 0.11289472,\n",
       "        0.05490763, 0.05373903, 0.16411568, 0.27821394, 0.19066434,\n",
       "        0.17203222, 0.20721472, 0.29212961, 0.25101586, 0.3247434 ,\n",
       "        0.05389524, 0.19252729, 0.20746932, 0.12646025, 0.09499646,\n",
       "        0.07838069, 0.36186836, 0.34732427, 0.03720131, 0.04570669,\n",
       "        2.93655505]),\n",
       " 'mean_score_time': array([0.01058774, 0.00981035, 0.00909123, 0.01561875, 0.01039658,\n",
       "        0.0091032 , 0.00880046, 0.00898871, 0.01049976, 0.00999236,\n",
       "        0.00978684, 0.00880103, 0.00960488, 0.00860119, 0.00980515,\n",
       "        0.01339855, 0.01539378, 0.00939255, 0.01029882, 0.01138129,\n",
       "        0.01040187, 0.01144824, 0.01120806, 0.01170545, 0.01170492,\n",
       "        0.01158557, 0.01196847, 0.01037278, 0.01216822, 0.01137023,\n",
       "        0.0123672 , 0.0115694 , 0.01316471, 0.01256676, 0.01157007,\n",
       "        0.01156931, 0.01156988, 0.01236897, 0.01176891, 0.01156893,\n",
       "        0.01276679, 0.0127666 , 0.01316547, 0.01176887, 0.01077209,\n",
       "        0.01336465, 0.01236768, 0.01356368, 0.01176872, 0.01316533,\n",
       "        0.01196852, 0.014362  , 0.01117048, 0.01496024, 0.012567  ,\n",
       "        0.0155591 , 0.01196828, 0.01136961, 0.0127666 , 0.01216826,\n",
       "        0.01057234, 0.01216836, 0.01216769, 0.01376386, 0.01256642,\n",
       "        0.01156974, 0.01176915, 0.01216817, 0.01057229, 0.0113699 ,\n",
       "        0.01196833, 0.01156955, 0.01436286, 0.01276641, 0.01196861,\n",
       "        0.0113698 , 0.01476078, 0.01336417, 0.01117063, 0.01336498,\n",
       "        0.0125668 ]),\n",
       " 'std_score_time': array([0.00100431, 0.00162561, 0.00120375, 0.00407126, 0.00324675,\n",
       "        0.00080769, 0.00117306, 0.00143171, 0.00348838, 0.00062227,\n",
       "        0.00117471, 0.00039488, 0.0007966 , 0.00120169, 0.00074564,\n",
       "        0.0037273 , 0.0047056 , 0.00101026, 0.00153866, 0.00161113,\n",
       "        0.00048938, 0.00237009, 0.00195113, 0.00231137, 0.00171573,\n",
       "        0.00185471, 0.00209187, 0.0004886 , 0.00255367, 0.00135302,\n",
       "        0.00337291, 0.00119735, 0.00263098, 0.00293166, 0.00149232,\n",
       "        0.00079771, 0.00119695, 0.00135355, 0.00074689, 0.00135065,\n",
       "        0.0014662 , 0.00263134, 0.00239416, 0.00146527, 0.00074612,\n",
       "        0.00079746, 0.00174012, 0.00161969, 0.00074639, 0.00171561,\n",
       "        0.00154474, 0.00360117, 0.00146577, 0.00345481, 0.00079784,\n",
       "        0.00293138, 0.00126162, 0.00135292, 0.00146546, 0.00159638,\n",
       "        0.000798  , 0.00097705, 0.00116311, 0.00146584, 0.00119693,\n",
       "        0.00135304, 0.00182812, 0.00116336, 0.0004885 , 0.00079807,\n",
       "        0.0014101 , 0.00079801, 0.0032525 , 0.0007463 , 0.00109275,\n",
       "        0.00079806, 0.00203427, 0.00173863, 0.00039899, 0.00241057,\n",
       "        0.00184963]),\n",
       " 'param_max_depth': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_child_weight': masked_array(data=[1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                    1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                    1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                    1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                    1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'max_depth': 1, 'min_child_weight': 1},\n",
       "  {'max_depth': 1, 'min_child_weight': 2},\n",
       "  {'max_depth': 1, 'min_child_weight': 3},\n",
       "  {'max_depth': 1, 'min_child_weight': 4},\n",
       "  {'max_depth': 1, 'min_child_weight': 5},\n",
       "  {'max_depth': 1, 'min_child_weight': 6},\n",
       "  {'max_depth': 1, 'min_child_weight': 7},\n",
       "  {'max_depth': 1, 'min_child_weight': 8},\n",
       "  {'max_depth': 1, 'min_child_weight': 9},\n",
       "  {'max_depth': 2, 'min_child_weight': 1},\n",
       "  {'max_depth': 2, 'min_child_weight': 2},\n",
       "  {'max_depth': 2, 'min_child_weight': 3},\n",
       "  {'max_depth': 2, 'min_child_weight': 4},\n",
       "  {'max_depth': 2, 'min_child_weight': 5},\n",
       "  {'max_depth': 2, 'min_child_weight': 6},\n",
       "  {'max_depth': 2, 'min_child_weight': 7},\n",
       "  {'max_depth': 2, 'min_child_weight': 8},\n",
       "  {'max_depth': 2, 'min_child_weight': 9},\n",
       "  {'max_depth': 3, 'min_child_weight': 1},\n",
       "  {'max_depth': 3, 'min_child_weight': 2},\n",
       "  {'max_depth': 3, 'min_child_weight': 3},\n",
       "  {'max_depth': 3, 'min_child_weight': 4},\n",
       "  {'max_depth': 3, 'min_child_weight': 5},\n",
       "  {'max_depth': 3, 'min_child_weight': 6},\n",
       "  {'max_depth': 3, 'min_child_weight': 7},\n",
       "  {'max_depth': 3, 'min_child_weight': 8},\n",
       "  {'max_depth': 3, 'min_child_weight': 9},\n",
       "  {'max_depth': 4, 'min_child_weight': 1},\n",
       "  {'max_depth': 4, 'min_child_weight': 2},\n",
       "  {'max_depth': 4, 'min_child_weight': 3},\n",
       "  {'max_depth': 4, 'min_child_weight': 4},\n",
       "  {'max_depth': 4, 'min_child_weight': 5},\n",
       "  {'max_depth': 4, 'min_child_weight': 6},\n",
       "  {'max_depth': 4, 'min_child_weight': 7},\n",
       "  {'max_depth': 4, 'min_child_weight': 8},\n",
       "  {'max_depth': 4, 'min_child_weight': 9},\n",
       "  {'max_depth': 5, 'min_child_weight': 1},\n",
       "  {'max_depth': 5, 'min_child_weight': 2},\n",
       "  {'max_depth': 5, 'min_child_weight': 3},\n",
       "  {'max_depth': 5, 'min_child_weight': 4},\n",
       "  {'max_depth': 5, 'min_child_weight': 5},\n",
       "  {'max_depth': 5, 'min_child_weight': 6},\n",
       "  {'max_depth': 5, 'min_child_weight': 7},\n",
       "  {'max_depth': 5, 'min_child_weight': 8},\n",
       "  {'max_depth': 5, 'min_child_weight': 9},\n",
       "  {'max_depth': 6, 'min_child_weight': 1},\n",
       "  {'max_depth': 6, 'min_child_weight': 2},\n",
       "  {'max_depth': 6, 'min_child_weight': 3},\n",
       "  {'max_depth': 6, 'min_child_weight': 4},\n",
       "  {'max_depth': 6, 'min_child_weight': 5},\n",
       "  {'max_depth': 6, 'min_child_weight': 6},\n",
       "  {'max_depth': 6, 'min_child_weight': 7},\n",
       "  {'max_depth': 6, 'min_child_weight': 8},\n",
       "  {'max_depth': 6, 'min_child_weight': 9},\n",
       "  {'max_depth': 7, 'min_child_weight': 1},\n",
       "  {'max_depth': 7, 'min_child_weight': 2},\n",
       "  {'max_depth': 7, 'min_child_weight': 3},\n",
       "  {'max_depth': 7, 'min_child_weight': 4},\n",
       "  {'max_depth': 7, 'min_child_weight': 5},\n",
       "  {'max_depth': 7, 'min_child_weight': 6},\n",
       "  {'max_depth': 7, 'min_child_weight': 7},\n",
       "  {'max_depth': 7, 'min_child_weight': 8},\n",
       "  {'max_depth': 7, 'min_child_weight': 9},\n",
       "  {'max_depth': 8, 'min_child_weight': 1},\n",
       "  {'max_depth': 8, 'min_child_weight': 2},\n",
       "  {'max_depth': 8, 'min_child_weight': 3},\n",
       "  {'max_depth': 8, 'min_child_weight': 4},\n",
       "  {'max_depth': 8, 'min_child_weight': 5},\n",
       "  {'max_depth': 8, 'min_child_weight': 6},\n",
       "  {'max_depth': 8, 'min_child_weight': 7},\n",
       "  {'max_depth': 8, 'min_child_weight': 8},\n",
       "  {'max_depth': 8, 'min_child_weight': 9},\n",
       "  {'max_depth': 9, 'min_child_weight': 1},\n",
       "  {'max_depth': 9, 'min_child_weight': 2},\n",
       "  {'max_depth': 9, 'min_child_weight': 3},\n",
       "  {'max_depth': 9, 'min_child_weight': 4},\n",
       "  {'max_depth': 9, 'min_child_weight': 5},\n",
       "  {'max_depth': 9, 'min_child_weight': 6},\n",
       "  {'max_depth': 9, 'min_child_weight': 7},\n",
       "  {'max_depth': 9, 'min_child_weight': 8},\n",
       "  {'max_depth': 9, 'min_child_weight': 9}],\n",
       " 'split0_test_score': array([0.63577432, 0.64172917, 0.6441601 , 0.64397166, 0.64521539,\n",
       "        0.64048543, 0.63878943, 0.63944899, 0.64054197, 0.66253345,\n",
       "        0.65377078, 0.65497682, 0.65850073, 0.65101949, 0.64427317,\n",
       "        0.64299175, 0.64598801, 0.63095014, 0.65196171, 0.63656579,\n",
       "        0.63091245, 0.63698036, 0.64922926, 0.64938002, 0.62237591,\n",
       "        0.64956846, 0.63411601, 0.64655335, 0.63545396, 0.63522783,\n",
       "        0.6366977 , 0.63888365, 0.62192364, 0.64171032, 0.63202427,\n",
       "        0.62160329, 0.63392756, 0.61587457, 0.62205555, 0.63933592,\n",
       "        0.63115743, 0.62772774, 0.61681679, 0.62900916, 0.62431689,\n",
       "        0.63600045, 0.63854445, 0.63892134, 0.63053556, 0.63718765,\n",
       "        0.63304187, 0.61830551, 0.62009573, 0.61877662, 0.6339841 ,\n",
       "        0.63074285, 0.62763351, 0.63234463, 0.62456187, 0.62303547,\n",
       "        0.62169751, 0.61035315, 0.629028  , 0.64830588, 0.63257076,\n",
       "        0.63164738, 0.62908454, 0.62152791, 0.62622018, 0.63044134,\n",
       "        0.62103795, 0.61112577, 0.65051068, 0.63313609, 0.65659744,\n",
       "        0.63458712, 0.6508122 , 0.64615762, 0.62194249, 0.62825538,\n",
       "        0.61921004]),\n",
       " 'split1_test_score': array([0.67716133, 0.67695333, 0.67839044, 0.68124575, 0.68134029,\n",
       "        0.68438469, 0.6866349 , 0.68368505, 0.68446033, 0.67001361,\n",
       "        0.67805007, 0.68869601, 0.67854171, 0.679733  , 0.66791468,\n",
       "        0.67353075, 0.65732547, 0.66184479, 0.6683496 , 0.67154527,\n",
       "        0.66341427, 0.67995991, 0.66969216, 0.6626768 , 0.66460555,\n",
       "        0.67131836, 0.67228273, 0.66585357, 0.67005143, 0.67712352,\n",
       "        0.66948415, 0.67173436, 0.65859239, 0.6523145 , 0.66566447,\n",
       "        0.67027835, 0.66921942, 0.65912185, 0.65781711, 0.6602375 ,\n",
       "        0.65932985, 0.66619393, 0.65227668, 0.65707965, 0.65866803,\n",
       "        0.66640194, 0.66583466, 0.67211255, 0.66190152, 0.6775017 ,\n",
       "        0.65967022, 0.65866803, 0.64736026, 0.6703918 , 0.65950004,\n",
       "        0.65702292, 0.67067544, 0.66464337, 0.64684971, 0.65161486,\n",
       "        0.65448907, 0.65341124, 0.65811966, 0.66460555, 0.65891385,\n",
       "        0.64671734, 0.65645564, 0.66764995, 0.6478519 , 0.66944634,\n",
       "        0.6454126 , 0.64913774, 0.67008925, 0.64877846, 0.66719613,\n",
       "        0.67086453, 0.65006429, 0.65749565, 0.66229862, 0.65755238,\n",
       "        0.66383027]),\n",
       " 'split2_test_score': array([0.61975267, 0.6167839 , 0.61997958, 0.62317525, 0.62413963,\n",
       "        0.62187051, 0.61712427, 0.61381514, 0.61205658, 0.60063535,\n",
       "        0.6003328 , 0.59564329, 0.58703956, 0.60330157, 0.60222373,\n",
       "        0.59197489, 0.59902806, 0.60619469, 0.59394146, 0.59252326,\n",
       "        0.58581045, 0.58845776, 0.59152106, 0.58893049, 0.59893351,\n",
       "        0.60632706, 0.60473867, 0.58908176, 0.5901785 , 0.5909916 ,\n",
       "        0.60343393, 0.59486801, 0.59396037, 0.60218592, 0.61788064,\n",
       "        0.60146736, 0.58783375, 0.60333938, 0.59745859, 0.61084638,\n",
       "        0.5987066 , 0.60199682, 0.60574087, 0.6031692 , 0.60483322,\n",
       "        0.61113002, 0.60628924, 0.60080554, 0.60402012, 0.59825278,\n",
       "        0.59486801, 0.601543  , 0.60371757, 0.59235307, 0.61128129,\n",
       "        0.61572498, 0.62009303, 0.61814537, 0.59959534, 0.58840103,\n",
       "        0.62056577, 0.60443612, 0.60173209, 0.61147039, 0.61226458,\n",
       "        0.62118977, 0.6121133 , 0.61094093, 0.5871341 , 0.59639967,\n",
       "        0.60091899, 0.60523032, 0.61396642, 0.60891763, 0.60545723,\n",
       "        0.60207246, 0.61269949, 0.61031692, 0.61086529, 0.60940927,\n",
       "        0.60683761]),\n",
       " 'split3_test_score': array([0.65554799, 0.65452689, 0.65492398, 0.65482944, 0.65675819,\n",
       "        0.65507526, 0.66139097, 0.66277135, 0.66681794, 0.68111338,\n",
       "        0.67005143, 0.65846003, 0.66360336, 0.66649648, 0.68750473,\n",
       "        0.67629151, 0.67046744, 0.67780425, 0.66963543, 0.67146963,\n",
       "        0.67441948, 0.67716133, 0.67179109, 0.66995689, 0.68340141,\n",
       "        0.65999168, 0.67076999, 0.68043265, 0.67740716, 0.68241812,\n",
       "        0.67048635, 0.67290674, 0.67757734, 0.66401936, 0.6736442 ,\n",
       "        0.66931397, 0.65823311, 0.67298238, 0.67228273, 0.65728765,\n",
       "        0.66880342, 0.67536495, 0.65664473, 0.66076696, 0.66080478,\n",
       "        0.67353075, 0.68697527, 0.66872778, 0.65961349, 0.67687769,\n",
       "        0.67014598, 0.68209666, 0.66097496, 0.66014295, 0.6742493 ,\n",
       "        0.6742493 , 0.6691627 , 0.66080478, 0.67493004, 0.67148854,\n",
       "        0.67657515, 0.65785493, 0.65013993, 0.67719915, 0.67532713,\n",
       "        0.66366009, 0.6622608 , 0.67846608, 0.67001361, 0.66313063,\n",
       "        0.65849784, 0.65460253, 0.65776038, 0.671602  , 0.66120188,\n",
       "        0.67944936, 0.66591029, 0.67691551, 0.66884124, 0.66965434,\n",
       "        0.64524242]),\n",
       " 'split4_test_score': array([0.64981847, 0.65263596, 0.65706074, 0.6571931 , 0.65405416,\n",
       "        0.6545458 , 0.65197413, 0.65346797, 0.65499962, 0.63556085,\n",
       "        0.63747069, 0.640534  , 0.63605249, 0.63028515, 0.62777021,\n",
       "        0.65108539, 0.63883216, 0.64125255, 0.62807276, 0.63083352,\n",
       "        0.63051206, 0.62353453, 0.62990697, 0.63784888, 0.64295439,\n",
       "        0.62168142, 0.63743287, 0.63104152, 0.63531503, 0.62325089,\n",
       "        0.63486121, 0.63028515, 0.62175705, 0.63355646, 0.61665154,\n",
       "        0.6291695 , 0.62716512, 0.62620074, 0.64717117, 0.63858634,\n",
       "        0.63278118, 0.63629831, 0.63826488, 0.62650329, 0.6338401 ,\n",
       "        0.64242493, 0.6273353 , 0.61754028, 0.63089025, 0.62913168,\n",
       "        0.61742682, 0.64026927, 0.63461538, 0.61665154, 0.63970199,\n",
       "        0.6452046 , 0.61841011, 0.62584146, 0.62724075, 0.63370774,\n",
       "        0.6332161 , 0.62086832, 0.63036079, 0.63593904, 0.62966115,\n",
       "        0.63431284, 0.63858634, 0.62258906, 0.63143862, 0.61436351,\n",
       "        0.62500945, 0.64874064, 0.63557976, 0.63340519, 0.60878527,\n",
       "        0.63183572, 0.64346494, 0.62296725, 0.62030104, 0.6411391 ,\n",
       "        0.63013388]),\n",
       " 'mean_test_score': array([0.64761096, 0.64852585, 0.65090297, 0.65208304, 0.65230153,\n",
       "        0.65127234, 0.65118274, 0.6506377 , 0.65177529, 0.64997133,\n",
       "        0.64793516, 0.64766203, 0.64474757, 0.64616714, 0.64593731,\n",
       "        0.64717486, 0.64232823, 0.64360928, 0.64239219, 0.64058749,\n",
       "        0.63701374, 0.64121878, 0.64242811, 0.64175861, 0.64245415,\n",
       "        0.64177739, 0.64386805, 0.64259257, 0.64168122, 0.64180239,\n",
       "        0.64299267, 0.64173558, 0.63476216, 0.63875731, 0.64117303,\n",
       "        0.63836649, 0.63527579, 0.63550378, 0.63935703, 0.64125876,\n",
       "        0.6381557 , 0.64151635, 0.63394879, 0.63530565, 0.6364926 ,\n",
       "        0.64589762, 0.64499578, 0.6396215 , 0.63739219, 0.6437903 ,\n",
       "        0.63503058, 0.64017649, 0.63335278, 0.6316632 , 0.64374334,\n",
       "        0.64458893, 0.64119496, 0.64035592, 0.63463554, 0.63364953,\n",
       "        0.64130872, 0.62938475, 0.63387609, 0.647504  , 0.64174749,\n",
       "        0.63950548, 0.63970012, 0.64023479, 0.63253168, 0.6347563 ,\n",
       "        0.63017537, 0.6337674 , 0.6455813 , 0.63916787, 0.63984759,\n",
       "        0.64376184, 0.64459024, 0.64277059, 0.63684973, 0.64120209,\n",
       "        0.63305084]),\n",
       " 'std_test_score': array([0.01927322, 0.01956923, 0.0190335 , 0.01889748, 0.01849048,\n",
       "        0.02050576, 0.0231312 , 0.02336001, 0.02453061, 0.02888262,\n",
       "        0.02758834, 0.03036659, 0.03191411, 0.02703031, 0.0298481 ,\n",
       "        0.03040473, 0.02415472, 0.02476889, 0.02849588, 0.02944002,\n",
       "        0.03097564, 0.03437198, 0.02966505, 0.0286248 , 0.02988242,\n",
       "        0.02418968, 0.0252932 , 0.03157678, 0.03102595, 0.034253  ,\n",
       "        0.02501337, 0.02900822, 0.02966401, 0.0209533 , 0.02400728,\n",
       "        0.02721488, 0.02827563, 0.02633955, 0.02661112, 0.01762311,\n",
       "        0.02458341, 0.02658517, 0.01979312, 0.0213179 , 0.02116805,\n",
       "        0.02237327, 0.02845433, 0.02791986, 0.02143585, 0.03021049,\n",
       "        0.02744843, 0.02853115, 0.02007378, 0.02914687, 0.02165293,\n",
       "        0.02029563, 0.02366283, 0.01884778, 0.02512692, 0.02798082,\n",
       "        0.02143736, 0.02211329, 0.01960286, 0.02283453, 0.02245801,\n",
       "        0.01455771, 0.01824662, 0.02732278, 0.02735534, 0.02797934,\n",
       "        0.02000225, 0.02107869, 0.01935355, 0.02063494, 0.02695207,\n",
       "        0.02818712, 0.01755852, 0.02383102, 0.02384273, 0.02123802,\n",
       "        0.01991591]),\n",
       " 'rank_test_score': array([12,  9,  6,  2,  1,  4,  5,  7,  3,  8, 10, 11, 20, 15, 16, 14, 34,\n",
       "        27, 33, 48, 62, 44, 32, 37, 31, 36, 23, 30, 40, 35, 28, 39, 69, 58,\n",
       "        47, 59, 67, 65, 56, 43, 60, 41, 72, 66, 64, 17, 19, 54, 61, 24, 68,\n",
       "        51, 76, 79, 26, 22, 46, 49, 71, 75, 42, 81, 73, 13, 38, 55, 53, 50,\n",
       "        78, 70, 80, 74, 18, 57, 52, 25, 21, 29, 63, 45, 77])}"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch1.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:30:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'mean_fit_time': array([0.89201393, 0.74221487, 0.69693513, 0.72027426, 0.74141722,\n",
       "         0.92233262, 0.77492771, 0.69833331, 0.6879601 , 0.71189609,\n",
       "         1.35118623, 1.24447169, 1.18184018, 1.17286286, 1.39826112,\n",
       "         1.15451264, 1.14792924, 1.26860743, 1.24925957, 1.12479248,\n",
       "         1.83369617, 1.93821673, 1.73196831, 1.94599628, 1.67073207,\n",
       "         1.77465301, 1.79081187, 1.62266059, 1.85663395, 1.62246122,\n",
       "         2.78096437, 2.40576692, 2.5633461 , 2.34552879, 2.48236265,\n",
       "         2.39000907, 2.26933198, 2.37604704, 2.27272348, 2.23821402,\n",
       "         3.45376539, 3.29479003, 3.66659608, 3.25748982, 2.85815773,\n",
       "         2.93674812, 2.87052426, 2.71015348, 2.83023109, 2.63974142,\n",
       "         4.1485075 , 4.25502334, 4.35096598, 4.8939146 , 5.49470935,\n",
       "         5.47296724, 4.10761771, 3.69811029, 3.7322228 , 3.34006944,\n",
       "         5.20608001, 4.46326618, 4.56100502, 4.4048234 , 4.32802811,\n",
       "         3.8804244 , 3.70329843, 3.72065229, 3.73002448, 3.51061435,\n",
       "         5.8553431 , 5.0915854 , 4.71978059, 4.62044573, 4.22151184,\n",
       "         4.15987763, 4.11001153, 3.97317681, 3.78986754, 3.79505286,\n",
       "         6.27143292, 5.42349901, 4.92842255, 4.77882271, 4.67888923,\n",
       "         4.3427886 , 4.16626019, 4.26719027, 4.39305434, 4.22490249,\n",
       "         6.99749007, 6.06897359, 5.74583716, 5.77216682, 5.05189271,\n",
       "         5.08939242, 4.69105892, 4.70541911, 4.21333313, 3.59917598]),\n",
       "  'std_fit_time': array([0.06227291, 0.02672711, 0.00502332, 0.01098697, 0.09910789,\n",
       "         0.07584292, 0.02004672, 0.03096186, 0.00989912, 0.02858283,\n",
       "         0.17663998, 0.12046081, 0.00874027, 0.00887624, 0.12273011,\n",
       "         0.00606986, 0.00640073, 0.13196222, 0.14018795, 0.00609622,\n",
       "         0.12672243, 0.14324845, 0.0138571 , 0.11245255, 0.00881712,\n",
       "         0.14582952, 0.15581385, 0.00979231, 0.11914864, 0.03189823,\n",
       "         0.11561433, 0.04495515, 0.1131709 , 0.04169505, 0.05981658,\n",
       "         0.09297302, 0.14537719, 0.18654937, 0.14737849, 0.13623501,\n",
       "         0.14940568, 0.17393269, 0.4174575 , 0.19232712, 0.11209011,\n",
       "         0.16209385, 0.13244458, 0.13563287, 0.12677068, 0.10340478,\n",
       "         0.16137483, 0.32131887, 0.44413039, 0.24355171, 0.26671654,\n",
       "         0.38880797, 0.32072364, 0.37858547, 0.10316933, 0.31946875,\n",
       "         0.21271483, 0.0751604 , 0.30426503, 0.07667045, 0.25842174,\n",
       "         0.07572211, 0.14413243, 0.1776877 , 0.1574109 , 0.21494129,\n",
       "         0.15623736, 0.07091446, 0.04886151, 0.04248876, 0.15837752,\n",
       "         0.14287241, 0.08244767, 0.10550518, 0.15982214, 0.20727513,\n",
       "         0.21465416, 0.0579313 , 0.18446272, 0.04296888, 0.06284484,\n",
       "         0.13511517, 0.12825622, 0.19724262, 0.09295345, 0.37284027,\n",
       "         0.14327499, 0.08971444, 0.06797793, 0.24578756, 0.32746824,\n",
       "         0.14843455, 0.06628075, 0.17862393, 0.11480464, 0.59643224]),\n",
       "  'mean_score_time': array([0.01037483, 0.00857844, 0.00897727, 0.00917606, 0.00917554,\n",
       "         0.01156931, 0.00917635, 0.00877719, 0.00797868, 0.00817909,\n",
       "         0.00777993, 0.00817828, 0.00897608, 0.00897694, 0.00797925,\n",
       "         0.008179  , 0.00837831, 0.00857759, 0.00797982, 0.00817909,\n",
       "         0.00837827, 0.0087769 , 0.00897694, 0.00837841, 0.00957494,\n",
       "         0.00857792, 0.00857677, 0.0091763 , 0.00857735, 0.00857768,\n",
       "         0.01037278, 0.00797987, 0.00837789, 0.01057186, 0.00797958,\n",
       "         0.0085773 , 0.00857754, 0.00817881, 0.00917535, 0.00977454,\n",
       "         0.00877743, 0.00758095, 0.01037288, 0.00897646, 0.00897722,\n",
       "         0.00937548, 0.00917616, 0.00797939, 0.00857902, 0.00837874,\n",
       "         0.00857759, 0.00937552, 0.00857749, 0.01117234, 0.00957503,\n",
       "         0.01057277, 0.0101728 , 0.01037288, 0.00997229, 0.00797944,\n",
       "         0.00937548, 0.00877814, 0.00977397, 0.00917554, 0.00877728,\n",
       "         0.00777993, 0.00817895, 0.00937524, 0.0091763 , 0.00897593,\n",
       "         0.01097083, 0.00837822, 0.00917602, 0.00937572, 0.00957456,\n",
       "         0.00897632, 0.00897589, 0.0091773 , 0.00957441, 0.00857763,\n",
       "         0.01057134, 0.00917602, 0.00837846, 0.01037335, 0.0107718 ,\n",
       "         0.00957537, 0.00997386, 0.00897689, 0.01017466, 0.01097164,\n",
       "         0.00957537, 0.00877686, 0.01058431, 0.00877724, 0.00977392,\n",
       "         0.00917597, 0.01156816, 0.00837774, 0.00917621, 0.00857701]),\n",
       "  'std_score_time': array([2.86350150e-03, 1.01638217e-03, 2.35989304e-03, 9.77174809e-04,\n",
       "         9.77330690e-04, 2.93147890e-03, 1.93375266e-03, 1.16283479e-03,\n",
       "         1.09205808e-03, 7.46315058e-04, 1.59592639e-03, 7.46212833e-04,\n",
       "         1.41043609e-03, 8.91963538e-04, 1.09305872e-03, 9.77028869e-04,\n",
       "         1.01705583e-03, 1.35268367e-03, 1.26172824e-03, 3.98922024e-04,\n",
       "         1.19650390e-03, 1.16307196e-03, 8.92229896e-04, 1.01636373e-03,\n",
       "         7.97891624e-04, 4.88791967e-04, 2.32620962e-03, 1.93402800e-03,\n",
       "         7.98345016e-04, 1.73892073e-03, 1.95436414e-03, 1.09301536e-03,\n",
       "         7.97939671e-04, 2.86274728e-03, 6.30751307e-04, 1.01719591e-03,\n",
       "         1.19628909e-03, 7.46646121e-04, 7.46086523e-04, 3.17881023e-03,\n",
       "         1.16267135e-03, 7.97665940e-04, 2.05360911e-03, 8.91963449e-04,\n",
       "         6.30299192e-04, 1.01767286e-03, 7.46505934e-04, 1.54507988e-03,\n",
       "         1.19578860e-03, 1.01665340e-03, 1.49296070e-03, 1.84971998e-03,\n",
       "         4.88733421e-04, 2.12882151e-03, 4.89124268e-04, 1.35306343e-03,\n",
       "         1.71413223e-03, 2.40976870e-03, 1.89130322e-03, 1.05982355e-06,\n",
       "         1.01720529e-03, 9.77827911e-04, 1.71590053e-03, 1.16270421e-03,\n",
       "         1.16383254e-03, 7.46697143e-04, 3.98993531e-04, 1.35288801e-03,\n",
       "         1.16306386e-03, 1.09227583e-03, 2.18446329e-03, 1.01713967e-03,\n",
       "         3.98636634e-04, 7.97140924e-04, 1.01689676e-03, 1.09157873e-03,\n",
       "         1.41053713e-03, 1.59715500e-03, 1.19590836e-03, 1.19711565e-03,\n",
       "         1.95426684e-03, 9.77428014e-04, 7.97772513e-04, 2.49142735e-03,\n",
       "         1.16336634e-03, 4.88910698e-04, 6.30675876e-04, 1.09253644e-03,\n",
       "         1.93605933e-03, 2.09226005e-03, 1.35285961e-03, 3.98492884e-04,\n",
       "         1.83927381e-03, 1.46609030e-03, 1.32395222e-03, 1.46579141e-03,\n",
       "         2.14572048e-03, 1.01723314e-03, 9.77388878e-04, 1.01787863e-03]),\n",
       "  'param_max_depth': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                     2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4,\n",
       "                     4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6,\n",
       "                     6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8,\n",
       "                     8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                     10, 10, 10, 10, 10, 10, 10, 10, 10, 10],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_min_child_weight': masked_array(data=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8,\n",
       "                     9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6,\n",
       "                     7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4,\n",
       "                     5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2,\n",
       "                     3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10,\n",
       "                     1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'max_depth': 1, 'min_child_weight': 1},\n",
       "   {'max_depth': 1, 'min_child_weight': 2},\n",
       "   {'max_depth': 1, 'min_child_weight': 3},\n",
       "   {'max_depth': 1, 'min_child_weight': 4},\n",
       "   {'max_depth': 1, 'min_child_weight': 5},\n",
       "   {'max_depth': 1, 'min_child_weight': 6},\n",
       "   {'max_depth': 1, 'min_child_weight': 7},\n",
       "   {'max_depth': 1, 'min_child_weight': 8},\n",
       "   {'max_depth': 1, 'min_child_weight': 9},\n",
       "   {'max_depth': 1, 'min_child_weight': 10},\n",
       "   {'max_depth': 2, 'min_child_weight': 1},\n",
       "   {'max_depth': 2, 'min_child_weight': 2},\n",
       "   {'max_depth': 2, 'min_child_weight': 3},\n",
       "   {'max_depth': 2, 'min_child_weight': 4},\n",
       "   {'max_depth': 2, 'min_child_weight': 5},\n",
       "   {'max_depth': 2, 'min_child_weight': 6},\n",
       "   {'max_depth': 2, 'min_child_weight': 7},\n",
       "   {'max_depth': 2, 'min_child_weight': 8},\n",
       "   {'max_depth': 2, 'min_child_weight': 9},\n",
       "   {'max_depth': 2, 'min_child_weight': 10},\n",
       "   {'max_depth': 3, 'min_child_weight': 1},\n",
       "   {'max_depth': 3, 'min_child_weight': 2},\n",
       "   {'max_depth': 3, 'min_child_weight': 3},\n",
       "   {'max_depth': 3, 'min_child_weight': 4},\n",
       "   {'max_depth': 3, 'min_child_weight': 5},\n",
       "   {'max_depth': 3, 'min_child_weight': 6},\n",
       "   {'max_depth': 3, 'min_child_weight': 7},\n",
       "   {'max_depth': 3, 'min_child_weight': 8},\n",
       "   {'max_depth': 3, 'min_child_weight': 9},\n",
       "   {'max_depth': 3, 'min_child_weight': 10},\n",
       "   {'max_depth': 4, 'min_child_weight': 1},\n",
       "   {'max_depth': 4, 'min_child_weight': 2},\n",
       "   {'max_depth': 4, 'min_child_weight': 3},\n",
       "   {'max_depth': 4, 'min_child_weight': 4},\n",
       "   {'max_depth': 4, 'min_child_weight': 5},\n",
       "   {'max_depth': 4, 'min_child_weight': 6},\n",
       "   {'max_depth': 4, 'min_child_weight': 7},\n",
       "   {'max_depth': 4, 'min_child_weight': 8},\n",
       "   {'max_depth': 4, 'min_child_weight': 9},\n",
       "   {'max_depth': 4, 'min_child_weight': 10},\n",
       "   {'max_depth': 5, 'min_child_weight': 1},\n",
       "   {'max_depth': 5, 'min_child_weight': 2},\n",
       "   {'max_depth': 5, 'min_child_weight': 3},\n",
       "   {'max_depth': 5, 'min_child_weight': 4},\n",
       "   {'max_depth': 5, 'min_child_weight': 5},\n",
       "   {'max_depth': 5, 'min_child_weight': 6},\n",
       "   {'max_depth': 5, 'min_child_weight': 7},\n",
       "   {'max_depth': 5, 'min_child_weight': 8},\n",
       "   {'max_depth': 5, 'min_child_weight': 9},\n",
       "   {'max_depth': 5, 'min_child_weight': 10},\n",
       "   {'max_depth': 6, 'min_child_weight': 1},\n",
       "   {'max_depth': 6, 'min_child_weight': 2},\n",
       "   {'max_depth': 6, 'min_child_weight': 3},\n",
       "   {'max_depth': 6, 'min_child_weight': 4},\n",
       "   {'max_depth': 6, 'min_child_weight': 5},\n",
       "   {'max_depth': 6, 'min_child_weight': 6},\n",
       "   {'max_depth': 6, 'min_child_weight': 7},\n",
       "   {'max_depth': 6, 'min_child_weight': 8},\n",
       "   {'max_depth': 6, 'min_child_weight': 9},\n",
       "   {'max_depth': 6, 'min_child_weight': 10},\n",
       "   {'max_depth': 7, 'min_child_weight': 1},\n",
       "   {'max_depth': 7, 'min_child_weight': 2},\n",
       "   {'max_depth': 7, 'min_child_weight': 3},\n",
       "   {'max_depth': 7, 'min_child_weight': 4},\n",
       "   {'max_depth': 7, 'min_child_weight': 5},\n",
       "   {'max_depth': 7, 'min_child_weight': 6},\n",
       "   {'max_depth': 7, 'min_child_weight': 7},\n",
       "   {'max_depth': 7, 'min_child_weight': 8},\n",
       "   {'max_depth': 7, 'min_child_weight': 9},\n",
       "   {'max_depth': 7, 'min_child_weight': 10},\n",
       "   {'max_depth': 8, 'min_child_weight': 1},\n",
       "   {'max_depth': 8, 'min_child_weight': 2},\n",
       "   {'max_depth': 8, 'min_child_weight': 3},\n",
       "   {'max_depth': 8, 'min_child_weight': 4},\n",
       "   {'max_depth': 8, 'min_child_weight': 5},\n",
       "   {'max_depth': 8, 'min_child_weight': 6},\n",
       "   {'max_depth': 8, 'min_child_weight': 7},\n",
       "   {'max_depth': 8, 'min_child_weight': 8},\n",
       "   {'max_depth': 8, 'min_child_weight': 9},\n",
       "   {'max_depth': 8, 'min_child_weight': 10},\n",
       "   {'max_depth': 9, 'min_child_weight': 1},\n",
       "   {'max_depth': 9, 'min_child_weight': 2},\n",
       "   {'max_depth': 9, 'min_child_weight': 3},\n",
       "   {'max_depth': 9, 'min_child_weight': 4},\n",
       "   {'max_depth': 9, 'min_child_weight': 5},\n",
       "   {'max_depth': 9, 'min_child_weight': 6},\n",
       "   {'max_depth': 9, 'min_child_weight': 7},\n",
       "   {'max_depth': 9, 'min_child_weight': 8},\n",
       "   {'max_depth': 9, 'min_child_weight': 9},\n",
       "   {'max_depth': 9, 'min_child_weight': 10},\n",
       "   {'max_depth': 10, 'min_child_weight': 1},\n",
       "   {'max_depth': 10, 'min_child_weight': 2},\n",
       "   {'max_depth': 10, 'min_child_weight': 3},\n",
       "   {'max_depth': 10, 'min_child_weight': 4},\n",
       "   {'max_depth': 10, 'min_child_weight': 5},\n",
       "   {'max_depth': 10, 'min_child_weight': 6},\n",
       "   {'max_depth': 10, 'min_child_weight': 7},\n",
       "   {'max_depth': 10, 'min_child_weight': 8},\n",
       "   {'max_depth': 10, 'min_child_weight': 9},\n",
       "   {'max_depth': 10, 'min_child_weight': 10}],\n",
       "  'split0_test_score': array([0.64583726, 0.64583726, 0.65395922, 0.65254589, 0.64975691,\n",
       "         0.64913504, 0.65034108, 0.64868277, 0.64404704, 0.64299175,\n",
       "         0.67879622, 0.67376475, 0.66309878, 0.65876456, 0.66309878,\n",
       "         0.66771567, 0.67385897, 0.68356386, 0.66852599, 0.67059888,\n",
       "         0.66287265, 0.66534127, 0.65981985, 0.65552331, 0.6679795 ,\n",
       "         0.6684883 , 0.66532243, 0.66545434, 0.67672333, 0.67359515,\n",
       "         0.6620058 , 0.66754607, 0.66946821, 0.6599706 , 0.66138394,\n",
       "         0.6473825 , 0.66487016, 0.66443674, 0.66995817, 0.65458109,\n",
       "         0.6565786 , 0.65111371, 0.65597558, 0.65096295, 0.6674707 ,\n",
       "         0.64067388, 0.66641541, 0.6676403 , 0.64845664, 0.64625184,\n",
       "         0.6236008 , 0.64044774, 0.64357592, 0.65181095, 0.62593751,\n",
       "         0.65329966, 0.62689858, 0.6291976 , 0.64858855, 0.63074285,\n",
       "         0.64749557, 0.6620058 , 0.64885237, 0.62855689, 0.64843779,\n",
       "         0.65299815, 0.63600045, 0.65637131, 0.62718125, 0.63375796,\n",
       "         0.65109486, 0.64137112, 0.62795387, 0.64662873, 0.64159726,\n",
       "         0.61928542, 0.64578073, 0.62069875, 0.61495119, 0.63247654,\n",
       "         0.65373309, 0.63479441, 0.63061094, 0.63982588, 0.64106961,\n",
       "         0.63848792, 0.60790337, 0.62132062, 0.63268383, 0.63343761,\n",
       "         0.64823051, 0.65818038, 0.64412241, 0.62827422, 0.62505182,\n",
       "         0.62895263, 0.6242792 , 0.62211209, 0.64562997, 0.6378849 ]),\n",
       "  'split1_test_score': array([0.67181   , 0.67181   , 0.66819832, 0.66965434, 0.66602375,\n",
       "         0.67373875, 0.67510022, 0.67158309, 0.66955979, 0.67116708,\n",
       "         0.67975191, 0.66923833, 0.67326602, 0.67839044, 0.68130247,\n",
       "         0.67816353, 0.6707889 , 0.68472506, 0.67965736, 0.68432796,\n",
       "         0.68321231, 0.66768777, 0.67629151, 0.67748279, 0.67559186,\n",
       "         0.68185084, 0.6701838 , 0.68646472, 0.69308297, 0.68795855,\n",
       "         0.67604568, 0.66874669, 0.69338552, 0.65764693, 0.70584676,\n",
       "         0.69073822, 0.67769079, 0.69750775, 0.69168369, 0.67634823,\n",
       "         0.66466228, 0.68924438, 0.6809432 , 0.6976023 , 0.68101883,\n",
       "         0.67649951, 0.6766886 , 0.66313063, 0.68960366, 0.68918766,\n",
       "         0.66950306, 0.6758755 , 0.68722109, 0.67829589, 0.68328795,\n",
       "         0.67150745, 0.6801301 , 0.67909008, 0.6772937 , 0.67581877,\n",
       "         0.67863626, 0.68688072, 0.65350579, 0.67392784, 0.68576507,\n",
       "         0.67298238, 0.66545647, 0.67818244, 0.68024355, 0.67345511,\n",
       "         0.67190455, 0.67859844, 0.6805461 , 0.65407307, 0.67525149,\n",
       "         0.67888208, 0.69718629, 0.69030331, 0.67995991, 0.68773164,\n",
       "         0.67232055, 0.67714242, 0.65672037, 0.67517586, 0.68130247,\n",
       "         0.66131533, 0.67493004, 0.68313668, 0.6815672 , 0.68315559,\n",
       "         0.68716436, 0.65757129, 0.67145072, 0.66371681, 0.68096211,\n",
       "         0.66076696, 0.66038878, 0.67644278, 0.66719613, 0.67320929]),\n",
       "  'split2_test_score': array([0.63771651, 0.64047727, 0.63864307, 0.6423682 , 0.63803797,\n",
       "         0.64057182, 0.64057182, 0.64490205, 0.64316239, 0.63480448,\n",
       "         0.64030709, 0.6307957 , 0.63987217, 0.64011799, 0.64270857,\n",
       "         0.6500832 , 0.63168444, 0.64244384, 0.6320059 , 0.63561758,\n",
       "         0.63372665, 0.62877241, 0.64858937, 0.65082066, 0.65053702,\n",
       "         0.64981847, 0.63610922, 0.63077679, 0.63404811, 0.63512594,\n",
       "         0.6151577 , 0.64458059, 0.63580667, 0.63329173, 0.63174117,\n",
       "         0.62398835, 0.63480448, 0.63818924, 0.6125104 , 0.63488011,\n",
       "         0.62534982, 0.62790258, 0.60751834, 0.61827774, 0.61504425,\n",
       "         0.62690039, 0.62939641, 0.62330762, 0.62926405, 0.62130323,\n",
       "         0.63115498, 0.62141669, 0.63041752, 0.62262688, 0.61750246,\n",
       "         0.63297027, 0.61578171, 0.62478254, 0.61693518, 0.5999168 ,\n",
       "         0.62735421, 0.62640874, 0.62007412, 0.62361017, 0.6137206 ,\n",
       "         0.61324786, 0.61313441, 0.59751532, 0.60906891, 0.62088722,\n",
       "         0.60818017, 0.6295666 , 0.624688  , 0.61256713, 0.60961728,\n",
       "         0.63032297, 0.59316618, 0.61258604, 0.60808562, 0.59053778,\n",
       "         0.6062136 , 0.61999849, 0.61833447, 0.64038272, 0.62402617,\n",
       "         0.61466606, 0.616973  , 0.61980939, 0.60978746, 0.62372362,\n",
       "         0.58980032, 0.60816126, 0.59938734, 0.62466909, 0.62822404,\n",
       "         0.61580062, 0.6141366 , 0.60604342, 0.60265865, 0.61827774]),\n",
       "  'split3_test_score': array([0.65781711, 0.65781711, 0.65885712, 0.65653128, 0.65594509,\n",
       "         0.65622873, 0.65700401, 0.65832766, 0.65844112, 0.65787384,\n",
       "         0.69259133, 0.68130247, 0.68655926, 0.68909311, 0.6907004 ,\n",
       "         0.68272067, 0.68404432, 0.69480372, 0.69087058, 0.68404432,\n",
       "         0.67118599, 0.67354966, 0.67857953, 0.68168066, 0.68118902,\n",
       "         0.68234249, 0.6894713 , 0.69423644, 0.68455487, 0.68166175,\n",
       "         0.67103472, 0.66445428, 0.65027229, 0.65953786, 0.66689358,\n",
       "         0.67595114, 0.67256637, 0.68099992, 0.67922245, 0.67606459,\n",
       "         0.66411391, 0.64272748, 0.67328493, 0.66076696, 0.66116406,\n",
       "         0.67825807, 0.65813857, 0.65562363, 0.67203691, 0.68669163,\n",
       "         0.68026246, 0.66577793, 0.65465925, 0.66596702, 0.66628848,\n",
       "         0.65592618, 0.67897663, 0.67670751, 0.66405718, 0.66464337,\n",
       "         0.63461538, 0.65511308, 0.66589138, 0.6661183 , 0.65864912,\n",
       "         0.67188564, 0.66001059, 0.66827396, 0.67718024, 0.66681794,\n",
       "         0.63877543, 0.65520762, 0.66556993, 0.64475078, 0.66797141,\n",
       "         0.6610506 , 0.64870282, 0.66645866, 0.66498374, 0.6707889 ,\n",
       "         0.67131836, 0.64289766, 0.65607745, 0.65324106, 0.66895469,\n",
       "         0.65967022, 0.6667423 , 0.66089933, 0.68028137, 0.67753952,\n",
       "         0.67092126, 0.64607443, 0.65639891, 0.66205279, 0.64964829,\n",
       "         0.66301717, 0.66609939, 0.69257242, 0.67406021, 0.66538083]),\n",
       "  'split4_test_score': array([0.62909387, 0.63051206, 0.63153317, 0.63232736, 0.6314008 ,\n",
       "         0.63128735, 0.63168444, 0.63334846, 0.63312155, 0.63811361,\n",
       "         0.65539672, 0.64384313, 0.64374858, 0.64843809, 0.63794342,\n",
       "         0.6378867 , 0.64200893, 0.64560169, 0.6539407 , 0.64571515,\n",
       "         0.6338401 , 0.63359428, 0.62678693, 0.63351864, 0.64771954,\n",
       "         0.63539067, 0.64832464, 0.63397247, 0.65203086, 0.63488011,\n",
       "         0.65108539, 0.61789955, 0.63257318, 0.63395356, 0.65783602,\n",
       "         0.6380947 , 0.62444218, 0.64087437, 0.64312457, 0.64493987,\n",
       "         0.61791846, 0.61994176, 0.62118977, 0.6261251 , 0.63091861,\n",
       "         0.6452046 , 0.63966417, 0.63196808, 0.63860525, 0.63060661,\n",
       "         0.62349671, 0.61294531, 0.6224567 , 0.61203767, 0.62058468,\n",
       "         0.63782997, 0.62362907, 0.64238711, 0.64964829, 0.64768172,\n",
       "         0.63145753, 0.61890175, 0.62928296, 0.62778912, 0.62620074,\n",
       "         0.63537176, 0.6427653 , 0.6531276 , 0.6533356 , 0.64872173,\n",
       "         0.62147341, 0.6110922 , 0.6425573 , 0.63149535, 0.61423115,\n",
       "         0.61589517, 0.62319416, 0.63368883, 0.64582861, 0.61322895,\n",
       "         0.63584449, 0.62370471, 0.64320021, 0.60736707, 0.61997958,\n",
       "         0.62391271, 0.64461841, 0.63412374, 0.61687845, 0.64679298,\n",
       "         0.62845095, 0.62404508, 0.64106346, 0.65142576, 0.62986915,\n",
       "         0.63223281, 0.63317828, 0.63155208, 0.60099463, 0.62485818]),\n",
       "  'mean_test_score': array([0.64845495, 0.64929074, 0.65023818, 0.65068541, 0.6482329 ,\n",
       "         0.65019234, 0.65094031, 0.65136881, 0.64966638, 0.64899015,\n",
       "         0.66936865, 0.65978888, 0.66130896, 0.66296084, 0.66315073,\n",
       "         0.66331395, 0.66047711, 0.67022764, 0.66500011, 0.66406078,\n",
       "         0.65696754, 0.65378908, 0.65801344, 0.65980521, 0.66460339,\n",
       "         0.66357815, 0.66188228, 0.66218095, 0.66808803, 0.6626443 ,\n",
       "         0.65506586, 0.65264544, 0.65630118, 0.64888014, 0.66474029,\n",
       "         0.65523098, 0.6548748 , 0.66440161, 0.65929985, 0.65736278,\n",
       "         0.64572461, 0.64618598, 0.64778236, 0.65074701, 0.65112329,\n",
       "         0.65350729, 0.65406063, 0.64833405, 0.6555933 , 0.65480819,\n",
       "         0.6456036 , 0.64329263, 0.6476661 , 0.64614768, 0.64272022,\n",
       "         0.65030671, 0.64508322, 0.65043297, 0.65130458, 0.6437607 ,\n",
       "         0.64391179, 0.64986202, 0.64352133, 0.64400046, 0.64655466,\n",
       "         0.64929716, 0.64347344, 0.65069412, 0.64940191, 0.64872799,\n",
       "         0.63828568, 0.6431672 , 0.64826304, 0.63790301, 0.64173372,\n",
       "         0.64108725, 0.64160604, 0.64474712, 0.64276181, 0.63895276,\n",
       "         0.64788602, 0.63970754, 0.64098869, 0.64319852, 0.64706651,\n",
       "         0.63961045, 0.64223342, 0.64385795, 0.64423966, 0.65292986,\n",
       "         0.64491348, 0.63880649, 0.64248457, 0.64602774, 0.64275108,\n",
       "         0.64015404, 0.63961645, 0.64574456, 0.63810792, 0.64392219]),\n",
       "  'std_test_score': array([0.01503414, 0.01429726, 0.01337926, 0.01267793, 0.01237393,\n",
       "         0.01443567, 0.01482648, 0.01289038, 0.01280901, 0.01361065,\n",
       "         0.01884555, 0.01919543, 0.01761621, 0.01828268, 0.02069668,\n",
       "         0.01695939, 0.02005449, 0.02177333, 0.02053035, 0.01999212,\n",
       "         0.0200042 , 0.01871241, 0.01910091, 0.01778242, 0.01334282,\n",
       "         0.01840633, 0.01838458, 0.02611479, 0.02184958, 0.02302393,\n",
       "         0.0216879 , 0.01945788, 0.02266279, 0.01248393, 0.02384221,\n",
       "         0.02458228, 0.02127172, 0.02285669, 0.02832001, 0.01659965,\n",
       "         0.02001462, 0.0241384 , 0.02879412, 0.02812954, 0.02437919,\n",
       "         0.02040981, 0.01730247, 0.01754409, 0.02218041, 0.02821351,\n",
       "         0.02430647, 0.02439197, 0.02264181, 0.02519963, 0.02686552,\n",
       "         0.01375666, 0.02837811, 0.02317414, 0.02014666, 0.02672427,\n",
       "         0.01862427, 0.02471447, 0.01661945, 0.02145657, 0.0252176 ,\n",
       "         0.02270857, 0.01862007, 0.02803853, 0.02778066, 0.01968698,\n",
       "         0.02228693, 0.02287948, 0.02164498, 0.0146114 , 0.02683182,\n",
       "         0.02470957, 0.03418296, 0.0292633 , 0.02779492, 0.03589035,\n",
       "         0.0247463 , 0.02039717, 0.01483886, 0.02202997, 0.02429698,\n",
       "         0.01867296, 0.02642758, 0.02455299, 0.03085929, 0.02362136,\n",
       "         0.034003  , 0.01968409, 0.02406126, 0.0165543 , 0.02096615,\n",
       "         0.01859528, 0.02029157, 0.03307969, 0.03107835, 0.02179785]),\n",
       "  'rank_test_score': array([ 54,  50,  44,  41,  57,  45,  38,  35,  47,  51,   2,  19,  16,\n",
       "          12,  11,  10,  17,   1,   4,   8,  23,  31,  21,  18,   6,   9,\n",
       "          15,  14,   3,  13,  27,  34,  24,  52,   5,  26,  28,   7,  20,\n",
       "          22,  67,  63,  59,  39,  37,  32,  30,  55,  25,  29,  68,  80,\n",
       "          60,  64,  85,  43,  69,  42,  36,  77,  75,  46,  78,  73,  62,\n",
       "          49,  79,  40,  48,  53,  98,  82,  56, 100,  88,  90,  89,  71,\n",
       "          83,  96,  58,  93,  91,  81,  61,  95,  87,  76,  72,  33,  70,\n",
       "          97,  86,  65,  84,  92,  94,  66,  99,  74])},\n",
       " {'max_depth': 2, 'min_child_weight': 8},\n",
       " 0.6702276354919299)"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test2 = {\n",
    " 'max_depth':[1,2,3,4,5,6,7,8,9,10],\n",
    " 'min_child_weight':[1,2,3,4,5,6,7,8,9,10]\n",
    "}\n",
    "gsearch2 = GridSearchCV(estimator = XGBClassifier( learning_rate=0.1, n_estimators=140, max_depth=1,\n",
    " min_child_weight=1, gamma=0, subsample=0.79, colsample_bytree=0.93,reg_alpha=0.1086,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test2, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch2.fit(X_train,y_train)\n",
    "gsearch2.cv_results_, gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:08:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'mean_fit_time': array([0.02752647, 0.02652993, 0.01755223, 0.02154284, 0.01655469,\n",
       "         1.30231786, 1.21176033, 1.21554928, 1.24626775, 1.193609  ,\n",
       "         1.19021769, 1.45471177, 1.24646535, 1.14094768, 1.15132036,\n",
       "         1.32046943, 1.20198426]),\n",
       "  'std_fit_time': array([0.00391807, 0.00644967, 0.00195361, 0.00223981, 0.00349013,\n",
       "         0.21158408, 0.15812182, 0.16045086, 0.13485001, 0.11012388,\n",
       "         0.1175322 , 0.2343767 , 0.20784411, 0.00769736, 0.02324871,\n",
       "         0.12746676, 0.1186225 ]),\n",
       "  'mean_score_time': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.00837836, 0.00957456, 0.01017389, 0.00857739, 0.00857673,\n",
       "         0.00837846, 0.0097733 , 0.00857782, 0.0095746 , 0.01017342,\n",
       "         0.01057267, 0.00917554]),\n",
       "  'std_score_time': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.00149204, 0.00223921, 0.0023932 , 0.00135319, 0.00119789,\n",
       "         0.00149304, 0.00132199, 0.00079781, 0.00162028, 0.00239377,\n",
       "         0.00271998, 0.00116266]),\n",
       "  'param_gamma': masked_array(data=[-0.005, -0.004, -0.003, -0.002, -0.001, 0.0, 0.001,\n",
       "                     0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008,\n",
       "                     0.009000000000000001, 0.01, 0.011],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'gamma': -0.005},\n",
       "   {'gamma': -0.004},\n",
       "   {'gamma': -0.003},\n",
       "   {'gamma': -0.002},\n",
       "   {'gamma': -0.001},\n",
       "   {'gamma': 0.0},\n",
       "   {'gamma': 0.001},\n",
       "   {'gamma': 0.002},\n",
       "   {'gamma': 0.003},\n",
       "   {'gamma': 0.004},\n",
       "   {'gamma': 0.005},\n",
       "   {'gamma': 0.006},\n",
       "   {'gamma': 0.007},\n",
       "   {'gamma': 0.008},\n",
       "   {'gamma': 0.009000000000000001},\n",
       "   {'gamma': 0.01},\n",
       "   {'gamma': 0.011}],\n",
       "  'split0_test_score': array([       nan,        nan,        nan,        nan,        nan,\n",
       "         0.68356386, 0.68356386, 0.68356386, 0.68356386, 0.68356386,\n",
       "         0.68356386, 0.68356386, 0.68356386, 0.68356386, 0.68356386,\n",
       "         0.68356386, 0.68356386]),\n",
       "  'split1_test_score': array([       nan,        nan,        nan,        nan,        nan,\n",
       "         0.68472506, 0.68472506, 0.68472506, 0.68472506, 0.68472506,\n",
       "         0.68472506, 0.68472506, 0.68472506, 0.68472506, 0.68472506,\n",
       "         0.68472506, 0.68472506]),\n",
       "  'split2_test_score': array([       nan,        nan,        nan,        nan,        nan,\n",
       "         0.64244384, 0.64244384, 0.64244384, 0.64244384, 0.64244384,\n",
       "         0.64244384, 0.64244384, 0.64244384, 0.64244384, 0.64244384,\n",
       "         0.64244384, 0.64244384]),\n",
       "  'split3_test_score': array([       nan,        nan,        nan,        nan,        nan,\n",
       "         0.69480372, 0.69480372, 0.69480372, 0.69480372, 0.69480372,\n",
       "         0.69480372, 0.69480372, 0.69480372, 0.69480372, 0.69480372,\n",
       "         0.69480372, 0.69480372]),\n",
       "  'split4_test_score': array([       nan,        nan,        nan,        nan,        nan,\n",
       "         0.64560169, 0.64560169, 0.64560169, 0.64560169, 0.64560169,\n",
       "         0.64560169, 0.64560169, 0.64560169, 0.64560169, 0.64560169,\n",
       "         0.64560169, 0.64560169]),\n",
       "  'mean_test_score': array([       nan,        nan,        nan,        nan,        nan,\n",
       "         0.67022764, 0.67022764, 0.67022764, 0.67022764, 0.67022764,\n",
       "         0.67022764, 0.67022764, 0.67022764, 0.67022764, 0.67022764,\n",
       "         0.67022764, 0.67022764]),\n",
       "  'std_test_score': array([       nan,        nan,        nan,        nan,        nan,\n",
       "         0.02177333, 0.02177333, 0.02177333, 0.02177333, 0.02177333,\n",
       "         0.02177333, 0.02177333, 0.02177333, 0.02177333, 0.02177333,\n",
       "         0.02177333, 0.02177333]),\n",
       "  'rank_test_score': array([17, 16, 15, 14, 13,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1])},\n",
       " {'gamma': 0.0},\n",
       " 0.6702276354919299)"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test3 = {\n",
    " 'gamma':[i*0.001 for i in range(-5,12)]\n",
    "}\n",
    "gsearch3 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=2,\n",
    " min_child_weight=8, gamma=0, subsample=0.79, colsample_bytree=0.93, reg_alpha=0.1086,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test3, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch3.fit(X_train,y_train)\n",
    "gsearch3.cv_results_, gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Accuracy : 0.64\n",
      "AUC Score (Train): 0.715278\n"
     ]
    }
   ],
   "source": [
    "xgb10 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=2,\n",
    " min_child_weight=8,\n",
    " gamma=0.0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb10, X_train,y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:09:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'mean_fit_time': array([1.11501665, 1.08709331, 1.05936732, 1.3112937 , 1.14354305,\n",
       "         1.15531001, 1.352982  , 1.22951193, 1.24686642, 1.38449807,\n",
       "         1.40683751, 1.3276495 , 1.41561451, 1.54905643, 1.38130674,\n",
       "         1.39407253]),\n",
       "  'std_fit_time': array([0.01335075, 0.02840615, 0.00840177, 0.1237936 , 0.01031644,\n",
       "         0.00806785, 0.14888895, 0.1183429 , 0.00647557, 0.16484438,\n",
       "         0.13905395, 0.03024716, 0.12323501, 0.13644872, 0.0098734 ,\n",
       "         0.0116026 ]),\n",
       "  'mean_score_time': array([0.01735616, 0.01097264, 0.00957484, 0.01017394, 0.01037092,\n",
       "         0.01137061, 0.00977478, 0.0097753 , 0.00977526, 0.00897727,\n",
       "         0.00937591, 0.00957417, 0.01077185, 0.00897713, 0.00937653,\n",
       "         0.00817823]),\n",
       "  'std_score_time': array([0.01254865, 0.00308928, 0.0016211 , 0.00317902, 0.00240648,\n",
       "         0.0024099 , 0.00116243, 0.00203414, 0.00171616, 0.00109306,\n",
       "         0.00232692, 0.00257007, 0.00222091, 0.0015448 , 0.00135465,\n",
       "         0.00146566]),\n",
       "  'param_colsample_bytree': masked_array(data=[0.6, 0.6, 0.6, 0.6, 0.7, 0.7, 0.7, 0.7, 0.8, 0.8, 0.8,\n",
       "                     0.8, 0.9, 0.9, 0.9, 0.9],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_subsample': masked_array(data=[0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8,\n",
       "                     0.9, 0.6, 0.7, 0.8, 0.9],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'colsample_bytree': 0.6, 'subsample': 0.6},\n",
       "   {'colsample_bytree': 0.6, 'subsample': 0.7},\n",
       "   {'colsample_bytree': 0.6, 'subsample': 0.8},\n",
       "   {'colsample_bytree': 0.6, 'subsample': 0.9},\n",
       "   {'colsample_bytree': 0.7, 'subsample': 0.6},\n",
       "   {'colsample_bytree': 0.7, 'subsample': 0.7},\n",
       "   {'colsample_bytree': 0.7, 'subsample': 0.8},\n",
       "   {'colsample_bytree': 0.7, 'subsample': 0.9},\n",
       "   {'colsample_bytree': 0.8, 'subsample': 0.6},\n",
       "   {'colsample_bytree': 0.8, 'subsample': 0.7},\n",
       "   {'colsample_bytree': 0.8, 'subsample': 0.8},\n",
       "   {'colsample_bytree': 0.8, 'subsample': 0.9},\n",
       "   {'colsample_bytree': 0.9, 'subsample': 0.6},\n",
       "   {'colsample_bytree': 0.9, 'subsample': 0.7},\n",
       "   {'colsample_bytree': 0.9, 'subsample': 0.8},\n",
       "   {'colsample_bytree': 0.9, 'subsample': 0.9}],\n",
       "  'split0_test_score': array([0.64304828, 0.67826857, 0.66125203, 0.66311763, 0.62995138,\n",
       "         0.66356989, 0.6698451 , 0.64836242, 0.63818641, 0.66272189,\n",
       "         0.67074963, 0.66130856, 0.6434817 , 0.65601327, 0.67759017,\n",
       "         0.661497  ]),\n",
       "  'split1_test_score': array([0.67319038, 0.68950911, 0.68273958, 0.6825694 , 0.68249376,\n",
       "         0.68737236, 0.67137509, 0.68128356, 0.69694047, 0.68232358,\n",
       "         0.67905227, 0.68160502, 0.67458967, 0.68585962, 0.68701309,\n",
       "         0.68498979]),\n",
       "  'split2_test_score': array([0.62393162, 0.62130323, 0.62788367, 0.63905907, 0.62555782,\n",
       "         0.61742682, 0.61897738, 0.64836245, 0.62487709, 0.62084941,\n",
       "         0.63463429, 0.65310869, 0.62979351, 0.6368845 , 0.62748657,\n",
       "         0.63888889]),\n",
       "  'split3_test_score': array([0.67249073, 0.67939263, 0.67651842, 0.67468421, 0.67347402,\n",
       "         0.68404432, 0.67277437, 0.67126163, 0.67799334, 0.68173739,\n",
       "         0.67406021, 0.67226382, 0.67016489, 0.67368202, 0.68937675,\n",
       "         0.68803419]),\n",
       "  'split4_test_score': array([0.64034491, 0.64234929, 0.64119582, 0.63994781, 0.63622268,\n",
       "         0.64807881, 0.64140383, 0.64202783, 0.63979654, 0.63701687,\n",
       "         0.6423682 , 0.65165267, 0.63779215, 0.64715226, 0.64210347,\n",
       "         0.64112019]),\n",
       "  'mean_test_score': array([0.65060118, 0.66216457, 0.6579179 , 0.65987562, 0.64953993,\n",
       "         0.66009844, 0.65487515, 0.65825958, 0.65555877, 0.65692983,\n",
       "         0.66017292, 0.66398775, 0.65116438, 0.65991833, 0.66471401,\n",
       "         0.66290601]),\n",
       "  'std_test_score': array([0.01930247, 0.02594673, 0.02076003, 0.0177497 , 0.02364317,\n",
       "         0.02566968, 0.02138624, 0.01522192, 0.02723001, 0.02446274,\n",
       "         0.01805759, 0.01145904, 0.01791266, 0.01772664, 0.02517305,\n",
       "         0.02084489]),\n",
       "  'rank_test_score': array([15,  4, 10,  8, 16,  6, 13,  9, 12, 11,  5,  2, 14,  7,  1,  3])},\n",
       " {'colsample_bytree': 0.9, 'subsample': 0.8},\n",
       " 0.6647140102447886)"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test4 = {\n",
    " 'subsample':[i/10.0 for i in range(6,10)],\n",
    " 'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
    "}\n",
    "gsearch4 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=177, max_depth=2,\n",
    " min_child_weight=8, gamma=0.00, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test4, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch4.fit(X_train,y_train)\n",
    "gsearch4.cv_results_, gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:24:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'colsample_bytree': 0.926, 'subsample': 0.79}, 0.6729241736445823)"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test5 = {\n",
    " 'subsample':[i/1000.0 for i in range(785,795)],\n",
    " 'colsample_bytree':[i/1000.0 for i in range(925,935)]\n",
    "}\n",
    "gsearch5 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=177, max_depth=2,\n",
    " min_child_weight=8, gamma=0.0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test5, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch5.fit(X_train,y_train)\n",
    "gsearch5.best_params_, gsearch5.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([1.82865977, 1.49363742, 1.66804447, 1.57808161, 1.58201437,\n",
       "        1.73275294, 1.62233663, 1.570892  , 1.82465005, 1.55816913,\n",
       "        1.7656239 , 1.56898975, 1.51744294, 1.72106924, 1.61919842,\n",
       "        1.57737684, 2.18282266, 1.69979773, 1.9504178 , 1.72833738,\n",
       "        1.82021217, 1.88311977, 1.58461781, 1.84187007, 1.74422131,\n",
       "        1.95648756, 1.6419631 , 1.4882071 , 1.72617159, 1.48952947,\n",
       "        1.48432364, 1.76736059, 1.56793079, 1.838696  , 2.00181489,\n",
       "        1.6578845 , 2.04253788, 1.64081101, 1.99606318, 1.73675537,\n",
       "        1.56740899, 1.78422914, 1.6465971 , 2.05291066, 1.6092967 ,\n",
       "        1.8819694 , 1.93682094, 3.86746192, 2.29107332, 1.6336318 ,\n",
       "        1.63123598, 1.61627817, 1.84227605, 1.64997296, 2.37545409,\n",
       "        3.48498263, 2.14586172, 1.71282125, 2.1360877 , 1.91168842,\n",
       "        2.03934755, 2.43488884, 2.20270877, 2.03356295, 2.21288095,\n",
       "        3.74099779, 3.42404604, 2.29805322, 1.60450969, 1.61149073,\n",
       "        1.84905577, 1.58436332, 1.64779291, 1.69646311, 1.66933608,\n",
       "        4.10981193, 2.57112427, 2.09380312, 1.59054685, 1.76787233,\n",
       "        1.57259483, 1.63403053, 1.65457578, 1.58057246, 1.77345781,\n",
       "        1.70364375, 1.74593177, 1.92904153, 1.7086309 , 1.6854928 ,\n",
       "        1.70962939, 1.57977576, 1.82771244, 1.62186279, 2.49971628,\n",
       "        1.99958105, 1.69253635, 1.82082553, 1.6512073 , 1.83380308]),\n",
       " 'std_fit_time': array([0.16138451, 0.01071457, 0.15124946, 0.10711063, 0.06509946,\n",
       "        0.05634005, 0.0426248 , 0.03377823, 0.14306106, 0.03066638,\n",
       "        0.11902989, 0.15314951, 0.00670067, 0.14649867, 0.09506897,\n",
       "        0.01479888, 0.17578046, 0.10135398, 0.31000415, 0.2595692 ,\n",
       "        0.11399931, 0.22169865, 0.00739677, 0.12712339, 0.1993256 ,\n",
       "        0.12690204, 0.17788681, 0.01019794, 0.11932759, 0.01141525,\n",
       "        0.0187935 , 0.14526601, 0.06207235, 0.14180082, 0.02156028,\n",
       "        0.15728417, 0.20919929, 0.00959466, 0.2672592 , 0.24071502,\n",
       "        0.2020977 , 0.22240816, 0.09072349, 0.18198166, 0.03386008,\n",
       "        0.30259146, 0.24693886, 1.05775572, 0.40891045, 0.16915779,\n",
       "        0.17588494, 0.05517877, 0.10029262, 0.16079949, 0.36626887,\n",
       "        0.4549862 , 0.27557985, 0.17491406, 0.15527274, 0.17269526,\n",
       "        0.39304215, 0.36906071, 0.26730631, 0.18628898, 0.6446404 ,\n",
       "        0.09671904, 0.34418362, 0.42838152, 0.04094395, 0.11703846,\n",
       "        0.13558393, 0.03707427, 0.1167241 , 0.16106359, 0.14155475,\n",
       "        1.20613356, 0.36697785, 0.26428097, 0.02859698, 0.10127854,\n",
       "        0.03785342, 0.16365341, 0.16513968, 0.0471994 , 0.15075653,\n",
       "        0.09541622, 0.01738449, 0.06894546, 0.10199261, 0.16804654,\n",
       "        0.13558088, 0.0187649 , 0.14273313, 0.11168071, 0.59320306,\n",
       "        0.50529909, 0.09660045, 0.08981422, 0.03389309, 0.11251968]),\n",
       " 'mean_score_time': array([0.00922856, 0.01100192, 0.01061401, 0.01360497, 0.00960717,\n",
       "        0.01360273, 0.00880446, 0.00879717, 0.00970383, 0.00959344,\n",
       "        0.00861135, 0.00849118, 0.01059508, 0.01241193, 0.00889983,\n",
       "        0.00781851, 0.01009078, 0.00870094, 0.00960002, 0.00969996,\n",
       "        0.0120038 , 0.00987463, 0.00900683, 0.00832543, 0.00910196,\n",
       "        0.00920782, 0.00890408, 0.00859632, 0.00839272, 0.00799513,\n",
       "        0.00781183, 0.01057677, 0.00979352, 0.00959277, 0.01198716,\n",
       "        0.00937567, 0.00897665, 0.00857782, 0.00857706, 0.00897679,\n",
       "        0.00837932, 0.00937586, 0.00857778, 0.01037521, 0.00857739,\n",
       "        0.01117001, 0.00957508, 0.01815057, 0.00837908, 0.01097131,\n",
       "        0.00897684, 0.00817847, 0.01057024, 0.00959044, 0.00940237,\n",
       "        0.01017799, 0.00837898, 0.01077023, 0.01077166, 0.01017632,\n",
       "        0.01356115, 0.01017456, 0.0103724 , 0.01076999, 0.01356306,\n",
       "        0.01416178, 0.01256628, 0.00957541, 0.00877719, 0.01017509,\n",
       "        0.0095746 , 0.00937591, 0.01097131, 0.00897651, 0.00877724,\n",
       "        0.01196856, 0.01316538, 0.01076913, 0.00837774, 0.00937676,\n",
       "        0.00817924, 0.00837784, 0.00837817, 0.00937557, 0.01216803,\n",
       "        0.00937538, 0.00877647, 0.00997376, 0.00897684, 0.00797963,\n",
       "        0.00877571, 0.0095747 , 0.00897837, 0.00897655, 0.00797858,\n",
       "        0.01039085, 0.00899453, 0.00861216, 0.00860734, 0.00857735]),\n",
       " 'std_score_time': array([0.00040131, 0.00242575, 0.00144645, 0.00215041, 0.00279878,\n",
       "        0.00407851, 0.0009758 , 0.00111712, 0.00087716, 0.0010213 ,\n",
       "        0.00079943, 0.00063401, 0.00340093, 0.00340328, 0.00110494,\n",
       "        0.00073547, 0.00189974, 0.00097694, 0.00149215, 0.0013405 ,\n",
       "        0.00274374, 0.00420178, 0.00062113, 0.00116754, 0.00112704,\n",
       "        0.0007436 , 0.00168088, 0.00101875, 0.00102592, 0.0006306 ,\n",
       "        0.0007479 , 0.00135156, 0.00147212, 0.00241295, 0.00518196,\n",
       "        0.00048951, 0.0008917 , 0.00135279, 0.00135292, 0.00141003,\n",
       "        0.00135209, 0.0014932 , 0.00048858, 0.00101743, 0.00135337,\n",
       "        0.00390913, 0.00149199, 0.01316032, 0.0004902 , 0.00454902,\n",
       "        0.00063007, 0.00039852, 0.00376155, 0.00101628, 0.00186102,\n",
       "        0.00270318, 0.00101675, 0.00239332, 0.00330226, 0.00146901,\n",
       "        0.00499072, 0.00132381, 0.00149255, 0.00193462, 0.00506805,\n",
       "        0.00353668, 0.00249048, 0.00119731, 0.00074592, 0.00255554,\n",
       "        0.00048906, 0.000798  , 0.00274895, 0.00089218, 0.00132358,\n",
       "        0.0026008 , 0.0093854 , 0.00311719, 0.00079789, 0.00331598,\n",
       "        0.00116331, 0.00048877, 0.00101725, 0.00101726, 0.00347805,\n",
       "        0.00184883, 0.00039842, 0.00236058, 0.00089244, 0.00063128,\n",
       "        0.00116095, 0.00079688, 0.00166901, 0.00063052, 0.00089282,\n",
       "        0.00173629, 0.00109734, 0.00048956, 0.00079653, 0.00048862]),\n",
       " 'param_colsample_bytree': masked_array(data=[0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.91,\n",
       "                    0.91, 0.91, 0.91, 0.91, 0.91, 0.91, 0.91, 0.91, 0.91,\n",
       "                    0.92, 0.92, 0.92, 0.92, 0.92, 0.92, 0.92, 0.92, 0.92,\n",
       "                    0.92, 0.93, 0.93, 0.93, 0.93, 0.93, 0.93, 0.93, 0.93,\n",
       "                    0.93, 0.93, 0.94, 0.94, 0.94, 0.94, 0.94, 0.94, 0.94,\n",
       "                    0.94, 0.94, 0.94, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95,\n",
       "                    0.95, 0.95, 0.95, 0.95, 0.96, 0.96, 0.96, 0.96, 0.96,\n",
       "                    0.96, 0.96, 0.96, 0.96, 0.96, 0.97, 0.97, 0.97, 0.97,\n",
       "                    0.97, 0.97, 0.97, 0.97, 0.97, 0.97, 0.98, 0.98, 0.98,\n",
       "                    0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.99, 0.99,\n",
       "                    0.99, 0.99, 0.99, 0.99, 0.99, 0.99, 0.99, 0.99],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_subsample': masked_array(data=[0.75, 0.76, 0.77, 0.78, 0.79, 0.8, 0.81, 0.82, 0.83,\n",
       "                    0.84, 0.75, 0.76, 0.77, 0.78, 0.79, 0.8, 0.81, 0.82,\n",
       "                    0.83, 0.84, 0.75, 0.76, 0.77, 0.78, 0.79, 0.8, 0.81,\n",
       "                    0.82, 0.83, 0.84, 0.75, 0.76, 0.77, 0.78, 0.79, 0.8,\n",
       "                    0.81, 0.82, 0.83, 0.84, 0.75, 0.76, 0.77, 0.78, 0.79,\n",
       "                    0.8, 0.81, 0.82, 0.83, 0.84, 0.75, 0.76, 0.77, 0.78,\n",
       "                    0.79, 0.8, 0.81, 0.82, 0.83, 0.84, 0.75, 0.76, 0.77,\n",
       "                    0.78, 0.79, 0.8, 0.81, 0.82, 0.83, 0.84, 0.75, 0.76,\n",
       "                    0.77, 0.78, 0.79, 0.8, 0.81, 0.82, 0.83, 0.84, 0.75,\n",
       "                    0.76, 0.77, 0.78, 0.79, 0.8, 0.81, 0.82, 0.83, 0.84,\n",
       "                    0.75, 0.76, 0.77, 0.78, 0.79, 0.8, 0.81, 0.82, 0.83,\n",
       "                    0.84],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'colsample_bytree': 0.9, 'subsample': 0.75},\n",
       "  {'colsample_bytree': 0.9, 'subsample': 0.76},\n",
       "  {'colsample_bytree': 0.9, 'subsample': 0.77},\n",
       "  {'colsample_bytree': 0.9, 'subsample': 0.78},\n",
       "  {'colsample_bytree': 0.9, 'subsample': 0.79},\n",
       "  {'colsample_bytree': 0.9, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.9, 'subsample': 0.81},\n",
       "  {'colsample_bytree': 0.9, 'subsample': 0.82},\n",
       "  {'colsample_bytree': 0.9, 'subsample': 0.83},\n",
       "  {'colsample_bytree': 0.9, 'subsample': 0.84},\n",
       "  {'colsample_bytree': 0.91, 'subsample': 0.75},\n",
       "  {'colsample_bytree': 0.91, 'subsample': 0.76},\n",
       "  {'colsample_bytree': 0.91, 'subsample': 0.77},\n",
       "  {'colsample_bytree': 0.91, 'subsample': 0.78},\n",
       "  {'colsample_bytree': 0.91, 'subsample': 0.79},\n",
       "  {'colsample_bytree': 0.91, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.91, 'subsample': 0.81},\n",
       "  {'colsample_bytree': 0.91, 'subsample': 0.82},\n",
       "  {'colsample_bytree': 0.91, 'subsample': 0.83},\n",
       "  {'colsample_bytree': 0.91, 'subsample': 0.84},\n",
       "  {'colsample_bytree': 0.92, 'subsample': 0.75},\n",
       "  {'colsample_bytree': 0.92, 'subsample': 0.76},\n",
       "  {'colsample_bytree': 0.92, 'subsample': 0.77},\n",
       "  {'colsample_bytree': 0.92, 'subsample': 0.78},\n",
       "  {'colsample_bytree': 0.92, 'subsample': 0.79},\n",
       "  {'colsample_bytree': 0.92, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.92, 'subsample': 0.81},\n",
       "  {'colsample_bytree': 0.92, 'subsample': 0.82},\n",
       "  {'colsample_bytree': 0.92, 'subsample': 0.83},\n",
       "  {'colsample_bytree': 0.92, 'subsample': 0.84},\n",
       "  {'colsample_bytree': 0.93, 'subsample': 0.75},\n",
       "  {'colsample_bytree': 0.93, 'subsample': 0.76},\n",
       "  {'colsample_bytree': 0.93, 'subsample': 0.77},\n",
       "  {'colsample_bytree': 0.93, 'subsample': 0.78},\n",
       "  {'colsample_bytree': 0.93, 'subsample': 0.79},\n",
       "  {'colsample_bytree': 0.93, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.93, 'subsample': 0.81},\n",
       "  {'colsample_bytree': 0.93, 'subsample': 0.82},\n",
       "  {'colsample_bytree': 0.93, 'subsample': 0.83},\n",
       "  {'colsample_bytree': 0.93, 'subsample': 0.84},\n",
       "  {'colsample_bytree': 0.94, 'subsample': 0.75},\n",
       "  {'colsample_bytree': 0.94, 'subsample': 0.76},\n",
       "  {'colsample_bytree': 0.94, 'subsample': 0.77},\n",
       "  {'colsample_bytree': 0.94, 'subsample': 0.78},\n",
       "  {'colsample_bytree': 0.94, 'subsample': 0.79},\n",
       "  {'colsample_bytree': 0.94, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.94, 'subsample': 0.81},\n",
       "  {'colsample_bytree': 0.94, 'subsample': 0.82},\n",
       "  {'colsample_bytree': 0.94, 'subsample': 0.83},\n",
       "  {'colsample_bytree': 0.94, 'subsample': 0.84},\n",
       "  {'colsample_bytree': 0.95, 'subsample': 0.75},\n",
       "  {'colsample_bytree': 0.95, 'subsample': 0.76},\n",
       "  {'colsample_bytree': 0.95, 'subsample': 0.77},\n",
       "  {'colsample_bytree': 0.95, 'subsample': 0.78},\n",
       "  {'colsample_bytree': 0.95, 'subsample': 0.79},\n",
       "  {'colsample_bytree': 0.95, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.95, 'subsample': 0.81},\n",
       "  {'colsample_bytree': 0.95, 'subsample': 0.82},\n",
       "  {'colsample_bytree': 0.95, 'subsample': 0.83},\n",
       "  {'colsample_bytree': 0.95, 'subsample': 0.84},\n",
       "  {'colsample_bytree': 0.96, 'subsample': 0.75},\n",
       "  {'colsample_bytree': 0.96, 'subsample': 0.76},\n",
       "  {'colsample_bytree': 0.96, 'subsample': 0.77},\n",
       "  {'colsample_bytree': 0.96, 'subsample': 0.78},\n",
       "  {'colsample_bytree': 0.96, 'subsample': 0.79},\n",
       "  {'colsample_bytree': 0.96, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.96, 'subsample': 0.81},\n",
       "  {'colsample_bytree': 0.96, 'subsample': 0.82},\n",
       "  {'colsample_bytree': 0.96, 'subsample': 0.83},\n",
       "  {'colsample_bytree': 0.96, 'subsample': 0.84},\n",
       "  {'colsample_bytree': 0.97, 'subsample': 0.75},\n",
       "  {'colsample_bytree': 0.97, 'subsample': 0.76},\n",
       "  {'colsample_bytree': 0.97, 'subsample': 0.77},\n",
       "  {'colsample_bytree': 0.97, 'subsample': 0.78},\n",
       "  {'colsample_bytree': 0.97, 'subsample': 0.79},\n",
       "  {'colsample_bytree': 0.97, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.97, 'subsample': 0.81},\n",
       "  {'colsample_bytree': 0.97, 'subsample': 0.82},\n",
       "  {'colsample_bytree': 0.97, 'subsample': 0.83},\n",
       "  {'colsample_bytree': 0.97, 'subsample': 0.84},\n",
       "  {'colsample_bytree': 0.98, 'subsample': 0.75},\n",
       "  {'colsample_bytree': 0.98, 'subsample': 0.76},\n",
       "  {'colsample_bytree': 0.98, 'subsample': 0.77},\n",
       "  {'colsample_bytree': 0.98, 'subsample': 0.78},\n",
       "  {'colsample_bytree': 0.98, 'subsample': 0.79},\n",
       "  {'colsample_bytree': 0.98, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.98, 'subsample': 0.81},\n",
       "  {'colsample_bytree': 0.98, 'subsample': 0.82},\n",
       "  {'colsample_bytree': 0.98, 'subsample': 0.83},\n",
       "  {'colsample_bytree': 0.98, 'subsample': 0.84},\n",
       "  {'colsample_bytree': 0.99, 'subsample': 0.75},\n",
       "  {'colsample_bytree': 0.99, 'subsample': 0.76},\n",
       "  {'colsample_bytree': 0.99, 'subsample': 0.77},\n",
       "  {'colsample_bytree': 0.99, 'subsample': 0.78},\n",
       "  {'colsample_bytree': 0.99, 'subsample': 0.79},\n",
       "  {'colsample_bytree': 0.99, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.99, 'subsample': 0.81},\n",
       "  {'colsample_bytree': 0.99, 'subsample': 0.82},\n",
       "  {'colsample_bytree': 0.99, 'subsample': 0.83},\n",
       "  {'colsample_bytree': 0.99, 'subsample': 0.84}],\n",
       " 'split0_test_score': array([0.64608224, 0.64498926, 0.65704971, 0.65135869, 0.66242038,\n",
       "        0.67759017, 0.67589417, 0.66172314, 0.66880865, 0.66196812,\n",
       "        0.64608224, 0.64498926, 0.65704971, 0.65135869, 0.66242038,\n",
       "        0.67759017, 0.67589417, 0.66172314, 0.66880865, 0.66196812,\n",
       "        0.65037877, 0.65642784, 0.65292278, 0.66767799, 0.67760902,\n",
       "        0.66315532, 0.6696755 , 0.68273471, 0.67448084, 0.66219425,\n",
       "        0.65816153, 0.65652207, 0.66145931, 0.65475069, 0.67796706,\n",
       "        0.67431124, 0.66176083, 0.67282252, 0.66958128, 0.66837523,\n",
       "        0.65816153, 0.65652207, 0.66145931, 0.65475069, 0.67796706,\n",
       "        0.67431124, 0.66176083, 0.67282252, 0.66958128, 0.66837523,\n",
       "        0.65639016, 0.6519994 , 0.65147175, 0.67042928, 0.69113934,\n",
       "        0.67076848, 0.65769042, 0.66155354, 0.6688275 , 0.67020314,\n",
       "        0.66008367, 0.65360118, 0.662345  , 0.65294162, 0.67216297,\n",
       "        0.6761203 , 0.6742547 , 0.66860136, 0.67218181, 0.65757736,\n",
       "        0.66008367, 0.65360118, 0.662345  , 0.65294162, 0.67216297,\n",
       "        0.6761203 , 0.6742547 , 0.66860136, 0.67218181, 0.65757736,\n",
       "        0.64564881, 0.65476953, 0.66255229, 0.6698451 , 0.68224475,\n",
       "        0.66709381, 0.66579354, 0.66025327, 0.67257754, 0.66411638,\n",
       "        0.65431727, 0.65397807, 0.66622696, 0.66980741, 0.68495835,\n",
       "        0.65541024, 0.67342555, 0.67133381, 0.67483888, 0.661497  ]),\n",
       " 'split1_test_score': array([0.68962257, 0.68695636, 0.6833825 , 0.68158611, 0.67504349,\n",
       "        0.68701309, 0.68357159, 0.68559489, 0.68130247, 0.68383632,\n",
       "        0.68962257, 0.68695636, 0.6833825 , 0.68158611, 0.67504349,\n",
       "        0.68701309, 0.68357159, 0.68559489, 0.68130247, 0.68383632,\n",
       "        0.6835905 , 0.68691854, 0.69573028, 0.68221012, 0.679941  ,\n",
       "        0.68411996, 0.68472506, 0.68771273, 0.68720218, 0.6864269 ,\n",
       "        0.68307995, 0.68366614, 0.68909311, 0.67003252, 0.6854247 ,\n",
       "        0.68362832, 0.6823803 , 0.68654035, 0.68058392, 0.68022464,\n",
       "        0.68307995, 0.68366614, 0.68909311, 0.67003252, 0.6854247 ,\n",
       "        0.68362832, 0.6823803 , 0.68654035, 0.68058392, 0.68022464,\n",
       "        0.69122986, 0.69538991, 0.67470312, 0.67901445, 0.67903336,\n",
       "        0.67975191, 0.68347704, 0.67347402, 0.68082974, 0.68533016,\n",
       "        0.68888511, 0.69283715, 0.68481961, 0.68137811, 0.68718327,\n",
       "        0.67570532, 0.68243703, 0.67757734, 0.68194539, 0.68084865,\n",
       "        0.68888511, 0.69283715, 0.68481961, 0.68137811, 0.68718327,\n",
       "        0.67570532, 0.68243703, 0.67757734, 0.68194539, 0.68084865,\n",
       "        0.68491415, 0.69247788, 0.68563271, 0.68166175, 0.6902844 ,\n",
       "        0.67092126, 0.68676726, 0.68243703, 0.68228576, 0.69268588,\n",
       "        0.6825694 , 0.69141895, 0.68251267, 0.68309886, 0.67950609,\n",
       "        0.67239619, 0.67665078, 0.68722109, 0.68343923, 0.69669465]),\n",
       " 'split2_test_score': array([0.64225475, 0.63535285, 0.64263293, 0.64185765, 0.62552001,\n",
       "        0.62748657, 0.63295137, 0.62465018, 0.63416156, 0.63697905,\n",
       "        0.64225475, 0.63535285, 0.64263293, 0.64185765, 0.62552001,\n",
       "        0.62748657, 0.63295137, 0.62465018, 0.63416156, 0.63697905,\n",
       "        0.64737917, 0.6435784 , 0.64132819, 0.6360714 , 0.64925119,\n",
       "        0.64263293, 0.61731337, 0.62597383, 0.63030406, 0.64968611,\n",
       "        0.63650632, 0.62968005, 0.65745783, 0.63416156, 0.65095303,\n",
       "        0.62232433, 0.62928296, 0.64287875, 0.6386998 , 0.63372665,\n",
       "        0.63650632, 0.62968005, 0.65745783, 0.63416156, 0.65095303,\n",
       "        0.62232433, 0.62928296, 0.64287875, 0.6386998 , 0.63372665,\n",
       "        0.64340821, 0.62574692, 0.65897058, 0.63399138, 0.63792451,\n",
       "        0.64522351, 0.62837531, 0.63588231, 0.63325391, 0.63461538,\n",
       "        0.64110128, 0.64382422, 0.64675516, 0.63644959, 0.64034491,\n",
       "        0.64119582, 0.63503139, 0.65095303, 0.63601467, 0.63956962,\n",
       "        0.64110128, 0.64382422, 0.64675516, 0.63644959, 0.64034491,\n",
       "        0.64119582, 0.63503139, 0.65095303, 0.63601467, 0.63956962,\n",
       "        0.6452046 , 0.63941835, 0.63544739, 0.63881325, 0.63408592,\n",
       "        0.64858937, 0.62574692, 0.62901823, 0.62799713, 0.64025036,\n",
       "        0.63682777, 0.63656304, 0.64475078, 0.64584752, 0.63866198,\n",
       "        0.63737614, 0.64034491, 0.62884804, 0.63157099, 0.62945314]),\n",
       " 'split3_test_score': array([0.69015203, 0.68595416, 0.68722109, 0.68117011, 0.68062174,\n",
       "        0.68937675, 0.69041676, 0.6886771 , 0.67702897, 0.68741018,\n",
       "        0.69015203, 0.68595416, 0.68722109, 0.68117011, 0.68062174,\n",
       "        0.68937675, 0.69041676, 0.6886771 , 0.67702897, 0.68741018,\n",
       "        0.69514409, 0.68377959, 0.68152939, 0.68168066, 0.6783148 ,\n",
       "        0.68255049, 0.68971712, 0.67806898, 0.68565161, 0.68986839,\n",
       "        0.68913093, 0.67814462, 0.67842826, 0.6738333 , 0.69037894,\n",
       "        0.68773164, 0.68048937, 0.68183193, 0.68221012, 0.68472506,\n",
       "        0.68913093, 0.67814462, 0.67842826, 0.6738333 , 0.69037894,\n",
       "        0.68773164, 0.68048937, 0.68183193, 0.68221012, 0.68472506,\n",
       "        0.69134332, 0.66891687, 0.68421451, 0.68381741, 0.67882535,\n",
       "        0.68498979, 0.67988428, 0.68920657, 0.68731563, 0.68629453,\n",
       "        0.68616217, 0.67670751, 0.70359655, 0.6831745 , 0.68313668,\n",
       "        0.68797746, 0.67748279, 0.69036003, 0.6907004 , 0.68606762,\n",
       "        0.68616217, 0.67670751, 0.70359655, 0.6831745 , 0.68313668,\n",
       "        0.68797746, 0.67748279, 0.69036003, 0.6907004 , 0.68606762,\n",
       "        0.69406626, 0.67579986, 0.69444444, 0.68932002, 0.68899856,\n",
       "        0.69136223, 0.68391196, 0.68098102, 0.68612435, 0.68969821,\n",
       "        0.70306709, 0.67752061, 0.67946827, 0.68986839, 0.68245594,\n",
       "        0.68376068, 0.69370698, 0.68894183, 0.68841237, 0.67950609]),\n",
       " 'split4_test_score': array([0.63573103, 0.64511005, 0.63298918, 0.6344452 , 0.64414568,\n",
       "        0.64210347, 0.64259511, 0.63921035, 0.64493987, 0.64346494,\n",
       "        0.63573103, 0.64511005, 0.63298918, 0.6344452 , 0.64414568,\n",
       "        0.64210347, 0.64259511, 0.63921035, 0.64493987, 0.64346494,\n",
       "        0.64843809, 0.66010514, 0.63072007, 0.63370774, 0.64047727,\n",
       "        0.64490205, 0.63410483, 0.63480448, 0.64250057, 0.64259511,\n",
       "        0.64410786, 0.65938658, 0.63747069, 0.64429695, 0.65989713,\n",
       "        0.6362794 , 0.63711141, 0.6521065 , 0.63062552, 0.64121473,\n",
       "        0.64410786, 0.65938658, 0.63747069, 0.64429695, 0.65989713,\n",
       "        0.6362794 , 0.63711141, 0.6521065 , 0.63062552, 0.64121473,\n",
       "        0.64501551, 0.65165267, 0.64475078, 0.63185463, 0.63045534,\n",
       "        0.62856441, 0.6443915 , 0.64323803, 0.64076091, 0.65212541,\n",
       "        0.63973981, 0.64770063, 0.64386204, 0.62979351, 0.65065048,\n",
       "        0.64314348, 0.64303003, 0.64015581, 0.64548824, 0.64779517,\n",
       "        0.63973981, 0.64770063, 0.64386204, 0.62979351, 0.65065048,\n",
       "        0.64314348, 0.64303003, 0.64015581, 0.64548824, 0.64779517,\n",
       "        0.65174722, 0.64442932, 0.64223584, 0.63699796, 0.64042054,\n",
       "        0.64335149, 0.63329173, 0.64919446, 0.64815445, 0.64335149,\n",
       "        0.64698207, 0.66647757, 0.63716814, 0.63297027, 0.65339233,\n",
       "        0.6301717 , 0.63531503, 0.64437259, 0.64306785, 0.6539407 ]),\n",
       " 'mean_test_score': array([0.66076852, 0.65967254, 0.66065508, 0.65808355, 0.65755026,\n",
       "        0.66471401, 0.6650858 , 0.65997113, 0.66124831, 0.66273172,\n",
       "        0.66076852, 0.65967254, 0.66065508, 0.65808355, 0.65755026,\n",
       "        0.66471401, 0.6650858 , 0.65997113, 0.66124831, 0.66273172,\n",
       "        0.66498612, 0.6661619 , 0.66044614, 0.66026958, 0.66511866,\n",
       "        0.66347215, 0.65910717, 0.66185895, 0.66402785, 0.66615415,\n",
       "        0.66219732, 0.66147989, 0.66478184, 0.655415  , 0.67292417,\n",
       "        0.66085499, 0.65820498, 0.66723601, 0.66034013, 0.66165326,\n",
       "        0.66219732, 0.66147989, 0.66478184, 0.655415  , 0.67292417,\n",
       "        0.66085499, 0.65820498, 0.66723601, 0.66034013, 0.66165326,\n",
       "        0.66547741, 0.65874115, 0.66282215, 0.65982143, 0.66347558,\n",
       "        0.66185962, 0.65876371, 0.66067089, 0.66219754, 0.66571372,\n",
       "        0.66319441, 0.66293414, 0.66827567, 0.65674746, 0.66669566,\n",
       "        0.66482848, 0.66244719, 0.66552952, 0.6652661 , 0.66237168,\n",
       "        0.66319441, 0.66293414, 0.66827567, 0.65674746, 0.66669566,\n",
       "        0.66482848, 0.66244719, 0.66552952, 0.6652661 , 0.66237168,\n",
       "        0.66431621, 0.66137899, 0.66406253, 0.66332762, 0.66720684,\n",
       "        0.66426363, 0.65910228, 0.6603768 , 0.66342785, 0.66602046,\n",
       "        0.66475272, 0.66519165, 0.66202536, 0.66431849, 0.66779494,\n",
       "        0.65582299, 0.66388865, 0.66414347, 0.66426586, 0.66421832]),\n",
       " 'std_test_score': array([0.02400529, 0.0221551 , 0.02156611, 0.01976175, 0.02033541,\n",
       "        0.02517305, 0.0229724 , 0.0251486 , 0.0184825 , 0.02044222,\n",
       "        0.02400529, 0.0221551 , 0.02156611, 0.01976175, 0.02033541,\n",
       "        0.02517305, 0.0229724 , 0.0251486 , 0.0184825 , 0.02044222,\n",
       "        0.02026249, 0.01662932, 0.02447533, 0.02138125, 0.01678585,\n",
       "        0.01771743, 0.02855442, 0.02602563, 0.02330073, 0.0190539 ,\n",
       "        0.02080888, 0.019027  , 0.01782045, 0.01502442, 0.01509171,\n",
       "        0.02649762, 0.02179498, 0.01696518, 0.02156278, 0.02059135,\n",
       "        0.02080888, 0.019027  , 0.01782045, 0.01502442, 0.01509171,\n",
       "        0.02649762, 0.02179498, 0.01696518, 0.02156278, 0.02059135,\n",
       "        0.02154322, 0.02293902, 0.01462211, 0.02238767, 0.02443824,\n",
       "        0.02153991, 0.02091886, 0.01948005, 0.02153739, 0.01990115,\n",
       "        0.02114441, 0.01880558, 0.0228718 , 0.02217233, 0.01828524,\n",
       "        0.01902854, 0.01946141, 0.01804128, 0.02107007, 0.01821148,\n",
       "        0.02114441, 0.01880558, 0.0228718 , 0.02217233, 0.01828524,\n",
       "        0.01902854, 0.01946141, 0.01804128, 0.02107007, 0.01821148,\n",
       "        0.02088562, 0.01994166, 0.0231769 , 0.02167223, 0.02469045,\n",
       "        0.01714449, 0.02531564, 0.0200978 , 0.02210467, 0.02215078,\n",
       "        0.02445372, 0.01890434, 0.01820951, 0.02172333, 0.0184545 ,\n",
       "        0.02026638, 0.02242194, 0.0238155 , 0.02271903, 0.02284767]),\n",
       " 'rank_test_score': array([71, 84, 74, 92, 94, 30, 22, 81, 67, 50, 71, 84, 74, 92, 94, 30, 22,\n",
       "        81, 67, 50, 24, 11, 76, 80, 21, 42, 86, 61, 39, 12, 57, 64, 27, 99,\n",
       "         1, 69, 90,  6, 78, 62, 57, 64, 27, 99,  1, 69, 90,  6, 78, 62, 17,\n",
       "        89, 49, 83, 41, 60, 88, 73, 56, 14, 45, 47,  3, 96,  9, 25, 52, 15,\n",
       "        18, 54, 45, 47,  3, 96,  9, 25, 52, 15, 18, 54, 33, 66, 38, 44,  8,\n",
       "        35, 87, 77, 43, 13, 29, 20, 59, 32,  5, 98, 40, 37, 34, 36])}"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch5.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Accuracy : 0.72\n",
      "AUC Score (Train): 0.729167\n"
     ]
    }
   ],
   "source": [
    "xgb15 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=177,\n",
    " max_depth=2,\n",
    " min_child_weight=8,\n",
    " gamma=0.02,\n",
    " subsample=0.79,\n",
    " colsample_bytree=0.926,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb15, X_train,y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:25:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'reg_alpha': 0.1}, 0.6642611262255892)"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test6 = {\n",
    " 'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]\n",
    "}\n",
    "gsearch6 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=177, max_depth=2,\n",
    " min_child_weight=8, gamma=0.02, subsample=0.93, colsample_bytree=0.79,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test6, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch6.fit(X_train,y_train)\n",
    "gsearch6.best_params_, gsearch6.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:26:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'reg_alpha': 0.1086}, 0.6690715474590723)"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test7 = {\n",
    " 'reg_alpha':[i/10000.0 for i in range(1070,1090)]\n",
    "}\n",
    "gsearch7 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=177, max_depth=2,\n",
    " min_child_weight=8, gamma=0.02, subsample=0.79, colsample_bytree=0.93,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test7, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch7.fit(X_train,y_train)\n",
    "gsearch7.best_params_, gsearch7.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Accuracy : 0.72\n",
      "AUC Score (Train): 0.729167\n"
     ]
    }
   ],
   "source": [
    "xgb3 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=2,\n",
    " min_child_weight=8,\n",
    " gamma=0.0,\n",
    " subsample=0.79,\n",
    " colsample_bytree=0.926,\n",
    " reg_alpha=0.1086,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb3, X_train,y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:56:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'reg_lambda': 1e-05}, 0.6329817158931083)"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test8 = {\n",
    " 'reg_lambda':[1e-5, 1e-6,0.0, 0.1, 1, 100]\n",
    "}\n",
    "gsearch8 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=177, max_depth=2,\n",
    " min_child_weight=8, gamma=0.0, subsample=0.926, colsample_bytree=0.79,reg_lambda = 0.1,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test8, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch8.fit(X,y)\n",
    "gsearch8.best_params_, gsearch8.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:56:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'reg_lambda': 0.0}, 0.6329817158931083)"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test9 = {\n",
    " 'reg_lambda':[i*0.000001 for i in range(0,11)]\n",
    "}\n",
    "gsearch9 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=177, max_depth=2,\n",
    " min_child_weight=8, gamma=0.0, subsample=0.926, colsample_bytree=0.79,reg_lambda = 0.1,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test9, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch9.fit(X,y)\n",
    "gsearch9.best_params_, gsearch9.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test9 = {\n",
    " 'reg_lambda':[i*0.000001 for i in range(0,11)]\n",
    "}\n",
    "gsearch9 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=177, max_depth=2,\n",
    " min_child_weight=8, gamma=0.0, subsample=0.926, colsample_bytree=0.79,reg_lambda = 0.1,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test9, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch9.fit(X,y)\n",
    "gsearch9.best_params_, gsearch9.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:38:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'learning_rate': 0.001, 'n_estimators': 7000}, 0.6280701754385964)"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test10 = {\n",
    " 'learning_rate':[0.1,0.01,0.001,0.0001],\n",
    " 'n_estimators':[5000,6000,4000,7000],\n",
    "}\n",
    "gsearch10 = GridSearchCV(estimator = XGBClassifier( max_depth=2,\n",
    " min_child_weight=8, gamma=0.0, subsample=0.926, colsample_bytree=0.79,reg_alpha=0.1086,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test10, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch10.fit(X,y)\n",
    "gsearch10.best_params_, gsearch10.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Accuracy : 0.76\n",
      "AUC Score (Train): 0.819444\n"
     ]
    }
   ],
   "source": [
    "xgb4 = XGBClassifier(\n",
    " learning_rate =0.005,\n",
    " n_estimators=7000,\n",
    " max_depth=2,\n",
    " min_child_weight=8,\n",
    " gamma=0.0,\n",
    " subsample=0.79,\n",
    " colsample_bytree=0.926,\n",
    " reg_alpha=0.1086,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb4, X,y, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_xgb = Pipeline([('scalar1', StandardScaler()),\n",
    "                         ('pca1', PCA(n_components=2) ),\n",
    "                         ('xgb_classifier', XGBClassifier(\n",
    " learning_rate =0.0085,\n",
    " n_estimators=7000,\n",
    " max_depth=2,\n",
    " min_child_weight=8,\n",
    " gamma=0.0,\n",
    " subsample=0.79,\n",
    " colsample_bytree=0.926,\n",
    " reg_alpha=0.1086,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:40:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scalar1',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('pca1',\n",
       "                 PCA(copy=True, iterated_power='auto', n_components=2,\n",
       "                     random_state=None, svd_solver='auto', tol=0.0,\n",
       "                     whiten=False)),\n",
       "                ('xgb_classifier',\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=0.926, gamma=0.0, g...\n",
       "                               max_delta_step=0, max_depth=2,\n",
       "                               min_child_weight=8, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=7000,\n",
       "                               n_jobs=4, nthread=4, num_parallel_tree=1,\n",
       "                               objective='binary:logistic', random_state=27,\n",
       "                               reg_alpha=0.1086, reg_lambda=1,\n",
       "                               scale_pos_weight=1, seed=27, subsample=0.79,\n",
       "                               tree_method='exact', use_label_encoder=True,\n",
       "                               validate_parameters=1, verbosity=None))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_xgb.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_xgb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1591\n"
     ]
    }
   ],
   "source": [
    "predicted_y = pipeline_xgb.predict(X_Sample_Test)\n",
    "predicted_y = list(predicted_y)\n",
    "w_list = []\n",
    "for j in range(len(predicted_y)):\n",
    "    w_list.append({\"Id\":(j+1), \"Category\":predicted_y[j]})\n",
    "print(len(w_list))\n",
    "with open('predictions'+'.csv', 'w', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=[\"Id\", \"Category\"])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(w_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base')",
   "language": "python",
   "name": "python37664bitbase3d920d87e3644dc8a79788ca4d0afcae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
